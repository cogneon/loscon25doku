---
links-as-notes: true
lof: false
logo-width: 100mm
subtitle: KI-unterst√ºtzte Dokumentation der lernOS Convention 2025
title: loscon25 Un-Konferenzband
titlepage: true
titlepage-color: 000000
titlepage-logo: src/images/loscon25-key-visual.png
titlepage-rule-color: 2e3192
titlepage-text-color: ed1b24
toc: true
toc-depth: 3
toc-own-page: true
---



# Willkommen

![](./images/loscon25-key-visual-banner.png)

Die [lernOS Convention
2025](https://community.sap.com/t5/sap-training-and-change-management/sap-learning-and-adoption-forum-2025-save-the-date/ba-p/14048737)
findet vom 1.-2. Juli 2025 in N√ºrnberg, an drei Satelliten Lokationen
(M√ºnchen, Hamburg, Berlin) und Online statt. Die Inhalte dieser
Dokumentation stammen aus den Aufzeichnungen der Impulsvortr√§ge,
Lightning Talks, Sessions, Workshops und Podcasts.

!!! note "Hinweis" Mit der Dokumentation k√∂nnt ihr sogar [mit diesem
Chatbot](https://chatgpt.com/g/g-685e35df934c8191bdfbd56cd136038b-loscon25-doku-bot)
(CustomGPT, Modell GPT-4o) "reden" ... das funktioniert sogar in
nat√ºrlicher Sprache mit dem Voice Mode. Die KI-generierten
Zusammenfassungen wurden **NICHT** nachberarbeitet. Die KI kann Fehler
machen üòâ

# Workflow der KI-generierten Zusammenfassung

Um die KI-basierte Dokumentation den Teilnehmenden schon w√§hrend der
Veranstaltung bereitstellen zu k√∂nnen, wurde die Auswertung und
Bereitstellnug der Inhalte weitgehend automatisiert:

![](./images/ai-documentation-chain.png)

1.  Die **Aufzeichnungen** (*Format: mp4*) der Beitr√§ge werden von den
    Room Buddies in einen zentralen Onedrive-Ordner hochgeladen.
2.  Die Aufzeichnungen werden aus einem von
    [MacWhisper](https://goodsnooze.gumroad.com/l/macwhisper) (Modell:
    whister-large-v3-turbo) beobachteten Ordner automatisch
    **transkribiert** (*Format: txt*).
3.  Die Transkripte werden mit der App [Chatbox](https://chatboxai.app/)
    mit einem dort angelegten Copilot (nicht Microsoft Copilot) nach
    einheitlichem Schema **zusammengefasst** (Format: md). *(noch
    festzulegen, aktuell: Zusammenfassung, Gliederung, Kernaussagen,
    Offene Fragestellungen, Handlungsempfehlungen, Thesen, Abschluss)*.
4.  Die Zusammenfassungen werden in der **Repo-Struktur** von
    [lernOS](https://lernos.org) in einem Github-Repository abgelegt.
5.  Mit der **lernOS Produktionskette** wird aus den Markdown-Dateien
    automatisch diese Web-Version sowie weitere Formate zum Download
    (pdf, html, docx, md) erzeugt.
6.  Die Markdown-Version (mit allen Zusammenfassungen) wird als
    **"Wissensbasis" f√ºr einen Chatbot** auf Basis eines
    [CustomGPT](https://help.openai.com/en/articles/8554397-creating-a-gpt)
    verwendet. Nutzende k√∂nnen so mit der Zusammenfassung der
    Veranstaltung "sprechen".
7.  Interessenten k√∂nnen sich eine **Markdown-Version der
    Dokumentation** unter *Download* zus√§tzlich herunterladen, um sie in
    eigenen KI-Tools wie z.B. [Microsoft
    Copilot](https://www.microsoft.com/de-de/microsoft-copilot/organizations),
    [SAP
    Joule](https://www.sap.com/germany/products/artificial-intelligence/ai-assistant.html),
    [Gemini](https://gemini.google.com/),
    [NotebookLM](https://notebooklm.google/), [Le
    Chat](https://chat.mistral.ai/) (europ√§isch) oder lokalen KI-Tools
    ([LM Studio](https://lmstudio.ai/),
    [Chatbox](https://chatboxai.app/),
    [GPT4All](https://www.nomic.ai/gpt4all), [Open
    WebUI](https://openwebui.com/)) zu verwenden.

# Impulsvortr√§ge

## Simon D√ºckert: Ni lernOS - Wenn wir nur w√ºssten, was wir wissen (sollten)

> Gerade in turbulenten Zeiten wie unseren ist das strategische
> Wissensmanagement von gro√üer Bedeutung. Umfelder und Rahmenbedingungen
> √§ndern sich kontinuierlich. Neue technologische Trends wie die
> K√ºnstliche Intelligenz zwingen uns, unsere Aufgaben, Rollen,
> Gesch√§ftsprozesse und vielleicht sogar Gesch√§ftsmodelle kritische zu
> hinterfragen und auftauchende Wissensl√ºcken systematisch zu schlie√üen.
> Dieser Impuls gibt einen kompakten √úberblick wie der Werkzeugkasten
> des Wissensmanagement und lernOS Individuen, Teams und Organisationen
> bei diesem Kraftakt helfen kann.

# lernOS - Wenn wir nur w√ºssten, was wir wissen (sollten)

### Kurze Zusammenfassung des Vortrags

Simon D√ºckert pr√§sentiert einen innovativen Ansatz zum Wissensmanagement
durch den praktischen Einsatz von KI-Tools. Er demonstriert live, wie
K√ºnstliche Intelligenz als Sparringspartner f√ºr strategische Reflexion
und Entwicklungsplanung eingesetzt werden kann. Dabei nutzt er die
"Future Backwards"-Methode und zeigt auf, wie Organisationen ihre
Wissensl√ºcken identifizieren und schlie√üen k√∂nnen. Der Vortrag
verdeutlicht die Diskrepanz zwischen der rasanten technologischen
Entwicklung und den noch immer hierarchischen Organisationsstrukturen
des 20. Jahrhunderts.

### Gliederung und Aufbau des Vortrags

Der Vortrag gliedert sich in mehrere aufeinander aufbauende Abschnitte:

**1. Einleitung und Problemstellung** - Aktuelle Herausforderungen durch
rasante Entwicklungsdynamiken - Die vier Prinzipien von Ethan Mollick im
Umgang mit KI

**2. Live-Demonstration: KI als Sparringspartner** - Einrichtung eines
Personal Context Files - Praktische Anwendung der Future
Backwards-Methode - Analyse von Vergangenheit, Gegenwart und Zukunft des
Wissensmanagements

**3. Reflexion organisationaler Herausforderungen** - Identifikation von
Wissensl√ºcken und strukturellen Problemen - Vision und Anti-Vision f√ºr
Wissensmanagement

**4. Ausblick auf zuk√ºnftige Entwicklungen** - KI-Agenten und Model
Context Protocol (MCP) - Integration von KI in bestehende Systeme

### Die vier Prinzipien von Ethan Mollick

#### Always put AI at the table

*"Bei allem, was wir machen, die KI mit an den Tisch zu setzen"* -
dieses erste Prinzip bildet die Grundlage f√ºr Simons Ansatz. Statt
traditioneller PowerPoint-Pr√§sentationen demonstriert er live die Arbeit
mit KI-Tools. Die KI wird nicht als externes Werkzeug betrachtet,
sondern als integraler Bestandteil des Arbeitsprozesses.

Die praktische Umsetzung zeigt sich in der direkten Einbindung von
Claude (Anthropic's KI) in den Vortrag. Simon l√§dt sein Personal Context
File hoch und arbeitet in Echtzeit mit der KI zusammen, um strategische
Fragestellungen zu durchdenken. Dies verdeutlicht, wie KI von einem
passiven Tool zu einem aktiven Arbeitspartner werden kann.

#### Human in the Loop - Always put the human in the loop

Das zweite Prinzip betont die unverzichtbare Rolle menschlicher
Expertise: *"Bei dem, was rauskommt, vielleicht habt ihr die Erfahrung
auch schon gemacht, da gibt es Dinge, die gut funktionieren und gut
sind, aber letztendlich braucht es doch die menschliche Expertise, um
einsch√§tzen zu k√∂nnen, stimmt das dann, was da steht oder was die KI
ausgibt."*

Simon demonstriert dies durch kontinuierliche Bewertung und Einordnung
der KI-Outputs. Er nutzt sein Fachwissen, um die Qualit√§t und Relevanz
der generierten Inhalte zu beurteilen und zeigt auf, wie wichtig die
menschliche Validierung bleibt, auch wenn KI-Systeme immer ausgefeilter
werden.

#### Anthropomorphismus mit Bewusstsein

Das dritte Prinzip lautet: *"Rede mit der KI, als ob es ein Mensch w√§re.
Anthropomorphismus, aber in Klammern, sei dir aber immer bewusst, dass
sie keiner ist."* Simon warnt vor der Gefahr, KI-Systemen menschliche
Eigenschaften zuzuschreiben: *"Da sagen Leute so Sachen wie, die KI
denkt gerade nach oder was f√ºhlt die wohl? Hat die schon Bewusstsein
entwickelt? Also ich finde, das ist ganz wichtig zu sagen, das sind
einfach nur Algorithmen. Das ist Statistik, da werden Dinge ausgerechnet
und nach Wahrscheinlichkeiten Buchstaben ausgegeben. Da denkt √ºberhaupt
nichts."*

Diese Klarstellung ist besonders wichtig, da sie hilft, realistische
Erwartungen an KI-Systeme zu entwickeln und deren Grenzen zu verstehen.

### Das Problem der Wissensl√ºcken in Organisationen

#### Strukturelle Defizite im deutschen Wirtschaftssystem

Simon identifiziert ein fundamentales Problem: *"Wir als Land, was
eigentlich nur Wissen und Ideen als Ressource hat, wir sitzen nicht auf
√ñl und auf Diamanten nicht. Dann sind wir heute noch ziemlich stark von
so organisationalen Strukturen gepr√§gt, wie die vor 100 Jahren auch
schon waren. Sehr hierarchisch, √ºberall gibt es mal so ein bisschen
agile Inseln und so weiter."*

Diese Analyse zeigt die Diskrepanz zwischen den Anforderungen einer
Wissensgesellschaft und den noch immer vorherrschenden
industriezeitalterlichen Organisationsformen auf. Deutschland als
ressourcenarmes Land ist besonders auf effektives Wissensmanagement
angewiesen, nutzt aber seine Potentiale nicht optimal.

#### Mangelnde Verankerung von Wissensmanagement

Ein zentrales Problem sieht Simon in der unzureichenden institutionellen
Verankerung: *"Das Thema Wissensmanagement aus meiner Sicht ist
eigentlich da eine andere Brille drauf, ist aber in den Organisationen
√ºberhaupt nicht so verankert und vor allen Dingen auch nicht mit
Ressourcen versehen, wie wir das eigentlich br√§uchten. Das hei√üt, da
wird mal hier ein Projekt gemacht und hier war ein Werkstatt und da
googelt dann mal, was Wissensmanagement ist, aber es ist nicht in den
Zielvereinbarungen von den F√ºhrungskr√§ften. Es ist nicht bonusrelevant.
Es gibt keine Abteilung oder Stabsstelle."*

Diese Beobachtung verdeutlicht, dass Wissensmanagement oft als
Nebenaktivit√§t behandelt wird, anstatt als strategische Kernfunktion der
Organisation.

### KI als "Einstein in der Hosentasche"

#### Zugang zu Weltwissen

Simon verwendet eine einpr√§gsame Metaphor: *"Das, was ihr kriegt mit so
einem LLM ist, ihr kriegt den kleinen Einstein in der Hosentasche, der
ganz flei√üig das ganze Internet durchgelesen hat. Und alle Trends und
alle Gartner-Studien und alle HBA-Artikel und alles wei√ü und kennt. Und
dieses Wissen k√∂nnt ihr euch zug√§nglich machen, um eure Wissensl√ºcken zu
schlie√üen."*

Diese Darstellung macht deutlich, welches Potential in der Nutzung von
Large Language Models liegt. Sie bieten Zugang zu einem enormen
Wissensschatz, der weit √ºber das hinausgeht, was einzelne Berater oder
Experten liefern k√∂nnen.

#### √úberlegenheit gegen√ºber traditioneller Beratung

Die Vorteile werden konkret benannt: *"Und das ist viel, viel mehr, als
wenn ihr ein oder f√ºnf oder zehn Berater zu einem Thema einkauft. Ihr
kriegt den Querschnitt des Weltwissens zu euren Fingerspitzen."*

Diese Aussage positioniert KI nicht als Ersatz f√ºr menschliche
Expertise, sondern als Erg√§nzung, die einen viel breiteren
Wissenshorizont er√∂ffnet.

### Die Future Backwards-Methode mit KI

#### R√ºckblick: Entwicklung der letzten 20 Jahre

Simon demonstriert, wie KI bei der historischen Analyse helfen kann:
*"Und das ist was, was LLMs super k√∂nnen. Die sind auf dem ganzen
Internet-Content oder sehr viel Internet-Content trainiert und dann kann
ich sehr sch√∂n sagen, dein Knowledge Cut-Off-Date ist zwar Herbst 2024,
aber stelle dir mal vor, es ist 1970. Wie w√ºrde Wissensmanagement da
aussehen?"*

Die R√ºckschau zeigt kontinuierliche Themen auf, die das
Wissensmanagement seit Jahrzehnten besch√§ftigen, aber noch immer nicht
gel√∂st sind. Dies verdeutlicht die Langsamkeit organisationaler
Ver√§nderungen im Vergleich zur technologischen Entwicklung.

#### Zukunftsvision: Heaven-Szenario

F√ºr die Zukunftsvision schl√§gt die KI konkrete Strukturen vor, wie die
Einrichtung von Chief Knowledge Officer-Positionen und die Investition
von *"drei bis f√ºnf Prozent des Umsatzes f√ºr das Thema
Wissensmanagement"*. Simon kommentiert: *"Wo ich sage, wenn ich das
ernsthaft machen will, kann ich nicht mit dem Werkstudent, der einen Tag
die Woche kommt, Wissensmanagement machen. Oder kann das so nebenher,
jeder macht das als Corporate Hobby."*

Diese Vision macht deutlich, welche Ressourcen und strukturellen
Ver√§nderungen n√∂tig w√§ren, um Wissensmanagement wirklich erfolgreich zu
implementieren.

#### Anti-Vision: Hell-Szenario

Das negative Szenario umfasst Probleme wie kognitiven Overload, digitale
Abh√§ngigkeit und Knowledge Silos. Besonders relevant ist der Aspekt des
"Brain Drain": *"Hier so Brain Drain, jetzt nach Pandemie stellt man
fest, viele Leute wechseln die Organisationen, also so Talentflucht
wegen schlechter Wissenskultur. Die guten Talente in der Zukunft, wenn
sie immer knapper werden jetzt durch demografischen Wandel, die gehen
nat√ºrlich dahin, wo sie gute Arbeitsbedingungen vorfinden und eine gute
Wissenskultur vorfinden."*

### Technologische Zukunft: Agenten und MCP

#### Von passiven zu aktiven KI-Systemen

Simon skizziert die n√§chste Entwicklungsstufe: *"Dieser Schritt von KI
und Sprachmodelle sind passiv. Hinzu, die werden aktive Agenten, die
irgendwas tun k√∂nnen, denen ich eine Aufgabe gebe, dann gehen die weg,
auch wieder wie die Werkstudenten, Werkstudentin oder Werkstudentin,
dann kommen die wieder, haben es gemacht und sage, ich passt nicht, dann
gehen die wieder weg."*

Diese Entwicklung hin zu autonomen KI-Agenten wird die Art, wie wir mit
Technologie arbeiten, fundamental ver√§ndern.

#### Model Context Protocol als Game Changer

Das Model Context Protocol wird als revolution√§re Entwicklung
dargestellt: *"Das ist ein Standard von Entropic, wo man jetzt sozusagen
ganz viele Quellen an diese LLMs anschlie√üen kann."* Simon vergleicht es
mit USB: *"Also es gibt so das gefl√ºgelt Wort von MCP als USB-Stecker
f√ºr die KI. USB war so eine Revolution, alles was ihr anschlie√üt,
Headset, Ventilator, Lautsprecher ist alles USB und diese Rolle wird MCP
spielen."*

Die Integration von MCP in Windows 11 wird weitreichende Konsequenzen
haben: *"Das hei√üt, ihr werdet mit jedem Excel-File, mit jeder
PowerPoint-Pr√§sentation, mit jeder Datenbank, mit ganzen GitHub-Repos
√ºber den MCP-Standard sprechen k√∂nnen."*

### Praktische Umsetzung und Personal Context Files

#### Kontextualisierung der KI-Interaktion

Ein wichtiger praktischer Aspekt ist die Vorbereitung der KI-Systeme:
*"Das hei√üt insbesondere, wenn ihr halt mit verschiedenen KIs promptet,
ist das relativ sinnvoll, sich so ein, nennt sich technisch Personal
Context File zu machen. Also ein File, was eigentlich euren Kontext
beschreibt. Wer bin ich? Was ist mein Lernstil? Woran arbeite ich
gerade? In welchen Projekten bin ich drin?"*

Diese Kontextualisierung ist entscheidend f√ºr die Qualit√§t der
KI-Outputs und macht die Interaktion effizienter und zielgerichteter.

#### Das Problem des "Memory Loss"

Simon beschreibt eine grundlegende Herausforderung: *"Ein bisschen
Problem bei diesen Chats ist ja immer, die kennen einen nicht. Sobald
ihr auf neuer Chat klickt, seid ihr sozusagen wieder komplett mit einem,
wer kennt noch Man in Black, geblitztingst. Also ihr seid sofort mit dem
geblitztingsten Werkstudenten da, der nichts von euch wei√ü."*

Diese Analogie verdeutlicht die Notwendigkeit, KI-Systeme kontinuierlich
mit relevantem Kontext zu versorgen.

### Handlungsempfehlungen und Call to Actions

#### Sofortiger Einstieg in KI-Tools

Simon ermutigt zur direkten Anwendung: *"Sprecht mich gerne an. Das sind
alles Sachen, die nicht erfunden oder Raumschiff Enterprise oder gefakt
sind. F√ºr mich war jetzt auch die Pr√§sentation ohne Netz und doppelten
Boden."*

Die Live-Demonstration soll zeigen, dass diese Technologien bereits
heute verf√ºgbar und einsetzbar sind.

#### Aufbau von KI-Kompetenz

Der Vortrag appelliert daran, sich aktiv mit verschiedenen Aspekten der
KI-Entwicklung auseinanderzusetzen, auch wenn es √ºberw√§ltigend
erscheinen mag: *"Selbst im Thema KI gibt es so viel mehr Subthemen, mit
denen man sich jetzt aktuell besch√§ftigen m√ºsste, dass man diese
typische Fear of Missing Out, also man muss irgendwie das f√ºr sich
sortiert haben."*

#### Experimentelles Lernen

Simon betont die Wichtigkeit des praktischen Ausprobierens: *"Wir haben
hier ganz viel Platz, setzen uns hin, auch in der Abendveranstaltung und
k√∂nnen uns das alle in Ruhe anschauen."*

#### Strategische Organisationsentwicklung

F√ºr Organisationen empfiehlt Simon eine systematische Herangehensweise
an Wissensmanagement, die √ºber Einzelprojekte hinausgeht und
strukturelle Ver√§nderungen umfasst.

#### Besch√§ftigung mit MCP

Als konkrete technische Empfehlung gibt Simon mit: *"Also wenn jemand
noch nie was von MCP geh√∂rt hat, besch√§ftigt euch da mal damit."* Diese
Technologie wird in naher Zukunft die Art der KI-Nutzung fundamental
ver√§ndern.

### Fazit

Der Vortrag zeigt eindrucksvoll, wie KI bereits heute als strategischer
Partner f√ºr Reflexion und Entwicklung eingesetzt werden kann. Simon
demonstriert nicht nur die technischen M√∂glichkeiten, sondern auch die
notwendige kritische Haltung im Umgang mit KI-Systemen. Seine
Live-Demonstration macht deutlich, dass die Zukunft des
Wissensmanagements in der intelligenten Kombination menschlicher
Expertise mit KI-Unterst√ºtzung liegt.

Die vier Prinzipien von Ethan Mollick bieten dabei einen praktischen
Rahmen f√ºr den verantwortungsvollen Umgang mit KI. Besonders wichtig ist
die Erkenntnis, dass KI nicht menschliche Intelligenz ersetzt, sondern
erweitert und dass der "Human in the Loop" unverzichtbar bleibt.

F√ºr Organisationen ergibt sich die dringende Notwendigkeit,
Wissensmanagement von einer Nebenaktivit√§t zu einer strategischen
Kernfunktion zu entwickeln. Dies erfordert nicht nur technische
L√∂sungen, sondern fundamentale strukturelle und kulturelle
Ver√§nderungen.

Die vorgestellten Zukunftstechnologien wie KI-Agenten und das Model
Context Protocol werden die Arbeitswelt in den n√§chsten Jahren erheblich
ver√§ndern. Wer diese Entwicklungen proaktiv mitgestaltet, wird
entscheidende Wettbewerbsvorteile erlangen.

## Bettina Laugwitz - Mind the AI Safety Gap

> Safety im Sinne von "AI soll so konstruiert sein und verwendet werden,
> dass sie nicht sch√§dlich f√ºr Menschen ist", da spielen ethische
> Prinzipien eine wichtige Rolle, aber auch "AI Literacy", die allen
> Beteiligten erm√∂glicht, Risiken, Grenzen und M√∂glichkeiten bewusst
> abzuw√§gen.

# Mind the AI Safety Gap - KI-Sicherheit und Ethik in der Praxis

## Kurze Zusammenfassung

Bettina Laugwitz von SAP pr√§sentierte einen umfassenden √úberblick √ºber
AI Safety und KI-Ethik, wobei sie die Parallelen zwischen der
Entwicklung der Automobilindustrie und der heutigen KI-Revolution
aufzeigte. Der Vortrag behandelte die drei Grundpfeiler
vertrauensw√ºrdiger KI - Rechtm√§√üigkeit, Robustheit und Ethik - und
stellte SAPs Ansatz zur verantwortungsvollen KI-Entwicklung vor. Durch
anschauliche Beispiele verdeutlichte sie sowohl die Potenziale als auch
die Risiken aktueller KI-Technologien und pr√§sentierte konkrete
L√∂sungsans√§tze f√ºr die Implementierung ethischer KI-Systeme.

## Gliederung und Aufbau des Vortrags

Der Vortrag folgte einer strukturierten 3x3-Gliederung:

**Was:** Definition und Abgrenzung von KI-Sicherheit und KI-Ethik
**Warum:** Begr√ºndung der Notwendigkeit von AI Safety **Wie:**
Praktische Umsetzungsans√§tze und SAPs Responsible AI Framework

Die Pr√§sentation nutzte durchgehend die Analogie zur
Automobilentwicklung, beginnend mit Bertha Benz' historischer Fahrt
1888, um die gesellschaftlichen Auswirkungen disruptiver Technologien zu
verdeutlichen.

### Was ist KI-Sicherheit und AI Safety?

Laugwitz etablierte zun√§chst eine klare begriffliche Grundlage und
betonte die Unterscheidung zwischen "Security" (sicher gebaut) und
"Safety" (sicher zu verwenden). *"Also es geht im Grunde darum, KI so zu
gestalten und so zu entwickeln, dass es keinen Schaden anrichtet. Also
dass sie nicht Menschen, Umwelt, gesellschaftliche Beeintr√§chtigungen
erzeugt."*

Die Referentin entwickelte eine Analogie zum Stra√üenverkehr, um die
verschiedenen Sicherheitsebenen zu verdeutlichen:

- Rechtliche Compliance: Wie Verkehrsteilnehmer Gesetze einhalten m√ºssen
- Technische Robustheit: Wie funktionierende Bremsen notwendig sind
- Ethische Prinzipien: Wie R√ºcksichtnahme √ºber gesetzliche Vorgaben
  hinausgeht

Diese Dreiteilung basiert auf den *"Guidelines for Trustworthy AI"* der
Europ√§ischen Kommission von 2018, die drei Grundpfeiler definiert:
*"Trustworthy AI needs to be rechtm√§√üig, robust und ethisch."*

### Kategorisierung von KI-Systemen

Ein wesentlicher Teil der Pr√§sentation widmete sich der systematischen
Einordnung verschiedener KI-Technologien:

**K√ºnstliche Intelligenz (√úberbegriff):** - Umfasst alle Systeme mit
menschen√§hnlichen Verhaltensweisen - Schlie√üt auch regelbasierte
Expertensysteme ein

**Maschinelles Lernen:** - Systeme, die sich durch Erfahrung oder Daten
weiterentwickeln - Klassifizierung und Kategorisierung basierend auf
Wahrscheinlichkeiten - Beispiele: Medizinische Diagnose,
Kreditbewertung, Bilderkennung

**Generative KI:** - Erzeugt neue Inhalte - *"Wichtiger Unterschied, der
nicht allen immer so klar ist"* - Fokus auf plausible Ausgaben, nicht
auf Wahrheit

**KI-Agenten:** - Komplexere Abl√§ufe mit Planungsf√§higkeiten -
Kooperation mit anderen Agenten - Tool-Verwendung f√ºr komplexe Aufgaben

### Warum KI-Sicherheit jetzt wichtig ist

Laugwitz argumentierte mit drei Hauptgr√ºnden f√ºr die Dringlichkeit des
Themas:

#### Dynamische Systementwicklung

*"Das Weiterentwickeln von den Systemen durch Daten und Erfahrungen
f√ºhrt halt dazu, dass es eine Dynamik gibt, dass die Systeme nicht
einfach so sind, wie man so fertig programmiert hat, ausgeliefert hat
und dann sind sie so sicher und robust bis zum n√§chsten Upgrade, sondern
man muss es eben im Auge behalten."*

#### Skalierungseffekte

Die Referentin nutzte die Automobilgeschichte als Metapher: *"Das ist
das einzige Auto, was au√üerhalb von Mannheim da herumf√§hrt. Das einzige
Auto, das da herumf√§hrt, ist jetzt noch mal kein gro√ües Risiko f√ºr
andere Menschen, f√ºr die Umwelt. Es stellt kein gro√ües Risiko dar. Es
wurden es aber mehr und immer mehr. Und jetzt heute sind es mehr als
eine Milliarde Autos, Kraftfahrzeuge, die in diesem Moment auf der
Weltkugel herumfahren."*

Sie wagte die *"steile These, dass k√ºnstliche Intelligenz, so wie wir es
jetzt heute erleben, √§hnlich disruptiv sein kann wie diese Technologie.
Mit gro√üen Auswirkungen. Das Tempo ist atemberaubend und deswegen auch
sehr wichtig, ein Auge drauf zu haben."*

#### Begrenzte KI-Literacy und Bias-Problematik

Anhand praktischer Beispiele demonstrierte Laugwitz die Grenzen
aktueller KI-Systeme:

- Mangelndes Weltwissen: Generierung unrealistischer Bilder (zerbrochene
  Eier)
- Gesellschaftliche Verzerrungen: Gender-Bias bei Berufsdarstellungen
  (Arzt vs.¬†Krankenschwester)

*"Also in den Daten gibt es eine Verzerrung, die sind Jahrzehnte alt,
spiegelt vielleicht eine gesellschaftliche Realit√§t von vor 30, 40
Jahren wieder, aber auch nicht repr√§sentativ und so weiter."*

### SAPs Responsible AI Framework

Laugwitz pr√§sentierte SAPs dreis√§uliges Modell f√ºr verantwortungsvolle
KI:

#### KI-Compliance

- Einhaltung globaler Vorschriften und Gesetze
- Anpassung an verschiedene Rechtsr√§ume

#### KI-Sicherheit

- Robuste Implementierung
- Schutz vor Manipulation und Hacking
- Zuverl√§ssige Funktionsweise

#### KI-Ethik

- Ethische Prinzipien f√ºr gute KI-Systeme
- Verantwortungs√ºbernahme f√ºr Systemverhalten

### Organisatorische Umsetzung bei SAP

Die Referentin betonte SAPs langj√§hrige Expertise: *"Das Thema ist schon
wirklich ganz lange bei uns ein wichtiges Thema und hat sich √ºber die
letzten Jahre aufgebaut und ausgebaut, sodass wir jetzt ein gro√ües,
hohes Level an Organisational Maturity haben, was das Thema KI-Ethik
betrifft."*

**Strukturelle Elemente:** - Global AI Ethics Policy mit definierten
Rollen und Verantwortlichkeiten - KI-Ethik-Bewertungsprozess in der
Produktentwicklung - Online-Kurse f√ºr Mitarbeiterbildung -
Kontinuierliche Risikoanalyse und -minimierung

### Drei Kernanforderungen ethischer KI

#### Menschliche Kontrolle und Selbstbestimmung

*"Es geht immer darum, dass der Mensch die Maschine unter Kontrolle hat
und nicht umgekehrt."* Die Referentin betonte die Bedeutung von "Human
in the Loop"-Konzepten und die bewusste Entscheidung, an welchen Stellen
menschliche Intervention erforderlich ist.

#### Fairness und Nichtdiskriminierung

Besonders relevant in HR-Anwendungen, um Verzerrungen bei
Bewerbungsverfahren zu vermeiden. Die systematische Analyse und
Korrektur von Bias in Trainingsdaten und Algorithmen steht im Fokus.

#### Transparenz und Erkl√§rbarkeit

*"Da geht es darum, dass Menschen die M√∂glichkeit haben m√ºssen zu
verstehen, was macht die Maschine jetzt eigentlich, so gut es halt
geht."* Obwohl KI-Systeme oft als Blackbox funktionieren, m√ºssen
Methoden entwickelt werden, um: - Systemverantwortlichen Einblicke in
die Funktionsweise zu geben - Anwendern die Bewertung von
KI-Empfehlungen zu erm√∂glichen - Fachexperten die Validierung von
Ergebnissen zu erlauben

### Handlungsempfehlungen und Call to Actions

#### F√ºr Organisationen

- **Aufbau organisatorischer Strukturen:** Etablierung von Rollen,
  Verantwortlichkeiten und Prozessen f√ºr KI-Ethik
- **Implementierung von Bewertungsprozessen:** Systematische
  Risikoanalyse bereits in der Konzeptionsphase von KI-Anwendungen
- **Kontinuierliche Weiterbildung:** Aufbau von KI-Literacy in der
  gesamten Organisation

#### F√ºr Entwickler und Produktteams

- **Fr√ºhzeitige Ethik-Integration:** *"Wenn man eine Anwendung
  definiert, sich √ºberlegt, in welche Anwendung wollen wir denn KI mit
  einbauen, dass man sich da schon dar√ºber Gedanken macht, was k√∂nnten
  Risiken sein"*
- **Human-in-the-Loop Design:** Bewusste Entscheidungen √ºber
  Automatisierungsgrade
- **Transparenz-Features:** Entwicklung erkl√§rbarer KI-Funktionen

#### F√ºr die Gesellschaft

- **Wachsamkeit bewahren:** *"Warum sollten wir also wachsam bleiben"* -
  kontinuierliche Beobachtung der KI-Entwicklung
- **KI-Literacy f√∂rdern:** Verbesserung des allgemeinen Verst√§ndnisses
  f√ºr KI-Technologien und deren Grenzen
- **Ethische Standards entwickeln:** Partizipation an gesellschaftlichen
  Diskussionen √ºber KI-Ethik

#### Spezifische Ressourcen-Empfehlungen

Laugwitz verwies mehrfach auf konkrete Hilfsmittel: - **SAP Responsible
AI Website:** Umfassende Dokumentation und Downloads - **AI Ethics
Handbook:** Praktischer Leitfaden f√ºr die Implementierung -
**Online-Kurse:** Strukturierte Weiterbildungsm√∂glichkeiten -
**UNESCO-Empfehlungen:** Internationale Standards als Orientierung

### Historische Parallelen und Zukunftsperspektiven

Die durchg√§ngige Analogie zur Automobilentwicklung verdeutlichte
wichtige Prinzipien:

**Innovation vor Regulation:** Wie der Dreipunkt-Sicherheitsgurt 1959
erfunden und erst 1973 gesetzlich vorgeschrieben wurde, entstehen auch
bei KI oft technische L√∂sungen vor rechtlichen Rahmen.

**Schrittweise Sicherheitsverbesserungen:** Von Sicherheitsglas in den
1920ern bis zu modernen Fahrassistenzsystemen zeigt sich, wie
kontinuierliche Innovation Sicherheitsstandards verbessert.

**Gesellschaftliche Transformation:** Die Entwicklung von einem
einzelnen Motorwagen zu √ºber einer Milliarde Fahrzeugen ver√§nderte
Gesellschaft, Gesetze und Technologie fundamental - ein Muster, das sich
bei KI wiederholen k√∂nnte.

Der Vortrag schloss mit einem optimistischen Ausblick: *"Das Thema ist
so spannend und so interessant. Ich bin jeden Tag sehr begeistert und
begl√ºckt, dass ich daran arbeiten darf, weil es auch so vielf√§ltig ist
und gleichzeitig auch so relevant."*

Diese Begeisterung f√ºr das Thema, kombiniert mit praktischen
L√∂sungsans√§tzen und klaren Handlungsempfehlungen, machte deutlich, dass
KI-Sicherheit nicht nur eine technische Herausforderung, sondern eine
gesellschaftliche Gestaltungsaufgabe ist, die proaktives Handeln aller
Beteiligten erfordert.

# Lightning Talks

## Fr√©d√©ric Heinemann - Collaborative Learning im SAP-Ecosystem - Key-User als Mentoren der Zukunft

...

## Simon D√ºckert - State of GenAI - was in meiner Wissensarbeit wirklich, wirklich funktioniert

...

## Bernhard Rupp - 12 Freunde m√ºsst ihr sein

...

## Florence Streif - Weichenstellung f√ºrs digitale Zeitalter - Zwischen Bahnhof und Besprechungsraum

...

## Moritz Huber - KI im Lern-Lifecycle - PoC f√ºr KI-gest√ºtztes Anwenderlernen

...

## Mike Fritz - SAP Enable Now trifft auf WalkMe und die SAP Integrated Toolchain

...

## Patrick Fueldner - Von der Einf√ºhrung zur Skalierung - Nestl√©s Digital Adoption-Strategie mit WalkMe

...

## Katja Sommerer - Big Bang - 40 L√§nder, 800 neue Mitarbeitende - Herausforderungen des Trainings in einem M+A-Projekt

...

## Andrea Fl√∂th - HR neu gedacht - BARMERs digitale Evolution mit Hilfe von SAP Preferred Success

...

## Mareike Muth - √úbersetzer der Moderne - Das Learning Team als Katalysator zwischen Fachbereich und Enduser

...

# Sessions & Workshops

## Promptathon

> Entwicklung und Optimierung von KI-Prompts f√ºr Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Discovery Workshop AI UseCases im Learning

> Exploration und Identifizierung von relevanten Use Cases f√ºr den
> Einsatz von KI f√ºr Change Management und Training in SAP Projekten.

## Good Practices & Lessons Learned SAP S/4HANA Transformationen

> Strategien f√ºr erfolgreiches OCM und Learning - Wichtige Do's & Dont's
> und deren Umsetzung mit dem SAP Activate Framework.

# Anhang

## Dokumentation der KI-basierten Dokumentation

Falls jemand einen √§hnlichen Ansatz der KI-basierten Dokumentation
verwenden m√∂chte, hier ein paar Informationen zu unserer Konfiguration:

1.  Alle Programmpunkte haben wir in Microsoft Teams (Vortr√§ge,
    Sessions) oder Discord/Reaper (Podcasts) aufgezeichnet (mp4, mp3).
2.  Die Aufzeichnungen haben wir mit Whisper auf einem Mac Mini M4
    transkribiert (txt).
3.  Die Transkripte haben wir mit einem Prompt (s.u.) in eine
    Dokumentation transformiert (md).
4.  Alle Dokumentationen haben wir in eine vorgefertigte Struktur in
    einem Github Repository kopiert
    ([github.com/cogneon/loscon25doku](github.com/cogneon/loscon25doku)).
5.  Mit der lernOS Produktionskette haben wir die Inhalte im Repository
    in eine [Web-Version](https://cogneon.github.io/loscon25doku/de) und
    weitere Download-Formate transformiert.

**Prompt:** folgt.
