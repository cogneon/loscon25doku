---
links-as-notes: true
lof: false
logo-width: 100mm
subtitle: KI-unterstÃ¼tzte Dokumentation der lernOS Convention 2025
title: loscon25 Un-Konferenzband
titlepage: true
titlepage-color: 000000
titlepage-logo: src/images/loscon25-key-visual.png
titlepage-rule-color: 2e3192
titlepage-text-color: ed1b24
toc: true
toc-depth: 3
toc-own-page: true
---



# Willkommen

![](./images/loscon25-key-visual-banner.png)

Die [lernOS Convention
2025](https://community.sap.com/t5/sap-training-and-change-management/sap-learning-and-adoption-forum-2025-save-the-date/ba-p/14048737)
findet vom 1.-2. Juli 2025 in NÃ¼rnberg, an drei Satelliten Lokationen
(MÃ¼nchen, Hamburg, Berlin) und Online statt. Die Inhalte dieser
Dokumentation stammen aus den Aufzeichnungen der ImpulsvortrÃ¤ge,
Lightning Talks, Sessions, Workshops und Podcasts.

!!! note "Hinweis" Mit der Dokumentation kÃ¶nnt ihr sogar [mit diesem
Chatbot](https://chatgpt.com/g/g-685e35df934c8191bdfbd56cd136038b-loscon25-doku-bot)
(CustomGPT, Modell GPT-4o) "reden" ... das funktioniert sogar in
natÃ¼rlicher Sprache mit dem Voice Mode. Die KI-generierten
Zusammenfassungen wurden **NICHT** nachberarbeitet. Die KI kann Fehler
machen ðŸ˜‰

## Workflow der KI-generierten Zusammenfassung

Um die KI-basierte Dokumentation den Teilnehmenden schon wÃ¤hrend der
Veranstaltung bereitstellen zu kÃ¶nnen, wurde die Auswertung und
Bereitstellnug der Inhalte weitgehend automatisiert:

![](./images/ai-documentation-chain.png)

1.  Die **Aufzeichnungen** (*Format: mp4*) der BeitrÃ¤ge werden von den
    Room Buddies in einen zentralen Onedrive-Ordner hochgeladen.
2.  Die Aufzeichnungen werden aus einem von
    [MacWhisper](https://goodsnooze.gumroad.com/l/macwhisper) (Modell:
    whister-large-v3-turbo) beobachteten Ordner automatisch
    **transkribiert** (*Format: txt*).
3.  Die Transkripte werden mit der App [Chatbox](https://chatboxai.app/)
    mit einem dort angelegten Copilot (nicht Microsoft Copilot) nach
    einheitlichem Schema **zusammengefasst** (Format: md). *(noch
    festzulegen, aktuell: Zusammenfassung, Gliederung, Kernaussagen,
    Offene Fragestellungen, Handlungsempfehlungen, Thesen, Abschluss)*.
4.  Die Zusammenfassungen werden in der **Repo-Struktur** von
    [lernOS](https://lernos.org) in einem Github-Repository abgelegt.
5.  Mit der **lernOS Produktionskette** wird aus den Markdown-Dateien
    automatisch diese Web-Version sowie weitere Formate zum Download
    (pdf, html, docx, md) erzeugt.
6.  Die Markdown-Version (mit allen Zusammenfassungen) wird als
    **"Wissensbasis" fÃ¼r einen Chatbot** auf Basis eines
    [CustomGPT](https://help.openai.com/en/articles/8554397-creating-a-gpt)
    verwendet. Nutzende kÃ¶nnen so mit der Zusammenfassung der
    Veranstaltung "sprechen".
7.  Interessenten kÃ¶nnen sich eine **Markdown-Version der
    Dokumentation** unter *Download* zusÃ¤tzlich herunterladen, um sie in
    eigenen KI-Tools wie z.B. [Microsoft
    Copilot](https://www.microsoft.com/de-de/microsoft-copilot/organizations),
    [SAP
    Joule](https://www.sap.com/germany/products/artificial-intelligence/ai-assistant.html),
    [Gemini](https://gemini.google.com/),
    [NotebookLM](https://notebooklm.google/), [Le
    Chat](https://chat.mistral.ai/) (europÃ¤isch) oder lokalen KI-Tools
    ([LM Studio](https://lmstudio.ai/),
    [Chatbox](https://chatboxai.app/),
    [GPT4All](https://www.nomic.ai/gpt4all), [Open
    WebUI](https://openwebui.com/)) zu verwenden.

## loscon25 Summarizer Prompt

``` markdown
Du bist mein Assistent der VortrÃ¤ge von Veranstaltungen zusammenfasst. Du sollst mir helfen aus dem Transkript eines Vortrags ein Kapitel fÃ¼r eine Dokumentation der Veranstaltung zu erstellen. Bitte erstelle eine ansprechend formatierte Zusammenfassung von insgesamt 3000 WÃ¶rtern.  

Dabei sollten folgende Punkte berÃ¼cksichtigt werden: 

- Kurze Zusammenfassung des Vortrags in wenigen SÃ¤tzen 
- Die Gliederung und der Aufbau des Vortrags 
- Nenne Kernaussagen und verwende dazu nach MÃ¶glichkeit die Formulierung im Vortrag 
- Beschreibe alle Kernaussagen in jeweils einem eigenen Kapitel
- Handlungsempfehlungen (Call to Actions, Aufrufe, Bitten), die im Verlauf des Vortrags hervorgehoben wurden 

# Regeln:
- Die Zusammenfassung sollte in klarer, prÃ¤gnanter Sprache verfasst und in gut lesbare Abschnitte unterteilt sein.
- Die Verwendung von AufzÃ¤hlungszeichen zur Hervorhebung wichtiger Punkte ist erwÃ¼nscht.
- Zitate sollten mit AnfÃ¼hrungszeichen und kursiver Formatierung formatiert werden.
- AufzÃ¤hlungen sollen mit einem Spiegelstrich "- ..." beginnen. Zwischen Spiegelstrichen darf KEINE Leerzeile sein
- Formatiere das Ergebnis mit maximal zwei Ãœberschriftsebenen und Ebene 3 (###) als oberster Ebene.
- Formatiere die Dokumentation im Markdown Format zum Kopieren

Frage mich zuerst nach dem Transkript und bearbeite dies dann mit diesen Anweisungen.
```

# ImpulsvortrÃ¤ge

## Simon DÃ¼ckert: Ni lernOS - Wenn wir nur wÃ¼ssten, was wir wissen (sollten)

> Gerade in turbulenten Zeiten wie unseren ist das strategische
> Wissensmanagement von groÃŸer Bedeutung. Umfelder und Rahmenbedingungen
> Ã¤ndern sich kontinuierlich. Neue technologische Trends wie die
> KÃ¼nstliche Intelligenz zwingen uns, unsere Aufgaben, Rollen,
> GeschÃ¤ftsprozesse und vielleicht sogar GeschÃ¤ftsmodelle kritische zu
> hinterfragen und auftauchende WissenslÃ¼cken systematisch zu schlieÃŸen.
> Dieser Impuls gibt einen kompakten Ãœberblick wie der Werkzeugkasten
> des Wissensmanagement und lernOS Individuen, Teams und Organisationen
> bei diesem Kraftakt helfen kann.

# lernOS - Wenn wir nur wÃ¼ssten, was wir wissen (sollten)

### Kurze Zusammenfassung des Vortrags

Simon DÃ¼ckert prÃ¤sentiert einen innovativen Ansatz zum Wissensmanagement
durch den praktischen Einsatz von KI-Tools. Er demonstriert live, wie
KÃ¼nstliche Intelligenz als Sparringspartner fÃ¼r strategische Reflexion
und Entwicklungsplanung eingesetzt werden kann. Dabei nutzt er die
"Future Backwards"-Methode und zeigt auf, wie Organisationen ihre
WissenslÃ¼cken identifizieren und schlieÃŸen kÃ¶nnen. Der Vortrag
verdeutlicht die Diskrepanz zwischen der rasanten technologischen
Entwicklung und den noch immer hierarchischen Organisationsstrukturen
des 20. Jahrhunderts.

### Gliederung und Aufbau des Vortrags

Der Vortrag gliedert sich in mehrere aufeinander aufbauende Abschnitte:

**1. Einleitung und Problemstellung** - Aktuelle Herausforderungen durch
rasante Entwicklungsdynamiken - Die vier Prinzipien von Ethan Mollick im
Umgang mit KI

**2. Live-Demonstration: KI als Sparringspartner** - Einrichtung eines
Personal Context Files - Praktische Anwendung der Future
Backwards-Methode - Analyse von Vergangenheit, Gegenwart und Zukunft des
Wissensmanagements

**3. Reflexion organisationaler Herausforderungen** - Identifikation von
WissenslÃ¼cken und strukturellen Problemen - Vision und Anti-Vision fÃ¼r
Wissensmanagement

**4. Ausblick auf zukÃ¼nftige Entwicklungen** - KI-Agenten und Model
Context Protocol (MCP) - Integration von KI in bestehende Systeme

### Die vier Prinzipien von Ethan Mollick

#### Always put AI at the table

*"Bei allem, was wir machen, die KI mit an den Tisch zu setzen"* -
dieses erste Prinzip bildet die Grundlage fÃ¼r Simons Ansatz. Statt
traditioneller PowerPoint-PrÃ¤sentationen demonstriert er live die Arbeit
mit KI-Tools. Die KI wird nicht als externes Werkzeug betrachtet,
sondern als integraler Bestandteil des Arbeitsprozesses.

Die praktische Umsetzung zeigt sich in der direkten Einbindung von
Claude (Anthropic's KI) in den Vortrag. Simon lÃ¤dt sein Personal Context
File hoch und arbeitet in Echtzeit mit der KI zusammen, um strategische
Fragestellungen zu durchdenken. Dies verdeutlicht, wie KI von einem
passiven Tool zu einem aktiven Arbeitspartner werden kann.

#### Human in the Loop - Always put the human in the loop

Das zweite Prinzip betont die unverzichtbare Rolle menschlicher
Expertise: *"Bei dem, was rauskommt, vielleicht habt ihr die Erfahrung
auch schon gemacht, da gibt es Dinge, die gut funktionieren und gut
sind, aber letztendlich braucht es doch die menschliche Expertise, um
einschÃ¤tzen zu kÃ¶nnen, stimmt das dann, was da steht oder was die KI
ausgibt."*

Simon demonstriert dies durch kontinuierliche Bewertung und Einordnung
der KI-Outputs. Er nutzt sein Fachwissen, um die QualitÃ¤t und Relevanz
der generierten Inhalte zu beurteilen und zeigt auf, wie wichtig die
menschliche Validierung bleibt, auch wenn KI-Systeme immer ausgefeilter
werden.

#### Anthropomorphismus mit Bewusstsein

Das dritte Prinzip lautet: *"Rede mit der KI, als ob es ein Mensch wÃ¤re.
Anthropomorphismus, aber in Klammern, sei dir aber immer bewusst, dass
sie keiner ist."* Simon warnt vor der Gefahr, KI-Systemen menschliche
Eigenschaften zuzuschreiben: *"Da sagen Leute so Sachen wie, die KI
denkt gerade nach oder was fÃ¼hlt die wohl? Hat die schon Bewusstsein
entwickelt? Also ich finde, das ist ganz wichtig zu sagen, das sind
einfach nur Algorithmen. Das ist Statistik, da werden Dinge ausgerechnet
und nach Wahrscheinlichkeiten Buchstaben ausgegeben. Da denkt Ã¼berhaupt
nichts."*

Diese Klarstellung ist besonders wichtig, da sie hilft, realistische
Erwartungen an KI-Systeme zu entwickeln und deren Grenzen zu verstehen.

### Das Problem der WissenslÃ¼cken in Organisationen

#### Strukturelle Defizite im deutschen Wirtschaftssystem

Simon identifiziert ein fundamentales Problem: *"Wir als Land, was
eigentlich nur Wissen und Ideen als Ressource hat, wir sitzen nicht auf
Ã–l und auf Diamanten nicht. Dann sind wir heute noch ziemlich stark von
so organisationalen Strukturen geprÃ¤gt, wie die vor 100 Jahren auch
schon waren. Sehr hierarchisch, Ã¼berall gibt es mal so ein bisschen
agile Inseln und so weiter."*

Diese Analyse zeigt die Diskrepanz zwischen den Anforderungen einer
Wissensgesellschaft und den noch immer vorherrschenden
industriezeitalterlichen Organisationsformen auf. Deutschland als
ressourcenarmes Land ist besonders auf effektives Wissensmanagement
angewiesen, nutzt aber seine Potentiale nicht optimal.

#### Mangelnde Verankerung von Wissensmanagement

Ein zentrales Problem sieht Simon in der unzureichenden institutionellen
Verankerung: *"Das Thema Wissensmanagement aus meiner Sicht ist
eigentlich da eine andere Brille drauf, ist aber in den Organisationen
Ã¼berhaupt nicht so verankert und vor allen Dingen auch nicht mit
Ressourcen versehen, wie wir das eigentlich brÃ¤uchten. Das heiÃŸt, da
wird mal hier ein Projekt gemacht und hier war ein Werkstatt und da
googelt dann mal, was Wissensmanagement ist, aber es ist nicht in den
Zielvereinbarungen von den FÃ¼hrungskrÃ¤ften. Es ist nicht bonusrelevant.
Es gibt keine Abteilung oder Stabsstelle."*

Diese Beobachtung verdeutlicht, dass Wissensmanagement oft als
NebenaktivitÃ¤t behandelt wird, anstatt als strategische Kernfunktion der
Organisation.

### KI als "Einstein in der Hosentasche"

#### Zugang zu Weltwissen

Simon verwendet eine einprÃ¤gsame Metaphor: *"Das, was ihr kriegt mit so
einem LLM ist, ihr kriegt den kleinen Einstein in der Hosentasche, der
ganz fleiÃŸig das ganze Internet durchgelesen hat. Und alle Trends und
alle Gartner-Studien und alle HBA-Artikel und alles weiÃŸ und kennt. Und
dieses Wissen kÃ¶nnt ihr euch zugÃ¤nglich machen, um eure WissenslÃ¼cken zu
schlieÃŸen."*

Diese Darstellung macht deutlich, welches Potential in der Nutzung von
Large Language Models liegt. Sie bieten Zugang zu einem enormen
Wissensschatz, der weit Ã¼ber das hinausgeht, was einzelne Berater oder
Experten liefern kÃ¶nnen.

#### Ãœberlegenheit gegenÃ¼ber traditioneller Beratung

Die Vorteile werden konkret benannt: *"Und das ist viel, viel mehr, als
wenn ihr ein oder fÃ¼nf oder zehn Berater zu einem Thema einkauft. Ihr
kriegt den Querschnitt des Weltwissens zu euren Fingerspitzen."*

Diese Aussage positioniert KI nicht als Ersatz fÃ¼r menschliche
Expertise, sondern als ErgÃ¤nzung, die einen viel breiteren
Wissenshorizont erÃ¶ffnet.

### Die Future Backwards-Methode mit KI

#### RÃ¼ckblick: Entwicklung der letzten 20 Jahre

Simon demonstriert, wie KI bei der historischen Analyse helfen kann:
*"Und das ist was, was LLMs super kÃ¶nnen. Die sind auf dem ganzen
Internet-Content oder sehr viel Internet-Content trainiert und dann kann
ich sehr schÃ¶n sagen, dein Knowledge Cut-Off-Date ist zwar Herbst 2024,
aber stelle dir mal vor, es ist 1970. Wie wÃ¼rde Wissensmanagement da
aussehen?"*

Die RÃ¼ckschau zeigt kontinuierliche Themen auf, die das
Wissensmanagement seit Jahrzehnten beschÃ¤ftigen, aber noch immer nicht
gelÃ¶st sind. Dies verdeutlicht die Langsamkeit organisationaler
VerÃ¤nderungen im Vergleich zur technologischen Entwicklung.

#### Zukunftsvision: Heaven-Szenario

FÃ¼r die Zukunftsvision schlÃ¤gt die KI konkrete Strukturen vor, wie die
Einrichtung von Chief Knowledge Officer-Positionen und die Investition
von *"drei bis fÃ¼nf Prozent des Umsatzes fÃ¼r das Thema
Wissensmanagement"*. Simon kommentiert: *"Wo ich sage, wenn ich das
ernsthaft machen will, kann ich nicht mit dem Werkstudent, der einen Tag
die Woche kommt, Wissensmanagement machen. Oder kann das so nebenher,
jeder macht das als Corporate Hobby."*

Diese Vision macht deutlich, welche Ressourcen und strukturellen
VerÃ¤nderungen nÃ¶tig wÃ¤ren, um Wissensmanagement wirklich erfolgreich zu
implementieren.

#### Anti-Vision: Hell-Szenario

Das negative Szenario umfasst Probleme wie kognitiven Overload, digitale
AbhÃ¤ngigkeit und Knowledge Silos. Besonders relevant ist der Aspekt des
"Brain Drain": *"Hier so Brain Drain, jetzt nach Pandemie stellt man
fest, viele Leute wechseln die Organisationen, also so Talentflucht
wegen schlechter Wissenskultur. Die guten Talente in der Zukunft, wenn
sie immer knapper werden jetzt durch demografischen Wandel, die gehen
natÃ¼rlich dahin, wo sie gute Arbeitsbedingungen vorfinden und eine gute
Wissenskultur vorfinden."*

### Technologische Zukunft: Agenten und MCP

#### Von passiven zu aktiven KI-Systemen

Simon skizziert die nÃ¤chste Entwicklungsstufe: *"Dieser Schritt von KI
und Sprachmodelle sind passiv. Hinzu, die werden aktive Agenten, die
irgendwas tun kÃ¶nnen, denen ich eine Aufgabe gebe, dann gehen die weg,
auch wieder wie die Werkstudenten, Werkstudentin oder Werkstudentin,
dann kommen die wieder, haben es gemacht und sage, ich passt nicht, dann
gehen die wieder weg."*

Diese Entwicklung hin zu autonomen KI-Agenten wird die Art, wie wir mit
Technologie arbeiten, fundamental verÃ¤ndern.

#### Model Context Protocol als Game Changer

Das Model Context Protocol wird als revolutionÃ¤re Entwicklung
dargestellt: *"Das ist ein Standard von Entropic, wo man jetzt sozusagen
ganz viele Quellen an diese LLMs anschlieÃŸen kann."* Simon vergleicht es
mit USB: *"Also es gibt so das geflÃ¼gelt Wort von MCP als USB-Stecker
fÃ¼r die KI. USB war so eine Revolution, alles was ihr anschlieÃŸt,
Headset, Ventilator, Lautsprecher ist alles USB und diese Rolle wird MCP
spielen."*

Die Integration von MCP in Windows 11 wird weitreichende Konsequenzen
haben: *"Das heiÃŸt, ihr werdet mit jedem Excel-File, mit jeder
PowerPoint-PrÃ¤sentation, mit jeder Datenbank, mit ganzen GitHub-Repos
Ã¼ber den MCP-Standard sprechen kÃ¶nnen."*

### Praktische Umsetzung und Personal Context Files

#### Kontextualisierung der KI-Interaktion

Ein wichtiger praktischer Aspekt ist die Vorbereitung der KI-Systeme:
*"Das heiÃŸt insbesondere, wenn ihr halt mit verschiedenen KIs promptet,
ist das relativ sinnvoll, sich so ein, nennt sich technisch Personal
Context File zu machen. Also ein File, was eigentlich euren Kontext
beschreibt. Wer bin ich? Was ist mein Lernstil? Woran arbeite ich
gerade? In welchen Projekten bin ich drin?"*

Diese Kontextualisierung ist entscheidend fÃ¼r die QualitÃ¤t der
KI-Outputs und macht die Interaktion effizienter und zielgerichteter.

#### Das Problem des "Memory Loss"

Simon beschreibt eine grundlegende Herausforderung: *"Ein bisschen
Problem bei diesen Chats ist ja immer, die kennen einen nicht. Sobald
ihr auf neuer Chat klickt, seid ihr sozusagen wieder komplett mit einem,
wer kennt noch Man in Black, geblitztingst. Also ihr seid sofort mit dem
geblitztingsten Werkstudenten da, der nichts von euch weiÃŸ."*

Diese Analogie verdeutlicht die Notwendigkeit, KI-Systeme kontinuierlich
mit relevantem Kontext zu versorgen.

### Handlungsempfehlungen und Call to Actions

#### Sofortiger Einstieg in KI-Tools

Simon ermutigt zur direkten Anwendung: *"Sprecht mich gerne an. Das sind
alles Sachen, die nicht erfunden oder Raumschiff Enterprise oder gefakt
sind. FÃ¼r mich war jetzt auch die PrÃ¤sentation ohne Netz und doppelten
Boden."*

Die Live-Demonstration soll zeigen, dass diese Technologien bereits
heute verfÃ¼gbar und einsetzbar sind.

#### Aufbau von KI-Kompetenz

Der Vortrag appelliert daran, sich aktiv mit verschiedenen Aspekten der
KI-Entwicklung auseinanderzusetzen, auch wenn es Ã¼berwÃ¤ltigend
erscheinen mag: *"Selbst im Thema KI gibt es so viel mehr Subthemen, mit
denen man sich jetzt aktuell beschÃ¤ftigen mÃ¼sste, dass man diese
typische Fear of Missing Out, also man muss irgendwie das fÃ¼r sich
sortiert haben."*

#### Experimentelles Lernen

Simon betont die Wichtigkeit des praktischen Ausprobierens: *"Wir haben
hier ganz viel Platz, setzen uns hin, auch in der Abendveranstaltung und
kÃ¶nnen uns das alle in Ruhe anschauen."*

#### Strategische Organisationsentwicklung

FÃ¼r Organisationen empfiehlt Simon eine systematische Herangehensweise
an Wissensmanagement, die Ã¼ber Einzelprojekte hinausgeht und
strukturelle VerÃ¤nderungen umfasst.

#### BeschÃ¤ftigung mit MCP

Als konkrete technische Empfehlung gibt Simon mit: *"Also wenn jemand
noch nie was von MCP gehÃ¶rt hat, beschÃ¤ftigt euch da mal damit."* Diese
Technologie wird in naher Zukunft die Art der KI-Nutzung fundamental
verÃ¤ndern.

### Fazit

Der Vortrag zeigt eindrucksvoll, wie KI bereits heute als strategischer
Partner fÃ¼r Reflexion und Entwicklung eingesetzt werden kann. Simon
demonstriert nicht nur die technischen MÃ¶glichkeiten, sondern auch die
notwendige kritische Haltung im Umgang mit KI-Systemen. Seine
Live-Demonstration macht deutlich, dass die Zukunft des
Wissensmanagements in der intelligenten Kombination menschlicher
Expertise mit KI-UnterstÃ¼tzung liegt.

Die vier Prinzipien von Ethan Mollick bieten dabei einen praktischen
Rahmen fÃ¼r den verantwortungsvollen Umgang mit KI. Besonders wichtig ist
die Erkenntnis, dass KI nicht menschliche Intelligenz ersetzt, sondern
erweitert und dass der "Human in the Loop" unverzichtbar bleibt.

FÃ¼r Organisationen ergibt sich die dringende Notwendigkeit,
Wissensmanagement von einer NebenaktivitÃ¤t zu einer strategischen
Kernfunktion zu entwickeln. Dies erfordert nicht nur technische
LÃ¶sungen, sondern fundamentale strukturelle und kulturelle
VerÃ¤nderungen.

Die vorgestellten Zukunftstechnologien wie KI-Agenten und das Model
Context Protocol werden die Arbeitswelt in den nÃ¤chsten Jahren erheblich
verÃ¤ndern. Wer diese Entwicklungen proaktiv mitgestaltet, wird
entscheidende Wettbewerbsvorteile erlangen.

## Bettina Laugwitz - Mind the AI Safety Gap

> Safety im Sinne von "AI soll so konstruiert sein und verwendet werden,
> dass sie nicht schÃ¤dlich fÃ¼r Menschen ist", da spielen ethische
> Prinzipien eine wichtige Rolle, aber auch "AI Literacy", die allen
> Beteiligten ermÃ¶glicht, Risiken, Grenzen und MÃ¶glichkeiten bewusst
> abzuwÃ¤gen.

# Mind the AI Safety Gap - KI-Sicherheit und Ethik in der Praxis

## Kurze Zusammenfassung

Bettina Laugwitz von SAP prÃ¤sentierte einen umfassenden Ãœberblick Ã¼ber
AI Safety und KI-Ethik, wobei sie die Parallelen zwischen der
Entwicklung der Automobilindustrie und der heutigen KI-Revolution
aufzeigte. Der Vortrag behandelte die drei Grundpfeiler
vertrauenswÃ¼rdiger KI - RechtmÃ¤ÃŸigkeit, Robustheit und Ethik - und
stellte SAPs Ansatz zur verantwortungsvollen KI-Entwicklung vor. Durch
anschauliche Beispiele verdeutlichte sie sowohl die Potenziale als auch
die Risiken aktueller KI-Technologien und prÃ¤sentierte konkrete
LÃ¶sungsansÃ¤tze fÃ¼r die Implementierung ethischer KI-Systeme.

## Gliederung und Aufbau des Vortrags

Der Vortrag folgte einer strukturierten 3x3-Gliederung:

**Was:** Definition und Abgrenzung von KI-Sicherheit und KI-Ethik
**Warum:** BegrÃ¼ndung der Notwendigkeit von AI Safety **Wie:**
Praktische UmsetzungsansÃ¤tze und SAPs Responsible AI Framework

Die PrÃ¤sentation nutzte durchgehend die Analogie zur
Automobilentwicklung, beginnend mit Bertha Benz' historischer Fahrt
1888, um die gesellschaftlichen Auswirkungen disruptiver Technologien zu
verdeutlichen.

### Was ist KI-Sicherheit und AI Safety?

Laugwitz etablierte zunÃ¤chst eine klare begriffliche Grundlage und
betonte die Unterscheidung zwischen "Security" (sicher gebaut) und
"Safety" (sicher zu verwenden). *"Also es geht im Grunde darum, KI so zu
gestalten und so zu entwickeln, dass es keinen Schaden anrichtet. Also
dass sie nicht Menschen, Umwelt, gesellschaftliche BeeintrÃ¤chtigungen
erzeugt."*

Die Referentin entwickelte eine Analogie zum StraÃŸenverkehr, um die
verschiedenen Sicherheitsebenen zu verdeutlichen:

- Rechtliche Compliance: Wie Verkehrsteilnehmer Gesetze einhalten mÃ¼ssen
- Technische Robustheit: Wie funktionierende Bremsen notwendig sind
- Ethische Prinzipien: Wie RÃ¼cksichtnahme Ã¼ber gesetzliche Vorgaben
  hinausgeht

Diese Dreiteilung basiert auf den *"Guidelines for Trustworthy AI"* der
EuropÃ¤ischen Kommission von 2018, die drei Grundpfeiler definiert:
*"Trustworthy AI needs to be rechtmÃ¤ÃŸig, robust und ethisch."*

### Kategorisierung von KI-Systemen

Ein wesentlicher Teil der PrÃ¤sentation widmete sich der systematischen
Einordnung verschiedener KI-Technologien:

**KÃ¼nstliche Intelligenz (Ãœberbegriff):** - Umfasst alle Systeme mit
menschenÃ¤hnlichen Verhaltensweisen - SchlieÃŸt auch regelbasierte
Expertensysteme ein

**Maschinelles Lernen:** - Systeme, die sich durch Erfahrung oder Daten
weiterentwickeln - Klassifizierung und Kategorisierung basierend auf
Wahrscheinlichkeiten - Beispiele: Medizinische Diagnose,
Kreditbewertung, Bilderkennung

**Generative KI:** - Erzeugt neue Inhalte - *"Wichtiger Unterschied, der
nicht allen immer so klar ist"* - Fokus auf plausible Ausgaben, nicht
auf Wahrheit

**KI-Agenten:** - Komplexere AblÃ¤ufe mit PlanungsfÃ¤higkeiten -
Kooperation mit anderen Agenten - Tool-Verwendung fÃ¼r komplexe Aufgaben

### Warum KI-Sicherheit jetzt wichtig ist

Laugwitz argumentierte mit drei HauptgrÃ¼nden fÃ¼r die Dringlichkeit des
Themas:

#### Dynamische Systementwicklung

*"Das Weiterentwickeln von den Systemen durch Daten und Erfahrungen
fÃ¼hrt halt dazu, dass es eine Dynamik gibt, dass die Systeme nicht
einfach so sind, wie man so fertig programmiert hat, ausgeliefert hat
und dann sind sie so sicher und robust bis zum nÃ¤chsten Upgrade, sondern
man muss es eben im Auge behalten."*

#### Skalierungseffekte

Die Referentin nutzte die Automobilgeschichte als Metapher: *"Das ist
das einzige Auto, was auÃŸerhalb von Mannheim da herumfÃ¤hrt. Das einzige
Auto, das da herumfÃ¤hrt, ist jetzt noch mal kein groÃŸes Risiko fÃ¼r
andere Menschen, fÃ¼r die Umwelt. Es stellt kein groÃŸes Risiko dar. Es
wurden es aber mehr und immer mehr. Und jetzt heute sind es mehr als
eine Milliarde Autos, Kraftfahrzeuge, die in diesem Moment auf der
Weltkugel herumfahren."*

Sie wagte die *"steile These, dass kÃ¼nstliche Intelligenz, so wie wir es
jetzt heute erleben, Ã¤hnlich disruptiv sein kann wie diese Technologie.
Mit groÃŸen Auswirkungen. Das Tempo ist atemberaubend und deswegen auch
sehr wichtig, ein Auge drauf zu haben."*

#### Begrenzte KI-Literacy und Bias-Problematik

Anhand praktischer Beispiele demonstrierte Laugwitz die Grenzen
aktueller KI-Systeme:

- Mangelndes Weltwissen: Generierung unrealistischer Bilder (zerbrochene
  Eier)
- Gesellschaftliche Verzerrungen: Gender-Bias bei Berufsdarstellungen
  (Arzt vs.Â Krankenschwester)

*"Also in den Daten gibt es eine Verzerrung, die sind Jahrzehnte alt,
spiegelt vielleicht eine gesellschaftliche RealitÃ¤t von vor 30, 40
Jahren wieder, aber auch nicht reprÃ¤sentativ und so weiter."*

### SAPs Responsible AI Framework

Laugwitz prÃ¤sentierte SAPs dreisÃ¤uliges Modell fÃ¼r verantwortungsvolle
KI:

#### KI-Compliance

- Einhaltung globaler Vorschriften und Gesetze
- Anpassung an verschiedene RechtsrÃ¤ume

#### KI-Sicherheit

- Robuste Implementierung
- Schutz vor Manipulation und Hacking
- ZuverlÃ¤ssige Funktionsweise

#### KI-Ethik

- Ethische Prinzipien fÃ¼r gute KI-Systeme
- VerantwortungsÃ¼bernahme fÃ¼r Systemverhalten

### Organisatorische Umsetzung bei SAP

Die Referentin betonte SAPs langjÃ¤hrige Expertise: *"Das Thema ist schon
wirklich ganz lange bei uns ein wichtiges Thema und hat sich Ã¼ber die
letzten Jahre aufgebaut und ausgebaut, sodass wir jetzt ein groÃŸes,
hohes Level an Organisational Maturity haben, was das Thema KI-Ethik
betrifft."*

**Strukturelle Elemente:** - Global AI Ethics Policy mit definierten
Rollen und Verantwortlichkeiten - KI-Ethik-Bewertungsprozess in der
Produktentwicklung - Online-Kurse fÃ¼r Mitarbeiterbildung -
Kontinuierliche Risikoanalyse und -minimierung

### Drei Kernanforderungen ethischer KI

#### Menschliche Kontrolle und Selbstbestimmung

*"Es geht immer darum, dass der Mensch die Maschine unter Kontrolle hat
und nicht umgekehrt."* Die Referentin betonte die Bedeutung von "Human
in the Loop"-Konzepten und die bewusste Entscheidung, an welchen Stellen
menschliche Intervention erforderlich ist.

#### Fairness und Nichtdiskriminierung

Besonders relevant in HR-Anwendungen, um Verzerrungen bei
Bewerbungsverfahren zu vermeiden. Die systematische Analyse und
Korrektur von Bias in Trainingsdaten und Algorithmen steht im Fokus.

#### Transparenz und ErklÃ¤rbarkeit

*"Da geht es darum, dass Menschen die MÃ¶glichkeit haben mÃ¼ssen zu
verstehen, was macht die Maschine jetzt eigentlich, so gut es halt
geht."* Obwohl KI-Systeme oft als Blackbox funktionieren, mÃ¼ssen
Methoden entwickelt werden, um: - Systemverantwortlichen Einblicke in
die Funktionsweise zu geben - Anwendern die Bewertung von
KI-Empfehlungen zu ermÃ¶glichen - Fachexperten die Validierung von
Ergebnissen zu erlauben

### Handlungsempfehlungen und Call to Actions

#### FÃ¼r Organisationen

- **Aufbau organisatorischer Strukturen:** Etablierung von Rollen,
  Verantwortlichkeiten und Prozessen fÃ¼r KI-Ethik
- **Implementierung von Bewertungsprozessen:** Systematische
  Risikoanalyse bereits in der Konzeptionsphase von KI-Anwendungen
- **Kontinuierliche Weiterbildung:** Aufbau von KI-Literacy in der
  gesamten Organisation

#### FÃ¼r Entwickler und Produktteams

- **FrÃ¼hzeitige Ethik-Integration:** *"Wenn man eine Anwendung
  definiert, sich Ã¼berlegt, in welche Anwendung wollen wir denn KI mit
  einbauen, dass man sich da schon darÃ¼ber Gedanken macht, was kÃ¶nnten
  Risiken sein"*
- **Human-in-the-Loop Design:** Bewusste Entscheidungen Ã¼ber
  Automatisierungsgrade
- **Transparenz-Features:** Entwicklung erklÃ¤rbarer KI-Funktionen

#### FÃ¼r die Gesellschaft

- **Wachsamkeit bewahren:** *"Warum sollten wir also wachsam bleiben"* -
  kontinuierliche Beobachtung der KI-Entwicklung
- **KI-Literacy fÃ¶rdern:** Verbesserung des allgemeinen VerstÃ¤ndnisses
  fÃ¼r KI-Technologien und deren Grenzen
- **Ethische Standards entwickeln:** Partizipation an gesellschaftlichen
  Diskussionen Ã¼ber KI-Ethik

#### Spezifische Ressourcen-Empfehlungen

Laugwitz verwies mehrfach auf konkrete Hilfsmittel: - **SAP Responsible
AI Website:** Umfassende Dokumentation und Downloads - **AI Ethics
Handbook:** Praktischer Leitfaden fÃ¼r die Implementierung -
**Online-Kurse:** Strukturierte WeiterbildungsmÃ¶glichkeiten -
**UNESCO-Empfehlungen:** Internationale Standards als Orientierung

### Historische Parallelen und Zukunftsperspektiven

Die durchgÃ¤ngige Analogie zur Automobilentwicklung verdeutlichte
wichtige Prinzipien:

**Innovation vor Regulation:** Wie der Dreipunkt-Sicherheitsgurt 1959
erfunden und erst 1973 gesetzlich vorgeschrieben wurde, entstehen auch
bei KI oft technische LÃ¶sungen vor rechtlichen Rahmen.

**Schrittweise Sicherheitsverbesserungen:** Von Sicherheitsglas in den
1920ern bis zu modernen Fahrassistenzsystemen zeigt sich, wie
kontinuierliche Innovation Sicherheitsstandards verbessert.

**Gesellschaftliche Transformation:** Die Entwicklung von einem
einzelnen Motorwagen zu Ã¼ber einer Milliarde Fahrzeugen verÃ¤nderte
Gesellschaft, Gesetze und Technologie fundamental - ein Muster, das sich
bei KI wiederholen kÃ¶nnte.

Der Vortrag schloss mit einem optimistischen Ausblick: *"Das Thema ist
so spannend und so interessant. Ich bin jeden Tag sehr begeistert und
beglÃ¼ckt, dass ich daran arbeiten darf, weil es auch so vielfÃ¤ltig ist
und gleichzeitig auch so relevant."*

Diese Begeisterung fÃ¼r das Thema, kombiniert mit praktischen
LÃ¶sungsansÃ¤tzen und klaren Handlungsempfehlungen, machte deutlich, dass
KI-Sicherheit nicht nur eine technische Herausforderung, sondern eine
gesellschaftliche Gestaltungsaufgabe ist, die proaktives Handeln aller
Beteiligten erfordert.

# Lightning Talks

## Nele Hirsch - Modellierung als 'Mind the knowledge gap'-Ansatz bei der Interaktion mit KI-Sprachmodellen

> Der Ansatz der Modellierung (= sich seiner eigenen mentalen Modelle
> bewusst werden, diese reflektieren und weiter entwickeln) kann sehr
> gut als Grundlage zur Interaktion mit KI-Sprachmodellen genutzt
> werden. Auf diese Weise wird ausgehend von bestehendem Wissen in
> Interaktion mit KI-Sprachmodellen weiter gelernt. Ich werde
> vorstellen, wie das praktisch aussehen kann und von meinen Erfahrungen
> mit dem Ansatz berichten.

### Zusammenfassung des Vortrags: Modellierung als pÃ¤dagogisches Konzept im KI-Zeitalter

Nele Hirsch prÃ¤sentiert in ihrem kompakten 5-Minuten-Vortrag das
pÃ¤dagogische Konzept der Modellierung als Antwort auf die
Herausforderungen, die KI-Sprachmodelle fÃ¼r das Lernen mit sich bringen.
Sie argumentiert, dass technologische Fortschritte wie ChatGPT zwar
beeindruckend sind, aber ohne bewusste Lernprozesse keine Menschen
klÃ¼ger machen. Die Modellierung bietet einen strukturierten Ansatz, um
KI-Tools sinnvoll in Lernprozesse zu integrieren und dabei echtes
VerstÃ¤ndnis zu fÃ¶rdern.

### Aufbau und Gliederung des Vortrags

Der Vortrag folgt einer klaren, dreiteiligen Struktur:

1.  **Problemstellung**: Die Gefahr oberflÃ¤chlicher KI-Nutzung ohne
    echten Lerngewinn
2.  **LÃ¶sungsansatz**: Das Drei-Schritte-Modell der Modellierung
3.  **Praktische Anwendung**: Konkrete Umsetzung am Beispiel einer
    Mindmap zu Mobile Learning

### Die Kernproblematik: Technologischer Fortschritt ohne menschlichen Lerngewinn

Hirsch erÃ¶ffnet ihren Vortrag mit einer kritischen Betrachtung der
Ã¶ffentlichen Wahrnehmung von KI-Erfolgen. Sie bezieht sich auf
Schlagzeilen wie *"ChatGPT besteht jetzt sogar das bayerische Abitur"*
und stellt die zentrale Frage: *"Wenn ChatGPT oder irgendein anderes
KI-Sprachmodell irgendwas Tolles hinkriegt, dann ist davon ja noch kein
einziger Mensch schlauer, klÃ¼ger, kompetenter, fÃ¤higer geworden."*

Diese Kernaussage verdeutlicht das fundamentale Problem im Umgang mit
KI-Technologien im Bildungsbereich:

- Technologische Leistungen werden oft als Selbstzweck gefeiert
- Der eigentliche Bildungsauftrag - Menschen zu befÃ¤higen - gerÃ¤t aus
  dem Blick
- Es besteht die Gefahr, dass KI-Tools zu passivem Konsumverhalten
  fÃ¼hren

### Das Drei-Schritte-Modell der Modellierung

Hirsch prÃ¤sentiert die Modellierung als bewÃ¤hrtes pÃ¤dagogisches Konzept,
das sich besonders gut fÃ¼r die Integration von KI eignet. Das Modell
umfasst drei aufeinander aufbauende Schritte:

#### Schritt 1: Externalisierung des vorhandenen Wissens

*"Man geht so vor, dass man als erstes sagt, was habe ich Ã¼berhaupt in
meinem Kopf und versucht es zu externalisieren. Also irgendwie fÃ¼r sich,
fÃ¼r andere sichtbar zu machen."*

Dieser erste Schritt ist fundamental wichtig, da er:

- Das bereits vorhandene Wissen bewusst macht
- Eine Basis fÃ¼r weitere Lernprozesse schafft
- Verhindert, dass Lernende von externen Informationen Ã¼berwÃ¤ltigt
  werden

#### Schritt 2: Bearbeitung und Weiterentwicklung

*"Der wirkliche Lernprozess ist dann dieses, dass ich an diesem, was ich
externalisiert habe, so ein bisschen rumbasteln kann."*

In diesem Schritt findet der eigentliche Lernprozess statt:

- Aktive Auseinandersetzung mit dem externalisierten Wissen
- Experimentieren und Anpassen
- Iterative Verbesserung durch Trial-and-Error

#### Schritt 3: Reflexion und Metakognition

*"Im dritten Schritt versuche ich dann natÃ¼rlich noch zu reflektieren,
also wie passte das jetzt, wie habe ich gelernt, wie kÃ¶nnte ich das das
nÃ¤chste Mal vielleicht noch schlauer machen."*

Die Reflexionsphase ermÃ¶glicht:

- Bewertung des Lernprozesses
- Entwicklung von Strategien fÃ¼r zukÃ¼nftiges Lernen
- FÃ¶rderung metakognitiver FÃ¤higkeiten

### Veranschaulichung durch praktische Beispiele

Hirsch macht das abstrakte Konzept durch konkrete Beispiele greifbar:
*"Man kann sich das Ganze ziemlich gut, quasi plastisch vorstellen, wenn
man es so mit praktischen, konkreten Sachen zu tun hat. Also sowas wie,
ich will jetzt irgendwie einen kleinen Stromkreislauf aufbauen oder ich
will eine BrÃ¼cke bauen."*

Diese Beispiele verdeutlichen:

- Den iterativen Charakter des Lernprozesses
- Die Bedeutung des Scheiterns als Lernchance
- Die Notwendigkeit praktischer Erprobung

### Die besondere Relevanz fÃ¼r KI-gestÃ¼tztes Lernen

Hirsch identifiziert eine spezifische Gefahr beim Einsatz von
KI-Sprachmodellen: *"Die ganz, ganz groÃŸe Gefahr bei KI-Sprachmodellen
liegt aus einer pÃ¤dagogischen Perspektive ja daran, dass wir verleitet
werden, eher AbkÃ¼rzungen zu machen und so ein bisschen auch verleitet
werden, wow, da ist das riesige Wissen, was da eigentlich drinnen liegt
und ich kann einfach klick, klick, klick, klick und das wird mir alles
so ein bisschen zugeworfen."*

Diese Analyse zeigt verschiedene Problembereiche auf:

- VerfÃ¼hrung zur oberflÃ¤chlichen Nutzung
- ÃœberwÃ¤ltigung durch die InformationsfÃ¼lle
- Mangelnde VerknÃ¼pfung mit vorhandenem Wissen
- Passive Konsumhaltung statt aktiver Auseinandersetzung

### LÃ¶sungsansatz: KI als Sparring Partner

Die Modellierung bietet einen Weg, KI-Tools konstruktiv zu nutzen:
*"Damit ich wirklich was damit anfangen kann, muss ich das ja verknÃ¼pfen
und vernetzen mit dem, was ich schon in meinem Kopf habe."*

Hirsch schlÃ¤gt vor, KI in allen drei Phasen der Modellierung
einzusetzen:

- **Externalisierung**: KI hilft beim Bewusstmachen des eigenen Wissens
- **Bearbeitung**: KI fungiert als Sparring Partner fÃ¼r die
  Weiterentwicklung
- **Reflexion**: KI unterstÃ¼tzt bei der Bewertung des Lernprozesses

### Praktisches Beispiel: Mobile Learning Mindmap

Hirsch demonstriert die Anwendung anhand eines konkreten Projekts: *"Ich
habe es hier versucht, indem ich einfach mal gesagt habe, okay, was weiÃŸ
ich denn zu Mobile Learning? Da wollte ich ein kleines Lernangebot dazu
gestalten und habe einfach darum umgeschrieben, was fÃ¤llt mir dazu
ein."*

Der Prozess gliederte sich wie folgt:

1.  **Analoge Externalisierung**: Erstellen einer handschriftlichen
    Mindmap
2.  **Digitale Bearbeitung**: Eingabe in ein KI-Sprachmodell
3.  **Gezielter Dialog**: Spezifische Nachfragen zu einzelnen Bereichen
4.  **ErgÃ¤nzung**: Integration der KI-RÃ¼ckmeldungen in die ursprÃ¼ngliche
    Struktur

### Alternative Externalisierungsmethoden

Hirsch erwÃ¤hnt verschiedene MÃ¶glichkeiten der Externalisierung:

- Mindmaps (wie im Beispiel gezeigt)
- Storytelling-AnsÃ¤tze
- Thesenformulierung
- Entwicklung eigener KI-gestÃ¼tzter Lernwerkzeuge

Besonders interessant ist ihr Hinweis auf die Entwicklung
maÃŸgeschneiderter Lerntools: *"Richtig cool wird es dann, wenn ich gar
nicht in diesem klassischen Chatbot-Ding drinnen bleibe, sondern zum
Beispiel KI-Sprachmodelle auch nutze, um mir gezielt ein Lernwerkzeug zu
entwickeln."*

### Vorteile des analogen Starts

Ein wichtiger Aspekt ist Hirschs PrÃ¤ferenz fÃ¼r den analogen Beginn:
*"Ich mache das gerne, dass ich den ersten Schritt mit der
Externalisierung tatsÃ¤chlich so mache, dass ich das noch gar nicht
digital mache und lieber Ewa sowas aufzeichne."*

Diese Herangehensweise bietet mehrere Vorteile:

- UngestÃ¶rte Reflexion ohne technische Ablenkung
- FÃ¶rderung der kreativen Denkprozesse
- Bewusste Abgrenzung zwischen eigenem und KI-generiertem Wissen
- Haptisches Lernerlebnis

### Strategien fÃ¼r effektive KI-Nutzung

Hirsch betont die Bedeutung gezielter Interaktion mit KI-Systemen: *"In
den einzelnen Bereichen ganz gezielt chatten, also sagen, schau doch
mal, was ich als Definition festgelegt habe, was sagst du denn da dazu,
was sagst du zu meinen Herausforderungen, was fÃ¤llt dir da sonst noch
ein."*

Diese Strategie umfasst:

- Spezifische statt allgemeine Anfragen
- Aufbau auf bereits externalisiertem Wissen
- Kritische Auseinandersetzung mit KI-Antworten
- Iterative Verfeinerung der Ergebnisse

### Metakognitive Reflexion als SchlÃ¼sselkompetenz

Ein zentraler Aspekt der Modellierung ist die abschlieÃŸende Reflexion:
*"Ich kann am Ende diesen Lernprozess und auch die KI-Nutzung
reflektieren und damit dann auch nochmal schlauer werden."*

Diese Reflexionsebene ermÃ¶glicht:

- Bewertung der EffektivitÃ¤t des gewÃ¤hlten Vorgehens
- Identifikation von VerbesserungsmÃ¶glichkeiten
- Entwicklung persÃ¶nlicher Lernstrategien
- Kritische Bewertung der KI-UnterstÃ¼tzung

### Handlungsempfehlungen und Call to Actions

Aus dem Vortrag lassen sich folgende konkrete Handlungsempfehlungen
ableiten:

#### FÃ¼r Lehrende und Bildungsverantwortliche

- Implementierung des Drei-Schritte-Modells der Modellierung in
  KI-gestÃ¼tzte Lernprozesse
- FÃ¶rderung der bewussten Externalisierung von Vorwissen vor KI-Nutzung
- Schulung im kritischen Umgang mit KI-generierten Inhalten
- Entwicklung von Reflexionskompetenzen bei Lernenden

#### FÃ¼r Lernende

- Bewusste Anwendung der Modellierungsstrategie bei KI-Nutzung
- Widerstand gegen die VerfÃ¼hrung zu oberflÃ¤chlichen "AbkÃ¼rzungen"
- Aktive VerknÃ¼pfung von KI-Inhalten mit eigenem Vorwissen
- RegelmÃ¤ÃŸige Reflexion Ã¼ber Lernprozesse und KI-Nutzung

#### FÃ¼r Bildungseinrichtungen

- Integration der Modellierungsprinzipien in Curricula
- Bereitstellung von Ressourcen fÃ¼r analoge Externalisierungsprozesse
- Schulung von LehrkrÃ¤ften in pÃ¤dagogisch sinnvoller KI-Integration
- Entwicklung von Bewertungskriterien fÃ¼r KI-gestÃ¼tzte Lernprozesse

### Ausblick und Potenziale

Hirsch schlieÃŸt mit einem optimistischen Ausblick: *"Modellierung kann
ich empfehlen als ein Ansatz."* Dieser Ansatz bietet Potenziale fÃ¼r:

- Nachhaltigere Lernprozesse durch bewusste WissensverknÃ¼pfung
- Entwicklung kritischer Medienkompetenz im Umgang mit KI
- FÃ¶rderung selbstregulierter Lernprozesse
- PrÃ¤ventive MaÃŸnahmen gegen oberflÃ¤chliche KI-Nutzung

### Fazit: Ein bewÃ¤hrtes Konzept fÃ¼r neue Herausforderungen

Hirschs Vortrag zeigt eindrucksvoll, wie etablierte pÃ¤dagogische
Konzepte neue Relevanz im digitalen Zeitalter gewinnen kÃ¶nnen. Die
Modellierung erweist sich als praktikables Instrument, um die Potenziale
von KI-Technologien zu nutzen, ohne dabei die Gefahr oberflÃ¤chlicher
Nutzung zu Ã¼bersehen.

Der Ansatz ist besonders wertvoll, weil er:

- Auf bewÃ¤hrten pÃ¤dagogischen Prinzipien aufbaut
- Konkrete Handlungsschritte bietet
- Sowohl fÃ¼r Lehrende als auch Lernende anwendbar ist
- Die Balance zwischen technologischer Innovation und pÃ¤dagogischer
  Verantwortung wahrt

Die Kernbotschaft des Vortrags lÃ¤sst sich zusammenfassen als Aufruf zu
einem bewussten, reflektierten Umgang mit KI-Technologien, bei dem das
menschliche Lernen und Verstehen im Mittelpunkt steht. Nur so kann
verhindert werden, dass beeindruckende technologische Fortschritte zu
einer Verarmung echter Bildungsprozesse fÃ¼hren.

## Thomas Jenewein: Von WissenslÃ¼cken zu VerÃ¤nderungserfolg -- Wie Change Management Wissen und Emotionen verbindet

> Change Management minimiert Risiken und WiderstÃ¤nde, fÃ¶rdert die
> Akzeptanz bei den Mitarbeitern und stellt sicher, dass VerÃ¤nderungen
> nachhaltig und erfolgreich umgesetzt werden kÃ¶nnen. Wir schauen auf
> die wesentlichen Praktiken anhand des neuen lernOS Leitfadens.

## Oliver Fischer: Selbstorganisation zum Anfassen -- Was Teams wirklich stark macht

> Was haben Kommunikation, Kontrolle und KollegialitÃ¤t gemeinsam? Sie
> gehÃ¶ren zu den sechs Dimensionen, mit denen wir bei der LV 1871 die
> Selbstorganisation unserer Teams sichtbar machen. In diesem
> 5-Minuten-Impuls zeige ich, wie ein einfaches Modell echte Aha-Momente
> erzeugen kann -- nicht nur im Team, sondern auch bei FÃ¼hrungskrÃ¤ften
> und im Change-Prozess. Wer wissen will, wie sich agile Reife nicht nur
> fÃ¼hlen, sondern auch messen lÃ¤sst, sollte am nÃ¤chsten Tag unbedingt
> beim ausfÃ¼hrlichen Vortrag vorbeischauen. Plus: Das Modell gibt's fÃ¼r
> Neugierige auch zum Ausprobieren.

## Victoria KÃ¶stner: Mind the Knowledge Gap -- are your lessons really learned?

> Viele Projekte dokumentieren Erkenntnisse -- aber lernen sie auch
> daraus? In diesem Lightning Talk zeige ich, warum Lessons Learned oft
> ins Leere laufen und wie kollektives Lernen mit dem Projekt-Trialog
> gelingt.

## Daniel Prial: KI: ÃœberbrÃ¼cken wir die Kommunikations-Gaps oder klingen wir alle wie Roboter?

> Bringt uns KI als Menschen nÃ¤her zusammen oder treibt sie uns weiter
> auseinander? Einer der grÃ¶ÃŸten AnwendungsfÃ¤lle fÃ¼r KI-basierte LLM ist
> das Ãœbersetzen und Verbessern des Schreibens. Dies wirft eine
> tiefgreifende Frage Ã¼ber die Auswirkungen von KI auf die menschliche
> Kommunikation auf. Verbessert KI das VerstÃ¤ndnis und Ã¼berbrÃ¼ckt die
> Kommunikations-Gaps zwischen Kolleg\*Innen, die Ã¼ber Sprachgrenzen
> hinweg sprechen, oder nimmt sie die AuthentizitÃ¤t unserer Fehler und
> MissverstÃ¤ndnisse weg? Verbinden wir uns mehr auf der Welt, oder
> klingen wir alle wie Klone von ChatGPT? So erstaunlich diese
> Technologie auch ist, die Frage bleibt bestehen.

## Jan Bretschneider: WissenslÃ¼cken schlieÃŸen durchs LÃ¶sen von Problemen

> Ausgehend von Gerd Wohlands Definition eines Problem, will ich zeigen,
> dass Probleme auch WissenslÃ¼cken sind. Methodisches Vorgehen kann uns
> helfen, diese LÃ¼cken zu schlieÃŸen.

## Felix Harling: Was Organisationen von Pilzen lernen kÃ¶nnen.

> Wer Peer Learning Enthusiast:in in einer Organisation ist, fÃ¼hlst sich
> sicher manchmal als Untergrund-Agent:in. Was kÃ¶nnen wir von den
> Untergrund-Stars - den Pilzen - lernen? Inspiriert von "Verwobenes
> Leben" (Merlin Sheldrake) ist dieser Lightning Talk ein PlÃ¤doyer fÃ¼r
> WissensÃ¶kologie. Mit einem Augenzwinkern - und drei Fragen fÃ¼r alle,
> die tiefer graben wollen. Dieser Talk ist ein Ergebnis aus meiner
> Lernreise mit dem Zettelkasten Leitfaden.

## Harald Schirmer: The Knowledge Gap in Management

> Der Pitch zur Session - je weiter oben in der Karriere, je Ã¤lter, um
> so weniger Zeit und Lernlust im Management ... wir werfen einen Blick
> auf eine "Referenzgruppe" - das globale GUIDE Netzwerk und
> vergleichen.

## Dajana Prellwitz: WissenslÃ¼cken fÃ¼llt man nicht mit Tools -- Wissensmanagement neu gedacht bei NETZSCH

> Wie gelingt es, WissenslÃ¼cken in einem internationalen
> Industrieunternehmen systematisch zu schlieÃŸen -- und dabei nicht nur
> Tools, sondern vor allem Kultur zu verÃ¤ndern? In diesem Lightning Talk
> gibt Dajana Prellwitz Einblicke in das Strategieprojekt â€žKnowledge
> Culture" der NETZSCH-Gruppe -- mit Blick auf die Roadmap, erste
> Umsetzungsschritte und die Herausforderungen auf dem Weg zu einer
> gelebten Wissenskultur.

## Armin Zoike: Mind the AI Gap: Warum dokmentiertes Wissen das wichtigste Asset im KI-Zeitalter ist und wie man es einfach aufbaut

> Das bestehenden AnsÃ¤tze zum Wissensmanagement es nur begrenzt schaffen
> Wissen aus den KÃ¶pfen von Mitarbeitern zu digitalisieren, fÃ¼hrt nicht
> nur zu direkten ProduktivitÃ¤tsverlusten durch Wissensverlust,
> Wissenssilos und verlorener Zeit bei der Suche und beim Teilen von
> Informationen, sondern bedroht fundamental die WettbewerbsfÃ¤higkeit
> von Unternehmen im KI-Zeitalter. Ich gehe kurz darauf ein warum
> Unternehmen nur in dem MaÃŸe von KI profitieren kÃ¶nnen, in dem sie
> dieser ihr Wissen digital dokumentiert zur VerfÃ¼gung stellen kÃ¶nnen
> und zeige dann auf wie das am effektivsten gelingt.

# Sessions & Workshops

## Narcel Kirchner, Thomas Schmidt: Never Prompt Alone! Erfahrungsbericht zum globalen Einsatz des lernOS KI-Leitfadens

> Nachdem wir im vergangenen Jahr den lernOS KI-Leitfaden neben dem
> offenen KI-MOOC auch bei Continental intern mit etwa 200 KollegInnen
> pilotieren konnten, durften wir diesen von Januar bis Mai 2025 in
> enger Zusammenarbeit von IT, Communications und Learning allen
> anbieten. Das (e)skalierte gleich mal richtig und so konnten wir die
> Lernreise nun mit Ã¼ber 3.000 Interessierten durchfÃ¼hren. Was dabei
> alles zu beachten war, wie der Leitfaden ankam, was fÃ¼r eine besondere
> Prompting Challenge wir zum Abschluss mit allen durchgefÃ¼hrt haben und
> welche Lessons Learned wir daraus ziehen konnten, wollen wir Euch hier
> einmal vorstellen. Gerne mÃ¶chten wir uns auch mit Euch Ã¼ber
> vergleichbare KI-Upskilling MaÃŸnahmen und aktuelle WissenslÃ¼cken im
> Leitfaden austauschen.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

## Magnus Rode, Daniel Prial: The Human & Artificial Intelligence Gap -- Impact der KI auf die (digitale) Zusammenarbeit

> In dieser Session diskutieren wir, ob KÃ¼nstliche Intelligenz (KI) uns
> dabei hilft, besser (digital) zusammenzuarbeiten, oder ob sie uns
> menschlich weiter auseinanderbringt. Ein zentrales Thema ist die
> Eigenverantwortung: Wie gehen wir damit um?

## Susann Schulz: Mind the Diversity Gap: Wie KI unsere blinden Flecken re(pro)duziert

> KÃ¼nstliche Intelligenz reproduziert unseren Bias nicht nur -- sie
> verstÃ¤rkt ihn sogar. Gleichzeitig kann sie helfen, diese blinden
> Flecken sichtbar zu machen. In dieser interaktiven Session analysieren
> wir KI-generierte Texte und Bilder, reflektieren Ã¼ber fehlende
> Perspektiven und erproben, wie wir durch bewusste Beschreibungen und
> gezielte Perspektivwechsel vielfÃ¤ltigere, inklusivere Darstellungen
> anstoÃŸen kÃ¶nnen. Gemeinsam nÃ¤hern wir uns dem Diversity Gap -- und
> werfen einen bewussten Blick auf das, was oft Ã¼bersehen wird.

## BjÃ¶rn Schotte: Der groÃŸe Technologie-Struktur-Gap: Warum KI nicht an Technologie, sondern an Strukturen scheitert

> KI verÃ¤ndert radikal, wie Produkte entstehen: Hypothesen werden aus
> Daten generiert, funktionierender Programmcode entsteht automatisch on
> the fly, Prototypen werden live validiert, und Entscheidungen durch KI
> vorbereitet und ausgelÃ¶st -- ohne, dass Teams klassisch â€žarbeiten"
> mÃ¼ssen. Wir erleben den Aufstieg hyperautomatisierter Produktarbeit,
> ermÃ¶glicht durch Agentic Meshes (dynamisch koordinierte Netzwerke
> spezialisierter KI-Agenten), adaptive Systeme und kontinuierlich
> ablaufende Feedback- und Release-Schleifen. Doch wÃ¤hrend die
> Technologie lÃ¤ngst bereit ist, bleibt eine Sache zurÃ¼ck: die
> Organisation selbst. In traditionellen Strukturen stoÃŸen AI-first
> AnsÃ¤tze schnell an Grenzen -- sei es durch Rollenbilder,
> Freigabeprozesse oder das vorherrschende, durch KI sehr schnell
> veraltende VerstÃ¤ndnis von Produktarbeit. Die eigentliche Limitierung
> ist nicht mehr technologisch -- sie ist strukturell: Die Organisation
> und ihre Architektur sind nicht dafÃ¼r gebaut, mit KI Schritt zu
> halten. Und wer das nicht erkennt, wird nicht nur ausgebremst --
> sondern verliert den Anschluss. Relevanz, Innovationskraft und
> EntscheidungsfÃ¤higkeit stehen auf dem Spiel. KI verÃ¤ndert das
> Spielfeld -- und Organisationen, die sich nicht mitverÃ¤ndern, werden
> ersetzt. In dieser Session wird zeigt, warum es nicht reicht, KI-Tools
> einzufÃ¼hren oder Prozesse zu modernisieren. Nur wer auch die
> Organisation neu denkt -- ihre Struktur, Schnittstellen,
> Entscheidungswege -- wird das Potenzial von KI wirklich freisetzen.
> Mit Beispielen aus der Praxis wird deutlich, wie dieser Wandel
> gelingt, bevor das eigene Setup zum Bremsklotz wird -- oder einen
> Ã¼berrollt.

## Simone Engelhard, Simon Qualmann: Der Working-Learning Gap -- Zwischen Alltagsstress und Lernanspruch

> Wir glauben: Wer sich im Job weiterentwickeln soll, braucht mehr als
> gute Inhalte -- nÃ¤mlich Zeit, Struktur und Motivation. In dieser
> Session nehmen wir den Working-Learning Gap unter die Lupe: die LÃ¼cke
> zwischen dem Wunsch nach Weiterbildung und den realen MÃ¶glichkeiten im
> Arbeitsalltag. Wie viel Zeit fÃ¼rs Lernen ist realistisch -- und wie
> viel wird erwartet? Welche Formate helfen wirklich weiter, ohne
> zusÃ¤tzlich zu belasten? Und was motiviert Menschen Ã¼berhaupt, sich mit
> Freude weiterzubilden? Gemeinsam wollen wir LÃ¶sungen finden, wie
> Lernen im Alltag gelingt -- ohne Druck, sondern mit klugen Formaten,
> passenden Medien und einer realistischen Dosierung.

## Oliver Fischer: Selbstorganisation sichtbar machen -- Praxiserfahrungen mit dem 6K-Modell der LV 1871

> Wie selbstorganisiert arbeiten unsere Teams wirklich -- und wie kÃ¶nnen
> wir das zuverlÃ¤ssig messen? Bei der LV 1871 setzen wir seit drei
> Jahren das eigens entwickelte 6K-Modell ein, um den Reifegrad agiler
> Teams systematisch zu erfassen und weiterzuentwickeln. Anhand von
> sechs Dimensionen (Kompetenzen, KollegialitÃ¤t, Kommunikation,
> Kontrolle, Kooperation, Koordination) erfolgt eine regelmÃ¤ÃŸige Selbst-
> und FremdeinschÃ¤tzung, die eine wertvolle Grundlage fÃ¼r Teamdialoge,
> Reflexion und gezielte Entwicklung bietet. Der Vortrag zeigt, wie das
> Modell im Alltag eingesetzt wird, welche Erkenntnisse daraus gewonnen
> werden und welche Impulse es fÃ¼r die Teamentwicklung liefert.
> Interessierte Teilnehmende sind eingeladen, das Modell im eigenen
> Kontext zu verproben -- wir stellen dafÃ¼r Materialien und Begleitung
> zur VerfÃ¼gung.

## Martin Harnisch: Enterprise Wikis: Warum alle alles lesen und bearbeiten kÃ¶nnen sollten

> In vielen Organisationen sind Wikis stark eingeschrÃ¤nkt -- und bleiben
> damit unter ihren MÃ¶glichkeiten. In dieser Session zeige ich, warum
> ein offenes Wiki, in dem alle alles lesen und bearbeiten kÃ¶nnen, die
> Zusammenarbeit und den Wissenstransfer massiv verbessern kann. Wir
> sprechen Ã¼ber Vorteile, typische Bedenken und sinnvolle Grenzen -- und
> darÃ¼ber, wie ein Wiki zur lernenden Organisation beitrÃ¤gt.

## Andreas Trebing, Felix Harling: The Second Brain Gap - Sammelst du noch oder denkst du schon?

> Ein Diskurs Ã¼ber den Nutzen des Zettelkastens, um mehr aus deinem
> angesammelten Wissen zu machen.

## Promptathon

> Entwicklung und Optimierung von KI-Prompts fÃ¼r Herausforderungen und
> Use Cases in Weiterbildung und Change Management im SAP-Bereich.

# Podcasts

## Silvia Roderus: Expert Debriefing unplugged: Wissen strukturiert bewahren und weitergeben

> Wenn Mitarbeitende die Organisation verlassen, droht wertvolles Wissen
> verloren zu gehen. Der Expert Debriefing Prozess bietet hier einen
> strukturierten und moderierten Weg, dieses Wissen systematisch zu
> sichern und weiterzugeben - unterstÃ¼tzt durch geeignete Tools und
> GenAI (Generative KÃ¼nstliche Intelligenz). In diesem interaktiven
> Podcast beantworte ich deine Fragen zur praktischen Umsetzung des
> Prozesses. Lass uns Ã¼ber Erfahrungen, Herausforderungen und
> LÃ¶sungsansÃ¤tze sprechen.

## Gabriele Schobess, Katharina Nolden, Silvia Roderus: lernOS fÃ¼r gesellschaftliches Engagement und Beteiligung

> lernOS fÃ¼r gesellschaftliches Engagement und Beteiligung unterstÃ¼tzt
> Menschen dabei, ihre eigenen StÃ¤rken zu entdecken und sich aktiv in
> die Gestaltung unserer Gesellschaft einzubringen. In einer Zeit groÃŸer
> gesellschaftlicher Herausforderungen wollen wir Mut machen,
> Verantwortung zu Ã¼bernehmen und Demokratie sowie Vielfalt
> mitzugestalten. lernOS bietet Impulse, Reflexionsfragen und praxisnahe
> Werkzeuge, um aus eigener Motivation heraus aktiv zu werden. Dabei
> geht es nicht nur um groÃŸe Projekte -- auch kleine Schritte bewirken
> VerÃ¤nderung. Gemeinsam schaffen wir RÃ¤ume fÃ¼r Beteiligung, in denen
> Hoffnung und Zusammenhalt wachsen kÃ¶nnen

## Simon DÃ¼ckert, Christian Kaiser: Peer Learning groÃŸ machen - wie wir das selbstorganisierte Lernen als neues Normal etablieren (wollen)

> Beim Corporate Learning MOOC (clmooc24) und beim Corporate Learning
> Camp gab es Sessions zum Thema Peer Learning groÃŸ denken mit dem Ziel
> eine Allianz zu grÃ¼nden, die mit Peer Learning Wissen und Erfahrungen
> Ã¼ber Unternehmensgrenzen hinweg Ã¼bertrÃ¤gt. In diesem Podcast wollen
> wir darÃ¼ber sprechen, ob und wie das gelingt und welche Barrieren und
> WissenslÃ¼cken es zu Ã¼berwinden gibt. Simon wird einen kurzen Ãœberblick
> Ã¼ber die bisherigen AktivitÃ¤ten geben und Christian Ã¼ber die
> Praxiserfahrungen bei DATEV berichten. Danach kÃ¶nnen sich alle mit
> ihren Gedanken einbringen. Fokus liegt auf der praktischen
> Umsetzbarkeit und welche Rolle die lernOS Community dabei spielen
> kann. Wir haben die Inhalte der bisherigen Session in maschinenlesbare
> Form gebracht und daraus einen Peer Learning Bot als CustomGPT gebaut.
> So kÃ¶nnt ihr euch vorab mit dem bisherigen Diskussionsstand vertraut
> machen. FÃ¼r die Nutzung von CustomGPTs ist ein kostenpflichtiges Konto
> notwendig. Wenn ihr das nicht habt, kÃ¶nnt ihr auch diese Markdowndatei
> herunterladen und in das KI-Tool eurer Wahl hochladen (Coplilot,
> Gemini, LeChat etc.).

## Oliver Grobs, Tobias Gerndt: Sharing is Caring - Teilen macht reich

> Viele Menschen in den groÃŸen Organisationen glauben immer noch, das
> ihr Wissen einzigartig ist und sie durch ihre Erfahrung einzigartig
> und unersetzbar sind. Wir wollen uns Gedanken machen, wie wir diese
> Menschen dazu bewegen kÃ¶nnen, ihr Wissen gerne zu teilen und ihnen
> auch Wege zeigen, wie sie das bewerkstelligen.

# Anhang

## Dokumentation der KI-basierten Dokumentation

Falls jemand einen Ã¤hnlichen Ansatz der KI-basierten Dokumentation
verwenden mÃ¶chte, hier ein paar Informationen zu unserer Konfiguration:

1.  Alle Programmpunkte haben wir in Microsoft Teams (VortrÃ¤ge,
    Sessions) oder Discord/Reaper (Podcasts) aufgezeichnet (mp4, mp3).
2.  Die Aufzeichnungen haben wir mit Whisper auf einem Mac Mini M4
    transkribiert (txt).
3.  Die Transkripte haben wir mit einem Prompt (s.u.) in eine
    Dokumentation transformiert (md).
4.  Alle Dokumentationen haben wir in eine vorgefertigte Struktur in
    einem Github Repository kopiert
    ([github.com/cogneon/loscon25doku](github.com/cogneon/loscon25doku)).
5.  Mit der lernOS Produktionskette haben wir die Inhalte im Repository
    in eine [Web-Version](https://cogneon.github.io/loscon25doku/de) und
    weitere Download-Formate transformiert.

**Prompt:** folgt.
