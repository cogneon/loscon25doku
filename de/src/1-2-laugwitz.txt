Vielen Dank, Simon. Ich glaube, man kann mich schon hören. Gut. Simon hat mir freundlicherweise die Definition von KI-Agenten schon abgenommen. Da kann ich eine Minute sparen von meiner Präsentation. Ich spreche über das Thema AI Safety oder KI Ethik. Also es geht im Grunde darum, KI so zu gestalten und so zu entwickeln, dass es keinen Schaden anrichtet. Also dass sie nicht Menschen, Umwelt, gesellschaftliche Beeinträchtigungen erzeugt. So, ich beginne aber mit dieser disruptiven Technologie, wenn ich mal so sagen darf, aus dem Jahr 1888. Das ist der Benz Patentmotorwagen Nummer 3. Zwei Jahre vorher hatte er seinen ersten Motorwagen patentieren lassen und das ist jetzt die Version Nummer 3. Die hatte eine Serienreife und war aber irgendwie ein Ladenhüter. hat sich irgendwie noch nicht durchsetzen können, aus welchen Gründen auch immer. Und dann hat sich eines schönen Sommertags im Jahr 1888 seine Frau Bertha Benz, die ihn nicht nur moralisch und finanziell, sondern bestimmt auch mit Ideen unterstützt hat, überlegt oder beziehungsweise umgesetzt, mit dem Motorwagen mal ein Stück zu fahren. Hat zwei der gemeinsamen Söhne, Eugen und Richard, sich geschnappt, hat gesagt, so Jungs, wir fahren heute mal zu Oma und Opa und wir nehmen das Auto. Oma und Opa wohnten in Pforzheim, die Bensens in Mannheim, das sind gut 100 Kilometer. Das hat gut zehn Stunden gedauert, diese Fahrt. Auf der Fahrt ist einiges passiert, gab es einige Premieren. Also zum Beispiel ist ihnen dann der Treibstoff ausgegangen in Wiesloch bei Waldorf, was in der Nähe von SAP Hauptquartier ist. Und die Stadtapotheke in Wiesloch gilt damit als die erste Tankstelle der Geschichte. So, aber eigentlich reden wir ja über KI, KI-Sicherheit und KI-Ethik. Und was das miteinander zu tun hat, wird sich hoffentlich in den nächsten Minuten erschließen. Also ich beginne mit dem Was, worum geht es eigentlich bei KI-Sicherheit und KI-Ethik, wobei ich jetzt eigentlich AI Safety bevorzuge, weil im Englischen hat man die Unterscheidung Security, etwas ist sicher gebaut und Safety, etwas ist sicher zu verwenden. Und diese Unterscheidung ist im Deutschen ein bisschen schwierig. Aber wie gesagt, es geht darum, Schaden zu vermeiden. Worum geht es? Warum ist das jetzt wichtig? Und warum ist ausgerechnet jetzt wichtig? Und wie kann man das umsetzen? Also was ist KI-Sicherheit, AI Safety? Ich komme nochmal zurück zu dem Motorwagen oder zu dem Auto. Wenn wir am Straßenverkehr teilnehmen mit einem motorisierten oder anderen Gefährt oder auch zu Fuß, sollten wir uns so verhalten, dass wir Recht und Gesetz einhalten. Wir kennen hoffentlich die wesentlichen Teile der Straßenverkehrsordnung und halten uns dran nach Kräften. Jetzt wissen wir zum Beispiel daraus, dass wir an einer roten Ampel anhalten sollen. Es ist schon mal gut, das zu wissen und auch gut, das vorzuhaben. Wenn jetzt aber die Bremsen nicht funktionieren, hilft das auch nur bedingt. Deswegen, die Fahrzeuge, die Technologie muss verlässlich funktionieren. Das ist der zweite Baustein zum Thema Sicherheit und Kraftverkehr, oder Kraftfahrzeuge im Straßenverkehr. Und dann gibt es noch Aspekte, also weder die Technologie, die heute da ist, löst alles, was potenziell Probleme erzeugen kann. Noch deckt die Gesetzeslage alle Situationen ab, die man sich vorstellen kann oder die passieren können. Deswegen ist es wesentlich und eigentlich auch natürlich, dass wir auch mit ethischen Prinzipien am Straßenverkehr teilnehmen. Also sehr einfach. Wir versuchen, keinen Schaden anzurichten. Wir versuchen nicht, Leute zu schädigen oder Gegenstände zu zerstören. Also Rücksichtnahme als ein grundlegendes, breit gefasstes ethisches Prinzip. Ähnliches kann man auch für Sicherheit und künstliche Intelligenz sich überlegen. Also zum einen künstliche Intelligenzanwendungen müssen gelten, Gesetze einhalten, sollten robust sein, also sollten nicht gehackt werden können, sollten so funktionieren, wie sie gebaut worden sind und sollten ethische Prinzipien erfüllen. um Schutz und Rücksicht zu gewährleisten. Und diese Dreiteilung habe ich entnommen oder abgeschaut von den Richtlinien für vertrauenswürdige KI, Guidelines for Trustworthy AI, die im Jahr 2018 veröffentlicht worden sind. Also die Europäische Kommission hatte eine sogenannte hochrangige Expertenkommission damit beauftragt, sich mal Gedanken darüber zu machen, was ist vertrauenswürdige KI. Und es lohnt sich, in diese Richtlinien mal reinzuschauen. Da sind auch konkretere Anforderungen darin aufgelistet, aber diese drei Aspekte sind so die Grundpfeiler, die diese hochrangige Expertenkommission definiert hat. Trustworthy AI needs to be rechtmäßig, robust und ethisch. Und warum brauchen wir KI-Sicherheit? Der Simon hat es schon gesagt, also gerade im Moment ist ja KI in aller Munde. Warum müssen wir da eigentlich drüber nachdenken? Und ich mache nochmal einen Schritt zurück. Also ich habe schon mitbekommen, ihr seid wirklich eine sehr KI-affine Community, habe ich den Eindruck. Also womöglich renne ich hier offene Türen ein, aber ich möchte trotzdem nochmal kurz die Begrifflichkeiten ein bisschen sortieren und klären. Also künstliche Intelligenz ist ja ein Überbegriff für Systeme, die Eigenschaften haben, menschenähnliche Verhaltensweisen zu zeigen. Also Kognition oder auch Aktion, also etwas erkennen, etwas produzieren, was menschliche Kognition auch nachahmt. Das ist relativ breit gefasst und schließt auch fest verdrahtete Systeme ein, also Expertensysteme, was man jetzt Symbolic AI nennt, also was regelbasiert mal programmiert wurde, kann durchaus künstliche Intelligenz sein. Ist das jetzt sehr weltbewegend? In diesem Moment ist das besonders kritisch vielleicht nicht unbedingt. Also interessanter wird es, wenn wir über die Subkategorie von Systemen sprechen, die was mit maschinellem Lernen zu tun haben. Also da geht es um KI-Systeme, die sich weiterentwickeln durch Erfahrung oder Daten. Maschinelles Lernen beinhaltet eben auch Systeme, die klassifizieren, kategorisieren, die Wahrscheinlichkeiten einschätzen und so weiter. Also ist auf einem radiologischen Befund ein Tumor erkennbar, ja oder nein. Wird dieser Antragsteller für den Kredit zurückzahlen können? Ja oder nein? Ist auf dem Bild eine Katze zu sehen? Ja oder nein? Oder ein Hund? Solche Kategorisierungen basierend auf Wahrscheinlichkeiten sind Teil des maschinellen Lernens und generative KI, wie der Name sagt und wie euch wahrscheinlich auch bewusst ist, auch vom Unterschied her erzeugt neue Inhalte. Und das ist ein Schritt, ein Unterschied, der nicht allen immer so klar ist. Also ich meine, als wir damals mit ChatGPT angefangen haben zu experimentieren und Menschen da irgendwie wahnsinnig enttäuscht waren, was da für ein Quatsch rauskommt, das war halt nicht, wofür es da ist. Also es hat Inhalte erzeugt, die gut klingen, die so sind, wie gute Texte zu sein haben. Aber ist es wahr? Kann es rechnen? Nein, das ist auch nicht die Aufgabe. Also deswegen betone ich das nochmal, weil das wirklich ein wichtiger Unterschied ist, wie man sich immer mal wieder unter Umständen vor Augen halten muss. Dann haben wir als nächste Stufe KI-Agenten. Simon hat es schon gesagt, also da geht es um komplexere Abläufe, auch nochmal überlegen und nicht einfach was machen. Und ich sage jetzt auch schon überlegen, also Schritte planen, Kooperationen planen mit anderen KI-Agenten, Verwendung von Tools, um komplexere Aufgaben zu lösen. so warum sollten wir also wachsam bleiben interessant der teil maschine maschinelles lernen nach rechts ja also die das weiterentwickeln von den systemen durch daten und erfahrungen führt halt dazu dass es eine dynamik gibt dass die systeme nicht einfach so sind wie man so fertig programmiert hat ausgeliefert hat und dann sind sie so sicher und robust bis zum nächsten upgrade sondern man muss es eben im Auge behalten. Nochmal zurück zum Motorwagen, mit dem Bertha Benz da durchs Greichgau getuckert ist. Also ich bitte jetzt mal kurz sich vorzustellen, das ist das einzige Auto auf der Welt, das herumfährt. Das fährt da irgendwie an Heidelberg vorbei, in Wiesloch vorbei, da durchs Greichgau. da sind Pferdevorwerke, da sind vielleicht ein paar Esel unterwegs, viele Fußgänger mit Handwagen unter Umständen. Das ist das einzige Auto, was außerhalb von Mannheim da herumfährt. Das einzige Auto, das da herumfährt, ist jetzt noch mal kein großes Risiko für andere Menschen, für die Umwelt. Es stellt kein großes Risiko dar. Es wurden es aber mehr und immer mehr. Und jetzt heute sind es mehr als eine Milliarde Autos, Kraftfahrzeuge, die in diesem Moment auf der Weltkugel herumfahren. Und das hat sehr große Veränderungen auf der Welt mit sich gebracht, natürlich was Gesetzgebung betrifft, natürlich was Technologie betrifft, gesellschaftlich und so weiter. Und ich würde jetzt mal die steile These wagen, dass künstliche Intelligenz, so wie wir es jetzt heute erleben, ähnlich disruptiv sein kann wie diese Technologie. Mit großen Auswirkungen. Das Tempo ist atemberaubend und deswegen auch sehr wichtig, ein Auge drauf zu haben. So, dritter Punkt. Also wie gesagt, das ist ja gar nicht schwer, aus KI irgendwelchen Quatsch rauszukriegen. Aber ich habe jetzt trotzdem mal zwei Beispiele mitgebracht. Das Bild habe ich von einem Jama erzeugt mit Adobe Firefly. Ich habe es vor ein paar Wochen nochmal versucht. Hat sich nicht grundlegend geändert. Also die Aufgabe war, mache ein Foto von einem Dutzend roher Eier, die gerade aus einem Meter Höhe auf einen Steinboden gefallen sind. Ja, also da ist jetzt einiges fragwürdig dran. Ja, mal abgesehen davon, dass Eier nicht so aussehen, wenn sie auf dem Boden gefallen sind. Und zwölf sind es auch nicht. Ja, also da ist wieder... Also das ist ja ganz amüsant und ganz drollig. Also ich fand es sehr verblüffend, ehrlich gesagt. Ich hatte das mal in der Präsentation gesehen, also ich wäre gar nicht selber drauf gekommen, aber ich fand das wirklich einen sehr interessanten Test dafür, wie wenig Weltwissen diese Maschinen, diese Anwendungen haben. Ein bisschen weniger amüsant ist es dann, wenn man solche Sachen fragt. Erzeugt ein Bild von A Doctor, auf Englisch ist es Gender Neu-Den-Den-Den-Den-Den-Den-Den-Den-Den-Den-Den-Den Gendern neutral kommen nur ältere Herren. A Nurse, auch auf Englisch gender neutral, kommen nur Damen. Also das ist jetzt auch schon wieder ein paar Jahre. Aber das Prinzip, das Grundproblem ist ja immer noch da. Also in den Daten gibt es eine Verzerrung, die sind Jahrzehnte alt, spiegelt vielleicht eine gesellschaftliche Realität von vor 30, 40 Jahren wieder, aber auch nicht repräsentativ und so weiter. Also wenn man jetzt sich darauf verlässt, also wenn man jetzt quasi durch KI die Welt anschaut und sich darauf verlässt, auf das, was aus einer KI rauskommt, ist man unter Umständen auf einem ziemlich falschen Dampfer. Und das kann natürlich je nach Kontext durchaus kritisch sein. Und diese Einschränkungen zu verstehen, auch die Unterschiede zu verstehen, was kann ich mit welcher Art von KI-System überhaupt machen und was sind die Einschränkungen? Das ist der dritte Punkt, den ich hier anführen möchte. warum wir wirklich wachsam sein sollen, weil das auch alles so schnell geht. Und ihr und ich seid auch ein bisschen KI-Literate, aber viele sind auf dem Level nicht. Und da gehen einige Risiken mit einher. So, dritter Punkt. Wie für KI-Sicherheit sorgen? Und da gibt es natürlich verschiedene Ebenen. Also es gibt gesellschaftliche Aufgaben, es gibt politische Aufgaben, es gibt internationale, die internationale Gemeinschaft muss sich verständigen und so weiter. Aber das geht dann auch eben runter bis zu Applikationsdesign jetzt bei uns bei SAP, wenn Teams an einer Applikation bauen für einen bestimmten betriebswirtschaftlichen Anwendungsfall. Also auf all diesen Ebenen kann und muss man sich Gedanken machen darüber, wie man die KI sicher gestalten kann. Und ich rede jetzt schwerpunktmäßig aus der SAP-Anwendungsbrille, aber nochmal ein letztes Mal zurück zum Thema Kraftfahrzeuge. Hier ist eine schöne Grafik dazu, wie bestimmte Erfindungen im Zusammenhang mit Autos die Anzahl von Todesfällen im Straßenverkehr reduziert hat über die letzten 60 Jahre. Man kann auch noch ein bisschen zurückgehen. Also irgendwann haben die Autohersteller festgestellt, wenn die Windschutzscheibe platzt und Menschen die Splitter abbekommen, dann gibt es schlimme Verletzungen, die aber unter Umständen vermieden werden können, wenn man anderes Material verwendet. Und das ist, glaube ich, sogar schon in den 1920er Jahren des Sicherheitsglas erfunden worden. Also das ist schon relativ lang her. Also die Ingenieure, die Hersteller von Technologie machen sich auch manchmal schon darüber Gedanken, wie sie weniger Schaden anrichten können. Und jetzt zum Beispiel am Beispiel vom Dreipunkt-Sicherheitsgurt, der wurde erfunden in 1959 und hat auch seinen Weg gefunden in die Gesetzgebung des Pflicht seit 1973. Also Erfindungen, die dazu gedient haben, weniger Schaden einzurichten, Menschen weniger zu beeinträchtigen, können sich so bewähren, dass sie dann auch irgendwann in der Gesetzgebung erscheinen. Aber ursprünglich war es weder technologisch da noch gesetzmäßig da, sondern es war eine Idee, die aus dem Grundsatz herausgekommen ist. Wir wollen dafür sorgen, dass die Nutzer unserer Technologie, von unseren Autos möglichst unbeeinträchtigt und unbeschadet die Technologie verwenden können. Ähnliches wiederum können wir auch anwenden und uns überlegen für Sicherheit und künstliche Intelligenz. Darüber hatte ich schon gesprochen. Und bei SAP haben wir es ganz ähnlich umgesetzt oder definiert. Und hier ist der QR-Code auf die Webseite, Responsible AI. Da findet ihr alle möglichen Informationen und mehr Dokumente zum Herunterladen. Also verantwortungsvolle KI bei SAP steht auf drei Säulen. KI-Compliance, Einhaltung globaler Vorschriften und Gesetze, KI-Sicherheit, da ist jetzt wieder ein bisschen die Unschärfe mit dem Begriff, also da geht es darum, die Dinge sind robust und sind sicher implementiert und das Thema KI-Ethik, wo wir einfach darüber nachdenken, welche Art oder welche Eigenschaften sollten KI-Systeme haben, damit wir sie für gut befinden und dafür auch die Verantwortung haben. übernehmen können. Und da gebe ich jetzt noch einen winzigen Einblick, das mache ich ganz kurz und verweise dann ein weiteres Mal auf die Webseite. Und hier auf dem Bild möchte ich nur kurz darauf hinweisen, dass das Thema KI-Ethik schon seit 2018 offen dazu bekannt haben, dass das ein Thema ist. Die Kollegen haben schon zwei, drei Jahre früher angefangen, waren auch Teile von der Expertenkommission, die ich vorhin erwähnt habe. Also das Thema ist schon wirklich ganz lange bei uns ein wichtiges Thema und hat sich über die letzten Jahre aufgebaut und ausgebaut, sodass wir jetzt ein großes, hohes Level an Organisational Maturity haben, was das Thema KI-Ethik betrifft. Das sind die aktuellen Leitprinzipien für KI-Ethik, basierend auf der UNESCO-Empfehlung für die Ethik von KI. Die findet man eben auch alle auf der Webseite. Ich fasse es mal zusammen danach, wer dafür zuständig ist, diese Prinzipien einzuhalten. Zum einen organisatorische Praxis. Also das heißt, die Organisation muss sich dafür aufstellen und Strukturen bereitstellen, damit das Thema wirklich umgesetzt werden kann. Das ist niedergeschrieben in der Global AI Ethics Policy. Kann man runterladen von der Webseite. Also da steht drin, welche Rollen gibt es und welche Verantwortlichkeiten und auch welche Anforderungen. Dann haben wir den KI-Ethik-Bewertungsprozess. Ich habe leider keine Zeit da im Detail, das war schon klar, aber das ist eigentlich die Folie, die am meisten fotografiert wird, die wirklich sehr aussagekräftig ist und aus der hervorgeht, wie wir sicherstellen in der Produktentwicklung, in der Softwareentwicklung, dass KI-Prinzipien und Anforderungen erfüllt und auch überprüft werden. auf der Webseite und auch Teil von dem Online-Kurs, den wir letztes Jahr veröffentlicht haben, für den ich auch noch Kurzwerbung mache. Also da geht es darum, wenn man eine Anwendung definiert, sich überlegt, in welche Anwendung wollen wir denn KI mit einbauen, dass man sich da schon darüber Gedanken macht, was könnten Risiken sein und wie können wir die entweder minimieren oder unter Umständen das System anders definieren, damit die ethischen Risiken reduziert werden. Und damit ihr es mal gehört habt, das sind die drei, aus meiner Sicht, die drei Kernanforderungen, Ethik-Anforderungen im Kontext von KI, menschliche Kontrolle und Selbstbestimmung. Es geht immer darum, dass der Mensch die Maschine unter Kontrolle hat und nicht umgekehrt. Human in the Loop fiel vorhin auch schon. Also das ist ein wichtiger Punkt, sich zu überlegen, an welchen Stellen braucht man wirklich die Entscheidung vom Menschen. An welchen Stellen ist es okay, wenn die KI da ihre Lösungen findet. Aber wo braucht man wirklich ein Human in the Loop? Fairness und Nichtdiskriminierung. Beispiel vorhin mit a doctor, a nurse. Gerade im Kontext Human Resources Anwendung oder so spielt das natürlich eine Rolle, dass man eben vermeidet, dass es Verzerrungen gibt beim Einladen von Bewerbern, Bewerberinnen und so weiter. Und Transparenz und Erklärbarkeit. Da geht es darum, dass Menschen die Möglichkeit haben müssen zu verstehen, was macht die Maschine jetzt eigentlich, so gut es halt geht. Also meistens ist es ja Blackbox, aber es gibt Möglichkeiten, da reinzuschauen, damit diejenigen, die zuständig sind für die Sicherheit der Systeme, auch erkennen, dass da vielleicht was gerade nicht mit rechten Dingen zugeht. Und auf der anderen Seite die Anwender von der KI-Anwendung, dass die einschätzen können, okay, also das, was da jetzt rausgekommen ist als Empfehlung oder als Ergebnis, bin ich mit meiner Fachexpertise damit einverstanden oder ziehe ich das in Zweifel oder kann ich das so akzeptieren? Also diese Transparenz, ganz wichtige Voraussetzung, um die anderen beiden Themen auch zu bearbeiten und zu erfüllen. Da die Empfehlung das AI-Ethics-Handbook, ebenfalls auf der Webseite. Genau, und nur nochmal die 3x3 Punkte, die ich versucht habe zu machen. Und damit komme ich auch zum Schluss von meinem Impuls. Ich hoffe, dass ihr dafür ein paar neue Perspektiven gewonnen habt. Ich muss sagen, das Thema ist so spannend und so interessant. Ich bin jeden Tag sehr begeistert und beglückt, dass ich daran arbeiten darf, weil es auch so vielfältig ist und gleichzeitig auch so relevant. Ich hoffe, dass ich euch da ein bisschen einen Einblick geben konnte und wünsche euch eine sehr erfolgreiche Konferenz, Kon, und danke sehr für eure Aufmerksamkeit.