't't und das ist das wir haben wir haben Gut, das heißt, akustisch bin ich total wahr. Bist du dran? Ja, wunderbar. Schön, dass ihr da seid. Es ist eine Mischung aus ein bisschen Vortrag, aber natürlich auch interaktive Diskussionen zum Thema, warum KI an Strukturen scheitert und nicht so sehr an der verfügbaren Technologie. Natürlich hängt beide ein bisschen damit zusammen. vielleicht als erstes mal so für die Teilnehmer hier, wer von euch nutzt denn schon KI abseits Chachiketio Compilot bei sich im Unternehmen? Also im Sinne von Agentensysteme, Reasoning-Modelle, schon Menschen ersetzt? Noch nicht? Ganzer Mensch noch nicht, aber halber. Nee, einfach Funktionen geschaffen, auch bestimmte Daten bestellte Reaktoren, die ja auch nicht Ja, sehr gut. Genau, und hier will ich ein bisschen drüber reden, wie Organisationen sich verändern müssen oder verändern sollten, wenn sie die vollen Hebel, die AI als Technologie uns bietet, tatsächlich auch nutzen wollen. Vielleicht zur grundsätzlichen Einordnung so ein bisschen. Die normalen Sprachmodelle sind ja mit dem Weltwissen trainiert. Das heißt, die können ganz gut auf Fragen antworten. Wenn es aber darum geht, dass beispielsweise unabhängige autonome Workflows innerhalb eures Unternehmens durchgeführt werden, das heißt also wirklich Prozesse erledigt werden, wo früher ein Mensch dafür zuständig war, dann brauchen wir noch eine ganze Menge mehr drumherum. Ich habe auch nachher mal aus technischer Sicht noch mal eine Beispielarchitektur drin, wie es sein kann. Hier geht es wie gesagt erstmal so ein bisschen vordergründig darum, was muss eigentlich ich als Organisation verändern werden. Für mich das Wichtigste nach 25 Jahren Vorträgen, was sehe ich hier ist, Modanobe zu erhalten. Also ihr seid eingeladen, gebt nur Widerspruch, gebt Kommentare, sagt, wenn ihr mit etwas nicht einverstanden seid, damit das Ganze auch ein bisschen interaktiver ist. Von den Slides her, das erste Slide, das wichtigste Statement für mich an der Stelle ist, Wissen, das nicht wirkt, ist wertlos. Ihr kennt das vielleicht alle, wer von euch hat so ein Wiki-Confluence, was auch immer, im Einsatz ist es total gut, um Daten reinzuschieben, aber wir wollen irgendwie Informationen finden. Immer total schwierig, selbst wir als kleines Unternehmen mit 80 Mitarbeitern haben es schon total schwer in unserem Confluence, was seit über 15 Jahren existiert oder noch länger, tatsächlich da auch gut Inhalte zu finden. Ich war letzte Woche in einem Expertenkreis im Bereich Contact Center Management und da war eine Kollegin von der BMP Paribas aus Neunberg da. Und die meinte, wir haben extra Dokumentateure und Redakteure, die auch so ein bisschen Struktur vorgeben. Da habe ich mir gedacht, Mensch, wer die Kohle dafür hat, der ist gut aufgestellt. Alle anderen müssen gucken, wie sie damit zurechtkommen aus dem Datenboost quasi sich zurechtzufinden. Und hier in dem Slide ist ein bisschen der Widerspruch aufgelistet. Auf der einen Seite der echte Mensch, der noch damit beschäftigt ist, Notizen zu machen und auf der anderen Seite die AI, die schon die Reports generiert und wenn man das ganz weiter drängt auf Basis der Ergebnisse, dann auch tatsächliche Handlungen durchführen, wie das Konto sperrt, Geld überweist oder was auch immer, haben wir ja auch schon die Fälle gehabt und ähnliches. Das heißt, Wissen, das nicht wirkt, sondern irgendwo nur abgehalftert, irgendwo rumliegend ist, einfach wertlos. Und die große Schwierigkeit ist, wie kann ich das Wissen im Unternehmen skalierbar machen, um für mich als Unternehmen tatsächlich auch wieder an die Pole Position zu kommen. Und wie gesagt, die Perspektive von gestern ist eben, wenn Wissen nicht skalierbar ist im Unternehmen. Die große Frage ist natürlich, wie kann ich als Organisation das erreichen und was muss ich vielleicht auch dafür tun, um in meiner Organisationsstruktur vielleicht noch ein paar Änderungen herbeizuführen, um genau diesen Regel zu finden und tatsächlich für mich umzusetzen. Wir selbst haben bei uns und bei unseren Kunden beobachten drei Trends und das, was so im Markt passiert. Zum einen AI wird ein Infrastrukturthema. Das bedeutet, die Unternehmen stellen fest, letztes Jahr war so ein bisschen so Experimentierwut gewesen. Ja, da werden hier mal ein bisschen Racklösungen gebaut, wo man mit seinen Unternehmensdokumenten checken kann. Die Ergebnisse sind alle nicht unbedingt immer die besten gewesen. Und die Unternehmen merken, also dieses AI, das scheint irgendwie so eine Wundertüte zu sein, die uns irgendwie viel mehr versprochen hat, als wir tatsächlich realisieren zu können. Und tatsächlich liegt das meiner Meinung oder unserer Meinung nach daran, dass AI im Unternehmen falsch verankert wird. Ich erzähle in Vorträgen immer, wenn Unternehmen anfangen, für ihre einzelnen Bereiche und Abteilungen singuläre Tools anzuschaffen. Es gibt den Unternehmens-Propilot oder das Unternehmens-GPT, Die Marketingabteilung gibt irgendwie so ein AI-Social-Media-Tool, damit sie ihre Social-Media-Texte schneller bauen können. HR bekommt irgendwie ein spezialisiertes Add-on für das Recruiting-System. Dann baut ihr ja eigentlich nur eure Siedlestruktur digital nach. Das ist eigentlich das, was man nicht will. Und deswegen sollte man AI eher als Infrastruktur denken, das heißt Plattformen-Gedanke, Use-Cases, die aufeinander aufbauen, wo die Agentensysteme sich untereinander austauschen, Informationen austauschen und sich gestalten. Und das geht nur, wenn man tatsächlich auch in seiner Organisation etwas ändert. Das ist wie gesagt der erste Trend, den wir sehen. Der zweite Trend ist, dass jetzt auch Wissensarbeits skalierbar wird. Als wir vor zwei Jahren Vorträge gehalten haben, als Chattagity rauskam, haben wir alle gesagt, ja, dauert noch so ein bisschen mit dem Beruf der Softwareentwicklung. Eigentlich wird es mehr Softwareentwicklung geben und ähnliches. Tatsächlich stellen wir aber jetzt fest, neueste Studien von LinkedIn-Jobs, von Indeed und ähnliches, dass auch die Zunft von uns Wissensarbeitern so ein bisschen gefährdet einherkommt. Wer fühlt sich bedroht durch AI? Von euch? Ist das gut? Das ist gut. Ich würde sagen, bedroht ist übertrieben. Aber Einfluss wird da sein. Ja, auf jeden Fall. Einfluss wird da sein, und zwar etwa zwei Drittel der Wissensarbeiterjobs werden entweder von mehr als 50 Prozent von AI quasi im Englischen infused, also durchgelagert oder tatsächlich ersetzt. Es gibt eine Statistik von OpenAI, dass der Beruf des Treckerfahrers beispielsweise noch Zukunft hat. Landwirte haben auch noch Zukunft, weil da einfach viel manuelle Arbeit da ist. Vielleicht in 50 Jahren nicht mehr, wenn wir dann die Roboter haben, die physischen Roboter, die dann auch noch mit LLM bespielen werden. Also es sieht gar nicht so rosig aus. Aber wieder zurück zur Ernsthaftigkeit. Worum geht es bei der Skalierbarkeit und der echten Digitalisierung von Wissensarbeit? Es geht um die Reproduzierbarkeit und um die Automatisierbarkeit. Kein Mensch hat Bock, ein Pina4-Papier zu locken, links in den Ordner einzuheften und dann ins Regal zu räumen. sind tätig, die will irgendwie keiner mehr machen, kann ich total gut verstehen. Trotzdem müssen wir irgendwie schauen, dass wir die Dinge gut skalierbar bekommen in den Unternehmen. Und das ist wie gesagt so einer der Trends, der auf die Organisation wartet, nur mit der richtigen Haltung und auch mit der, meiner Meinung nach, richtigen Haltung und auch mit der richtigen Art und Weise, wie man an solche Infrastrukturthemen rangeht, wird man es schaffen, die Wissensarbeit auch tatsächlich skalierbar zu kommen. zwar nicht um Menschen zu ersetzen, sondern vielleicht auch Engpässe zu beheben. Ich habe nachher noch ein Case dabei von einem Unternehmen, wo wir eine große Lösung gebaut haben. Da geht es um den Bereich Übersetzungen. Die brauchen jetzt weniger Übersetzer, aber die schmeißen keine Leute raus, weil die Übersetzer haben sie erst gar nicht bekommen. Das heißt, Stichwort Fachkräfte, die Leute, die ich gar nicht erst bekomme, die kann ich jetzt durch AI sozusagen mit einbinden. Und der dritte Trend, den wir sehen, von Agenten hat jeder schon gehört, Wer setzt von euch AI-Agenten ein, die nicht Workflow-Systeme sind? Also so Power Automate und so zählt nicht, weil sie sind keine echten Agenten. N8N zählt auch nicht, weil das ist nur ein deterministisches Workflow-System. Der Trend geht dahin, dass man statische Agenten hat, das heißt also Systeme, die autonom handeln, die in der Lage sind, Prozesse in euren Systemen im Unternehmen auszuführen. Warum könnten sie das? Weil sie die Schnittstellen dazu bekommen und selbst wenn sie die Schnittstellen nicht dazu bekommen, man kann heutzutage Browser feinsteuern, wir können ganze Computer feinsteuern, das sind durch LLMs, das heißt also über Vision-Modelle, dass einfach erkannt wird, was passiert da gerade auf meinem Desktop, in der SAP-Maske, wo muss ich jetzt hinklicken, um was auszuführen und ähnliches. Das sind bisher statische Agenten, das heißt Agentensysteme, die in der Lage sind, selbstständig zu lernen und durch Workflows durchzuklicken in den Systemen. Und der Trend, der jetzt dahin geht, ist zu sagen, es gibt die sogenannte Metakognition. Das heißt, die AI-Systeme, wenn sie so programmiert sind, sind in der Lage, sich selbst zu reflektieren, auf der Basis zu adaptieren, den Kontext, in dem sie gerade ablaufen, zu beobachten und danach zu handeln. und das vor allem die Spannende aus Sicht eines Wissensarbeiters, die mit Unbekannten und Unbekannten umgehen zu können. Das heißt, die lernen, was sie nicht wissen und versuchen dann, sich das Wissen sozusagen beizubringen. Wenn man sie connectet mit einer Internetrecherche beispielsweise und der Agent stellt fest, ah hoppla, ich weiß da was nicht, dann kann er erstmal einen Rechercheauftrag starten. Ihr kennt es vielleicht von Research als eine Ausprägung davon. Wenn man sagt, man hat ein bisschen research, das Thema ist das Konzept, dann geht das System auch erstmal für 15 Minuten auf die Reise und guckt mal, was kann es denn so an Informationen zusammenklauen. Und durch die Selbstreflexion bin ich aber in der Lage, den Human rauszunehmen, den Menschen, weil ich ihn dann irgendwann nicht mehr brauche, sondern das Agentensystem lernt dann selbstständig, was denn für sich die Wahrheit ist und was nicht die Wahrheit ist. Das sind eben metakognitive Systeme, die wir brauchen. Die Auswirkungen sind tatsächlich spürbar. Unternehmen, die nicht in diese Trends rein investieren, die verlieren Zeit, Geld und Innovationskraft, einfach durch eine fragmentierte Wissenslandschaft, durch viele Datensinos. Also jede Abteilung hat natürlich ihrerseits wiederum Daten, die nur in der Abteilung präsent sind, die nicht übergreifend tätig sind. Wir wissen auch, das könnte man auf die Idee kommen, dann lass uns doch ein zentrales Datenprojekt machen, Daten harmonisieren. Ich weiß nicht, ob ihr zu den 15 Prozent aller Unternehmen gehört, bei denen das erfolgreich ist, bei 85 Prozent aller Datenprojekte zur Zentralisierung scheitern. Deswegen ist es wichtig, da eher mit Konzepten zu arbeiten. Beta-Mesh nennt sich das beispielsweise, wo man sagt, die Dezentralität, die lasse ich einfach bei. Also das wissen wir auch aus der Agilität, der im agilen Umfeld tätig ist. Zentralität ist schwierig. Dezentralität ist etwas, um mit der Komplexität der Prozesse zurechtzukommen. Und das Gleiche betrifft auch die Komplexität der Daten, die ich habe. Das heißt, Unternehmen, die da nicht reingehen, die verlieren, weil sie zu viele Datensilos haben, weil sie zu viele manuelle Prozesse haben, Handover zwischen zwei Kollegen, vielleicht mögen sich nicht so aus verschiedenen Abteilungen und Ähnliches. Und man ist eben gefangen in den einzelnen Silos. Und das aufzubrechen, wird man nicht schaffen, wenn man jetzt jede Abteilung halt so einen Unternehmensstip. Ich gebe noch fünf Minuten. Macht mal. Ja, wer ist der Gewinner? Gewinner sind semantische Wissensarchitekturen, das heißt, aus den Daten Sinn machen, beispielsweise wenn wir bei REC-Systemen sind, ihr kennt das vielleicht, checkt mit ihr Documents, war vor zwei Jahren so ein Hype-Burner, da gab es Startups, die haben da hunderte Millionen Dollar dafür bekommen, von einem umgerechnet 100 Zeilen Pipe-Code, den man schreibt, damit man halt über KI mit seinen PDFs irgendwie quatschen kann. Das reicht aber heutzutage nicht mehr aus, denn wenn ihr euch komplexe PDFs vorschreibt, sind Tabellen drin, dann habt ihr irgendwo eine Grafik, die entbettet ist im PDF, die hat einen Umsatzchart drin und drei Seiten später im PDF-Text wird sich auf das Umsatzchart bezogen, beispielsweise. Das kann ein einfaches Wacksystem nicht erkennen, mit entsprechenden Systemen, die man in so eine, wir nennen das Pipeline reinbaut, können wir aus dem Daten Sinn machen und semantische Zusammenhänge in den einzelnen Datenschapfen erkennen, weil wir ein Vision-Modell, also ein Wischen-LLM fragen können, so was steht denn da auf dem Grafen drauf und dann gibt er mir halt die Antwort. Und diese Antwort kann ich wiederum auch in meiner Rack-Vektor-Datenbank mit Rack speichern. Oder ich kann sagen, rekonstruieren wir mal die Tabellen im Markdown-Format, mein Markdown-Format ist für LLLM besonders gut lesbar. Und so kommt man halt an die semantische Daten. Und diese Wissensalteatur, die brauchen, damit ich als Unternehmen einen Wettbewerbsvorteil rausnehmen kann für mich. Und besonders spannend wird es, wenn ich mich nicht nur auf die Semantik innerhalb einer Datei beziehen kann, sondern beispielsweise auf die Semantik aller Dateien aus den verschiedensten Abteilungen. Weil sonst habe ich ja wieder das Problem, dass ich nur in meinem Abteilungssilo sozusagen das lokal verfügbare Wissen zur Verfügung habe. Als Unternehmen will ich aber das Unternehmenswissen sozusagen bekommen. Und Metacognition habe ich schon gesagt, die kann eigene Wissensmittel erkennen und bezüglich. Das bedeutet also, die Karten werden neu gemischt auf dem Markt mit AI, diejenigen, die da auch viel rein investieren, die gehören zu den Gewinnern. Wir haben zentrale Wissensmodelle, wir haben semantische Graphen, wir haben kontinuierende Kontextanreicherungen, dass das System versteht, was macht denn der Nutzer da eigentlich, wenn er da hin und her klickt und ähnliches. Ich habe erst heute auf der Zugfahrt hierher von einem der Gründer von Shopware, das ist nur ein Beispiel, einen Post gesehen. Der hat ein dynamisches Shopfrontend auf LLM-Basis gebaut. Das heißt, der Mauszeiger des Nutzers wird verfolgt und abhängig vom Kontext, wo der Nutzer sich gerade befindet, werden die UI-Elemente neu gebaut. Hatten wir auch schon vor zwei Jahren mal auf dem CTO-Stammtisch, hat einer erzählt, er macht genau das. Das heißt, UX ist ein Themenfeld, was irgendwie auch so ein bisschen weggeflügt worden ist, weil man sagt, okay, die UI baut sich im Kontext des jeweiligen Nutzers, was der gerade machen möchte, entsprechend auf. Und damit sind wir bei Intelligence on Tap. Das heißt, wissen, was immer zu jeder Zeit im jeweiligen Kontext verfluchtbar ist. Und das ist das große Versprechen, was dahinter steht, weil die AI durch ihr non-deterministisches Verhalten in der Lage ist, uns genau das zu liefern, weil sie so menschenähnlich denkt, sozusagen. Die Verlierer sind die Silostruktur. Ich entscheide nur nach Bauchgefühl, weil ich habe jetzt auch keinen Bock, mich durch die drei Millionen Dateien in meinem SharePoint, Prozessdoku 1, Prozessdoku 2, unterstrich 2025 und 203 und so weiter durchzuklicken, was ist gerade aktuell, sondern ich habe das Wissen tatsächlich da. Wir hatten mal eine Anfrage von einem Kunden, Müller-Drucken-Gerick-Ritte war das, für die haben wir letzten Endes den Case gemacht, über den ich es nachher erzähle. Aber die ursprüngliche Anfrage war, baut uns einen Chatbot für unsere Prozessdokums für die Filialenmitarbeiter. Und die hatten das Problem, dass sie halt einfach verschiedene Dateien mit Prozessanweisungen in verschiedenen Systemen haben. Mal im Confluence, mal im SharePoint, ich weiß nicht, ob ihr das kennt aus euren eigenen Unternehmen. Und was man da eigentlich auch machen kann, ist ein Agentensystem draufsetzen, das bevor die Daten in die Datenbank gehen, das selber prüft, was ist denn jetzt die aktuelle Information, das vielleicht noch mit einem Menschen, als er sich assistieren lässt, der ihm dann vielleicht ein paar Stellen schubst und sagt, okay, in die Richtung geht es. Und schon bekomme ich die aktuellste Information, das aktuellste Wissen raus und kann dann gleich diese Dokumente neu bauen, die ich eigentlich gar nicht mehr brauche, weil das System hat ja schon verstanden, was eigentlich das Richtige ist. Also wie gesagt, Verlierer, Bauchgefühl, verteiltes Wissen, das Wissen ist in Tickets, kodiert in E-Mails, in SharePoint und so weiter und so fort. Das kennt ihr alle. Ja, und die große Frage ist: Okay, was hat das jetzt alles mit mir zu tun? Ich weiß nicht, ob ihr euch selber manchmal die Fragen stellt, wie hier: Wie viele eure besten Antworten findet ihr im Wiki und wie viele beim Kollegen in der Kaffeeküche oder beim One-on-One über Teams? Was für euer Erfahrungswert? Kaffeeküche Kaffeeküche hat sich post-Pandemie tatsächlich auch so ein bisschen verschoben. Ja, oder? Der One-on-One-Call zur richtigen Zeit mit der richtigen Person ist natürlich immer der Volltreffer. Aber der wird halt multipliziert in der Wahrscheinlichkeit, dass er stattfindet. Also ich bin da schon noch ein Wikifreund aus ganz anderen Gruppen. Keine Ahnung, was zu sagen. aber Dokumenten freuen, dass man über Dokumente auch Personen findet oder so. Weil diese spontane, der sie abnimmt. Ist das bei der Dramatisierung? Entschuldigung, wir haben noch ein Netz. Ich weiß nicht, wie groß die Bedrohung sein muss für den wirtschaftlichen Erfolg von Unternehmen, weil ja alle dramatisiert haben, was passiert, wenn es sie nicht mehr gibt. Was aber sicher nicht zu unterschätzen ist, ist die Zufallsbegegnung. Ich muss zugeben, dass ich ab und zu im Unternehmen bei physischen Treffen Zufallsbegegnungen habe, die ich als wertvoll bezeichnen würde und die finden nicht so statt, wenn ich getrennt voneinander in unterschiedlichen Einheiten online sitze und vermutlich ist es halt ein, wie gestalte ich das am besten und da wird jetzt KI mit Agenten noch dazukommen und du hast vorher gefragt, was wir tun, wir erst daten setzen es im Service ein und ich bin erstaunt, mit welcher Geschwindigkeit es jetzt voll automatisiert ist. Service Tools im Service gibt. Ich frage mich jetzt nicht technisch, wie wir es machen, aber es ist schon eine Kultur. Wir fragen unsere Kunden, ob sie das wollen und 50% sagen nein. Aber die Zahl wird auch jetzt schnell verändert sich, dass die Akzeptanz geht, weil die merken, sie müssen nicht in Hotlines auf Menschen warten, sondern diese Maschine schneller antwortet und sie Probleme löst. Und bei uns sind es häufig Software-Technik-Probleme, also wo es die Empathie nicht die entscheidende Frage ist, sondern die Korrektheit der Antwort. Insofern glaube ich, dass wir da eine hohe Dynamik im Thema kriegen und wir sind ein sehr konservatives Unternehmen mit Geschwindigkeit, wie wir uns mit dem Thema auseinandersetzen, zeigt, mit welcher Wucht das jetzt kommt. Das spricht zwei wichtige Punkte. Das eine, was ich gerne noch mal betonen würde, ist ein ganz wichtiger Effekt und man kann gar nicht so viel nachdokumentieren, wie neues Wissen jeden Tag entsteht in der eigenen Arbeitsaufgabe, ob als Softwareentwickler oder im Marketingbereich oder in anderen Bereichen. Die neuen Dinge, die man hat, wird man ja nicht dokumentieren, nur damit ein anderer Kollege, wenn er mal diese Informationen braucht, dann nachgucken kann, weil sie dann sowieso schon veraltet ist, weil man dann sowieso als Unternehmen schon das nächste Punkt weiter einsetzt. Weil das andere Punkt, das ich jetzt dokumentiert hätte, das habe ich ja nur getestet, festgestellt, drei Tage später nutze ich was anderes. Das heißt, die Geschwindigkeit, in der Kontextinformation entsteht, ist mit normaler Dokumentation, das wissen wir auch alle schon seit 10, 15 Jahren, nicht mehr zu erfassen. Wir haben aber jetzt Systeme, und das ist so, was du gerade auch angesprochen hast, die in der Lage sind, mit unstrukturierten Informationen erstaunlich gut umgehen zu können, halt wie ein Mensch sozusagen. Und hier auch, wie viele Powerpoints liegen im Sharepoint und wie viele davon sind noch alle. Das ist so das typische Thema, was eigentlich im letzten Projekt passiert, obwohl es eine Doku dazu gibt, das heißt, man schaut vielleicht erst gar nicht in der Minute nach. Vielleicht musst du jetzt 200 Seiten, 30 Liefenseiten durchgucken und dann wird da quer verlinkt und was auch immer und irgendwann hat man keinen Bock mehr. Und man hat auch nicht Zeit. Also wir sind ja Generation TikTok irgendwie, die Aufmerksamkeit sparen ist auch ganz unten. Der nächste Kollege steht schon nebenan, virtuell oder physisch am Schreibtisch hat die nächste Frage. Da habe ich ja gar nicht die Zeit, mich zu konzentrieren und zu fokussieren. Deswegen wäre es ganz gut mit deiner Maschine, weil die jammert nicht, die hat keine Hunger, die schlägt nicht und so weiter. Ich habe noch zu der Seite vorhin noch eine Anmerkung. Eine Sache, die mich immer wieder umtreibt, ist dieses kontextuale Wissen. Du beschreibst jetzt, was ist in dem Dokument drin. Aber es kann ja sein, dass in dem Moment, wo mich einer fragt, ich was völlig anderes sagen würde, was ich niemals niedergeschrieben hätte, weil genau in dem Kontext, wie er mich jetzt fragt, fällt es mir jetzt so und so ein. Wäre ich jetzt nie drauf gekommen, das niederzuschreiben. Und das finde ich super schwierig, also das ist für mich der unvorstellbare, schwierigste Fall, den ich mir vorstellen kann. Also wie man es schaffen kann, dieses Wissen irgendwie zu fangen, indem du alles mitmonitorst. Also ich hab... Ja, aber ich spule jetzt mal zurück, ich sag's jetzt nochmal, wie ich's meinte. Ich hab das noch nicht gesagt. Ich habe das noch nie gesagt, aber wenn mich jetzt einer fragen würde, dann würde ich wissen, in dem Moment generieren. Also, das ist wie AI in dem Moment. Genau, das musst du mit schneiden. Also ich nutze beispielsweise seit eineinhalb Jahren Fireflies.AI, es gibt Millionen verschiedene Webfälle, kommen immer dazu, der hat bestimmt schon über 1000 Mietings mitgeschritten, sowohl interne wie auch externe, den kann ich nachträglich fragen. Ich kann auch zu meinem Diskussionsstil fragen: Hat der Björn da gut geantwortet? War er empathisch oder hat er mal wieder nur Unsinn von sich gegeben? Und deswegen habe ich das hier rausgeholt. Mein neuestes Investment, finde ich total gut, kann ich jedem empfehlen, ist die Plaudertasche. Plauder AI ist so ein kleines Gerät, das kann man auch bei physischen Meetings dann einfach anschalten, mitlaufen lassen. Man kann es auch irgendwo im Hemd verstecken. Man braucht keine besonders hohe Audioqualität. um Erkenntnisse daraus ziehen zu können. Also beispielsweise auf einer Konferenz, wenn Vorträge sind, dann wird es manchmal ganz gerne laufen und dann im Nachgang automatisch eine Mindmap oder eine Zusammenfassung, also wer es nicht an kann, um eine Zusammenfassung entsprechend zu bekommen. Und eigentlich zu deiner Frage, man müsste so viel wie möglich mitlaufen lassen, weil wenn die Frage beantwortet ist, hast ja keinen Bock mehr, das dann nochmal zu dokumentieren für die Ewigkeit. Vor allem in der schnellen Zeit, was habe ich mir jetzt vor fünf Minuten erzählt, Wie genau habe ich es denn jetzt gesagt und was ist denn beim anderen angekommen? Das geht eigentlich nur durch Echtzeit-Projekt. Es gibt auch Systeme, habe ich jetzt nicht installiert, ich traue mich noch nicht, gebe ich ehrlich zu. Den brauche ich noch mal ein Mac installieren und der recordet alles, macht Screenshots, Audio und so weiter. Und ich kann dann nachher wie ein Teilmaschinen zurückgeben, was habe ich denn am 1. Juli um 1333/33 auf dem Rechner gebaut? Eine Wortmeldung in der Söhne dran, Annika? Ja, genau, hi. Es hieß vorher, dass das Bauchgefühl ein Verlierer wäre von diesem Ganzen. Und ich finde es in dem Zusammenhang ganz im Gegenteil. Weil, also genau in dem, was jetzt gerade gesagt wurde, wie kommen wir denn an das implizite Wissen dran? Und klar, dann haben wir einmal, dass wir die Sachen, die schon explizit in Wortform da sind, die kann man der KI geben. Andererseits müssen wir aber auch Möglichkeiten finden, wie wir denn das Bauchgefühl tatsächlich zugänglich machen können. Und da gibt es in der Psychologie viele Sachen, die wahrscheinlich einen größeren Stellenwert bekommen werden, dass wir eben in unserer gesamten Wahrnehmung irgendwie unsere Informationen abfragen können. Deswegen Team Bauchgefühl. Ja, super Punkt. Ich stimme dir da prinzipiell zu. Mein Punkt vorhin war Noah, sich nicht zu 100% nur auf das Bauchgefühl zu verlassen, sondern wenn man tatsächlich das Unterstützen bekommt, man kann ja dann immer noch, weil am Ende in den meisten Situationen dann noch der Mensch die Entscheidung kriegt, kann man ja immer noch die Erkenntnisse der Maschine mit seinem Bauchgefühl zusammenwerfen und dann gucke, für was entscheide ich mich jetzt oder generiere ich vielleicht sogar eine dritte Option raus, weil ich mich mit der AI unterhalte und sage, du mein Bauchgefühl sagt mir jetzt folgendes, Wenn du das jetzt mit berücksichtigen würdest, wie wäre jetzt deine Empfehlung und dann wird neu kalkuliert und ich kriege eine neue. Warum sollte man gerade jetzt damit starten? Die Innovationszyklen werden durch und mit AI schneller. AI ist ein hoch innovativ Feld, ein hoch exploratives Feld. Wer von euch AI-Projekte im Unternehmen macht, ich kann nur davor warnen, dass wir klassische Softwareprojekte aufsetzen wollen. Das wird nicht funktionieren. Die relevanten Open Source Frameworks, die eingesetzt werden, die übrigens auch von den großen Hyperscalern genutzt werden, selbst Microsoft und viel sowas wie LangChain und ähnliches, die sind alle hoch innovativ zyniker, würden sagen hoch instabil, das stimmt aber nicht, sondern weil es einfach darum geht, die Fähigkeit der Transformer Modelle, also der quasi LLMs, um sinnvolle Elemente zu erweitern und da wird viel experimentiert. Beispielsweise Voice AI. Hatten wir vorhin das Beispiel, nutzen wir auch in diversen Projekten. Letztes Jahr haben wir das noch gerne mit OpenAI gemacht, da gab es noch keine Real-Time Voice. Dann kam irgendwann OpenAI mit Real-Time Voice raus, dass ich also einen Dialog führe, wo ich als Mensch keine Angst mehr haben muss, weil ich das Gefühl habe, da ist eine Maschine, sondern ich kann es nicht mehr wirklich gut unterscheiden, ob da jetzt eine Maschine oder ein Mensch ist. Mittlerweile hat Google da ein sehr, sehr gutes Sprachmodell für Real-Time Voice, wo OpenAI gar nicht mithalten kann. Das heißt, die verschiedenen Modellanbieter, die sind so innovativ und so schnelllebig und das gesamte Ökosystem drumherum, wenn ihr ein Vision AI und ähnliches denkt, dass man da ganz anders rangehen muss, wenn man sowas implementiert. Das heißt, die Innovationszyklen werden kürzer und schneller und darauf muss ich als Organisation sowohl organisatorisch wie auch in der Implementierung darauf eingeschaltet sein. Die Verlierer warten auf die nächste Freigabe von irgendeinem Chef, der sich das erstmal alles angucken muss, durch 200 Seiten. Ach nee, mach mal ein PowerPoint, dann macht die AI das PowerPoint. Der Chef beauftragt, die AI in Summary durch die PowerPoint zu machen und dann eine Antwort durch die AI generieren zu lassen. Und irgendwie sind wir eine Analyse. Sondern eigentlich wäre es besser, genau aus so einer Kette den Menschen rauszunehmen, weil die AI am Ende bessere Entscheidungen wird. Das heißt, vernetzte AI-Systeme werten aus, verstehen und setzen direkt und vor allem autonom um. Und was ich gerade gesagt hatte, mit schlägt nicht, jammer nicht, weiß mehr, lernt schneller. Das trifft leider auf die AI zu. Da sind wir leider nicht so gut konstruiert als Humanoide. Und deswegen ist es manchmal sinnvoll, da ein bisschen stärker die AI einzubinden. Und am Ende bedeutet das, wenn ich heute starte, kann ich meinen Vorsprung aufbauen, der morgen nicht kommt. Viele Unternehmer haben aber blinde Flecken. Was wir vorhin hatten, wir ertrinken an Informationen, wir verdursten an Wissen. Wissen ist nicht maschinenlesbar, die Maschinen können nicht so gut damit umgehen, auch wenn durch Vision AI, OCR-Erkennung und so weiter ich da schon gut rankomme. Das Wissen ist nicht kontextualisiert. Es ist nicht aktuell, die Daten sind wie gesagt verspreut über zig Systeme ohne jegliche semantische Verbindung. Und den Hebel von KI kriege ich nur durch verbundene semantische Bedeutung, die ich mir generiere. Menschen improvisieren an vielen Stellen, das ist durchaus ganz gut. KI tut das nur, wenn die Systeme es hergibt. Und selbstlernende Systeme brauchen mehr als nur Daten, weil sie brauchen den Kontext. Wo passiert etwas mit den Daten? Wie entstehen die Daten? Wenn sie den Kontext erkennen, dann sind sie in der Lage, auch eigene Lücken zu erkennen und diese selbst zu schließen. Das ist tatsächlich Metacognition. Ein Konzept übrigens, was Microsoft in seinem AI Beginnerskurs erzählt. Da sieht man durchaus, was das für eine Bedeutung hat, nach welchem untersten Level wir sozusagen tätig sind. Unternehmen, die das noch nicht berücksichtigen, sind dann halt noch ein bisschen weiter unten. Und wer das nicht ermöglicht, der limitiert einfach die KI. Wie gesagt, einzelne Coop-Tilots und so weiter in den Abteilungen geben ein gutes Gefühl, weil der CIO kann in der Checkbox abhaken, jetzt machen wir auch was mit KI. Er kann sich wieder schlafen legen, aber spätestens im nächsten Quartalsabschluss kommt das doofere Erwachtungsbügel. Der große Denkfehler ist, was ich vorhin sagte zu den Datenzentralisierungsinitiativen: Wir müssen erstmal alles dokumentieren, die Daten sauber machen, in Ordnung bringen und dann in zwei Jahren, wenn dann auch noch das neue ERP-System eingeführt ist, dann kann man das mit dieser KIP mal machen. Ja, kann man schon tun. Und tatsächlich ist es so, in den Invest reinzugehen, weil moderne KIP-Systeme helfen, überhaupt erstmal zugänglich und nutzbar zu machen. Und wie wir alte Agilisten und ihr als Lernerfahrer auf der Lernheilskonferenz, im Besonderen, Lernen geschieht ja nicht vor der Nutzung, sondern dadurch, dass man es tut und Erfahrungen sammelt und dann lernt. Und das Gleiche muss halt auch mit der Klinik. So, genug Quatsch, wie gelingt jetzt der Wandel? Wir müssen das Wissen dort abholen, was steht. In den internen Tools, in den Prozessen, in den Gesprächen, was ich gerade sagte. Also ideal ist es eigentlich, die Gespräche mitzuschneiden und irgendwie alles aufzunehmen, metakognitive Systeme in der Organisation zu etablieren und dadurch Nutzung zu haben, Feedback-Systeme zu integrieren in den Anwendungen. Ihr kennt es, die einfachste Form, Daumen hoch, Daumen runter, könnt ihr aus Chat-GPT. Es gibt noch ein paar schlauere Dinge, wie man das umbauen kann, damit ich auch die Querverbindungen rausbefomme. Also die Querverbindung, wenn du jetzt gerade ein System nutzt und dein Kollege in der anderen Abteilung auch ein System nutzt, die AI daraus Rückschlüsse erzielen kann, beispielsweise die dann wiederum helfen, bessere Unternehmensentscheidungen zu treffen, um dann am Ende besser Datenschutz zu stehen. Das Architekturprinzip ist dezentral-zentral. Die Agenten operieren zwar in Kraftdormänen, sind aber verletzt über eine zentrale, semantische Plattform. Aktuell ist es so, das hängt ein bisschen mit Halluzination zusammen, wenn man zu viel Kontext im System reinklickt, ist so ein bisschen wie Harald Junkel, wenn er zu viel getrunken hat, dann wird er ein bisschen wirr und kann da nicht gut mit umgehen. Deswegen kann man beispielsweise die Agentensysteme nach Fachdomäne schneiden, braucht aber dann auch schon mal 100 Orchestratoren oder ähnliches, die dann damit umgehen. Wie geht man vor? Wir müssen schauen, dass wir die Informationssilos zu vernetzten Wissensgrafen machen. Also da kommen wir wieder so aus der Grafentheorie. Wie kann ich quasi einzelne Wissensknoten, die tatsächlich für die AI nutzbar machen. Microsoft hat ein Konzept am Start, es nennt sich Graph Rack. Gerüchte besagen, dass es nur dazu bringt, damit ihr noch mehr Token-Euro an Microsoft zahlt, weil es wirklich arschteuer ist. Aber in die Richtung ist es gut, grafenbasierte Systeme zu nehmen. Statt Prozesse zu dokumentieren, brauche ich adaptive agentengesteuerte Abläufe. Das heißt, ein System, bei dem ich als Mensch das System benutze, aber unten drunter etwas quasi mitschneidet oder mitbekommt, was ich tue im jeweiligen Kontext. Ich muss in lernende metakognitive Systeme reingehen und in kontextbasiertes autonomes Handeln. Und das mache ich stufenweise. Das heißt, ich fange nicht mit dem vollen Programm an, sondern ich fange mit kleinen Schritten an, um mich da nach vorne zu bewegen. Aber wenn ich jetzt heute erst mit dem Einfachen weg anfange, dann bin ich vielleicht schon zwei Jahre zu spät. Also dessen sollte man sich auch ein bisschen bewusst sein. Meine zentrale These ist, Intelligenz entsteht dort ein bisschen vernetzt, reflektiert und handlungsfähig wird. Die metakognitiven Systeme erkennen nicht nur die Lücken, sondern sie handeln auch darauf. Und damit bekomme ich eben große Wettbewerbsvorteile. Ja, hallo. Danke. Kurz die Anmerkung vielleicht von meiner Seite. Wir benutzen bei uns im Unternehmen Systeme, die RAG-basiert sind, aber gleichzeitig auf einen Wissensgraph zugreifen. Also wir benutzen auch eine Graph-Datenbank. Die wird demnächst auch auf Graph-RAG umgestellt und wir machen damit extrem gute Erfahrungen, weil die Relevanz der Ergebnisse deutlich höher ist als in einem einfachen Chat-System. Und das eben auch gerade quellenübergreifend dann mit Hilfe von Metadaten und Verschlagwortungen gut funktioniert, weil wir dann die Relevanz und Kontexte, das was vorhin angesprochen wurde, gut finden. Das, was unterschätzt wird, ist tatsächlich aus meiner Erfahrung heraus jetzt die Notwendigkeit, genau dieses System hochgradig zu kuratieren und dafür auch geeignete Prozesse zu haben. Das ist der Schlüssel zum Erfolg an der Stelle. Also das ist nichts, was immer wie die Informatikkollegen kommen dann immer schnell und sagen, ja, das können wir auch generieren. Funktioniert nicht, haben wir ausprobiert. Also das ist ein Element, das Kuratieren braucht. Da geht es aus meiner Sicht heute noch nicht, zumindest nicht zuverlässig und nicht sinnvoll über ein erneutes Generat aus einem GPD. Ja, also kann ich in Teilen bestätigen. Danke erstmal für deinen Beitrag. Würde mich auch interessieren, im Nachgang nochmal ein bisschen in den Erfahrungsaustausch mit dir zu gehen. So Themen wie Data Labeling und ähnliches, da kommt man teilweise nicht drum herum. Aber wenn man in Richtung synthetische Dataset-Generierung beispielsweise denkt, man kann schon einen Teil tatsächlich automatisieren, weil beispielsweise auch das Testing ganz anders verläuft, als jetzt in der klassischen Softwareentwicklung, wo ich einen Unit-Test schreibe. Danke nochmal für den Beitrag und auch eine Bestätigung, dass einfach ein REC-System irgendwann an die Decke sozusagen stoßen. Ja, was hindert Organisationen? Wir können sagen aus der Erfahrung heraus, Faktor 10 als Beschleunigung ist nicht das Ziel, sondern der Ausgangspunkt. Das heißt, jegliche AI-Lösung, die wir bauen, stellen wir fest, dass wir Minimum als Faktor 10 haben beim Einsatz von KI-Systemen, die agentisch agieren und um das, wie gesagt, erfolgreich zu nutzen, AI-Systeme abteilungsübergreifend denken, vielleicht aber auch die Gelegenheit nutzen, um die Prozesse komplett neu zu denken und nicht zu sagen, okay, ich behalte den Prozess und kriege da halt jetzt ein Tooling dazu, was mir den Scheißprozess halt scheiß digitalisiert und am Ende vielleicht ein bisschen schneller macht, sondern vielleicht auch die Gelegenheit nutzen, das neu zu gestalten. Als ich das funktionalisieren und mit einzelnen AI-Tools nachbauen, dann rate ich dringend ab. und vor allem in Plattformen zu denken für vernetztes Wissen und autonomes Handeln. Die Stärke von AI ist eben das vernetztes Wissen. Gerade sowas, die Lemantik über GraphRank oder was ich vorhin erläutert habe, um aus den Dokumenten Sinn zu kriegen, ist das, was wir im ersten Schritt der Maschine zugänglich machen, um dann auf dieser Basis tatsächlich neues Wissen und neue Erkenntnisse zu generieren. Es gibt ein Open Source Projekt, was wir auch ganz gerne nutzen. Rally AI heißt das, da brauche ich kein Power BI mehr, um meine Business Charts für den CFO zu machen, sondern ich stelle einfach meine Frage und kriege dann mein ganzes Dashboard automatisch generiert auf Basis der Frage. Weil einfach die Maschine entlang des Kontextes weiß, was ich als CFO wissen will. Und wenn die Daten angeschlossen sind, dann kriege ich halt ein schönes Dashboard mit meinen Graphen entsprechend raus. Ist für alle Consultants, die so Dashboards bauen, ein bisschen doof. aber den CFO freut es vielleicht, weil man muss nicht immer jeden Report neu generieren. Ich weiß nicht, wer schon länger in der IT ist, Crystal Reports und ähnliches, falls das noch ein Begriff ist, was haben wir uns da durchkonfiguriert. Das sind alles unnütze Dinge, die wir nicht mehr brauchen. Was ist uns wichtig? Entscheidungssysteme bauen statt Konzepts. Konzepts generieren kein Mehrwert, kein Business Impact, Produktionsweifel, KI-Architekturen. Wir sind ein großer Ressource-Vertreter. Ich komme auch gleich noch auf eine Beispielarchitektur und vor allem lernende Agenten mit Wirkung im Alltag. Und das Wichtigste, was ich euch mitgeben möchte, wenn ihr eure AI-Tools im Unternehmen anguckt, schaut drauf, habt ihr eher Einzeltools oder seid ihr schon in Richtung eines Plattform-Gedankens unterwegs? Und diejenigen, die in Richtung einer Plattform gehen, die werden, glaube ich, auf einem guten Weg sein, die nur Einzeltools haben, da wird es auch schwierig sein. Ich habe ja auch so ein bisschen erzählt, was Produktentwicklung betrifft. Ich habe keinen Bock mehr auf Scrum, bin ich ganz ehrlich. Ich habe vor zwei, drei Jahren schon Vorträge gehalten, dass mit Cloud-Native ich eigentlich gar kein Scrum mehr brauche, weil wenn ich täglich Features release, brauche ich diesen komischen Zwei-Wochen-Container nicht mehr, damit der Manager zufrieden ist und dann am Ende die Entwickler zusammenscheißen kann, wenn unsere drei Storys nicht geschafft haben. Das wird jetzt nochmal eins schlimmer, weil ich mit AI in der Softwareentwicklung Features in Stunden kriege oder in Minuten. Und wer mal Cloud Code ausprobiert hat, das ist ein ziemlich gutes Tool. Hier rechts die GIF-Grafik ist ein Migrationsagent, den wir mal gebaut haben. Wir haben große Kompetenz im Bereich Softwaremodernisierung und haben ein Tumier gebaut, ein Agentensystem, was in der Lage ist, von Programmiersprache A nach Programmiersprache B zu migrieren oder von Framework Version X auf Framework Version Y inklusive vollständiger Code-Dokumentation des Altcodes und ähnliche Geschichten. bis hin zu, dokumentieren wir mal meine SAP, ZBARPs, die 11.000 Schritte, die ich da habe, was machen die denn eigentlich und wo sollte ich die hin migrieren? Das heißt, ein Automat, ein Agentensystem auf beiden grafen, das autonom ergibt. Damit man in der Softwareentwicklung erfolgreich mit AI ist, ihr kennt das alle, White Coding und so weiter, wenn man es ernsthaft macht, geht man vor wie ein grüber Architekt und wie ein grüber Planner. Das heißt, ich gehe erstmal als Softwareentwickler mit dem AI-System in eine planerische Diskussion. Was möchte ich eigentlich erreichen? Und lasse mir mal einen Plan geben. Und erst dann gehe ich in ganz kleinen Schritten voran und baue mir noch Software-Systeme. Produktstrategie, falls jemand von der Product Owner ist, die haben auch keinen Job mehr so richtig, weil das macht ihr ja auch. Produktstrategie kann ich mir direkt durch die Ergebnisse geben lassen. und Chat-GPT-Suite darin, hundert von Seiten zu generieren, die sich am Ende keiner durchliest. Was ich viel schöner finde, ist, wenn ich nicht mehr User-Stories habe, weil ich die Garantien im Gespräch mit ihr als Stakeholder ein Tool habe, beispielsweise mir genannt, UiSard, mit dem ich einfach den Prototypen der Sache, die du mir beschreibst, schon mal direkt bauen lasse und dann können wir uns gemeinsam mit aufknallen und sagen, klick das durch, Fällt dir das? Was soll ich noch ändern? Und schon habe ich den Anfang der Entwicklungsweise gegangen. Ist natürlich doof für Softwareentwickler, aber eigentlich nicht doof, weil es wird noch mehr Softwareentwicklung gebraucht, weil die Unternehmen doof sind. Es hat noch nie in der Geschichte so geklappt, dass wenn Ressourcen eingespart worden sind, sondern die Menschen wollten immer mehr. Und ihr kennt es vielleicht aus den Budgetgeschichten. Die Speckles der Unternehmen sind voll, die Entwicklerteams kommen nicht hinterher, auch wegen der Scheißtechnologie, die im Einsatz ist und alte Legacy-Systeme und so weiter. Das kann ich jetzt alles anders gestalten, wenn ich das möchte. Und die nächste Grenze wird jetzt auch gerade geknackt. Es geht gerade viel VC-Geld rein, um zu gucken, wie kann ich Infrastrukturen, also diesen ganzen DevOps-Gedanken, Cloud-Provisioning, wie kann ich das durch AI-System erledigen lassen. der Kubernetes schon mal gehört hat, das ist so ein Orchestrierungstool für Containerschiffe in der digitalen Welt, wo die Software drauf läuft, gibt es auch mittlerweile Agentensysteme, die meine Container-Infrastruktur und meine Kubernetes-Infrastruktur komplett automatisch selber bauen. Also da geht gerade viel vor Segel ein und ich selbst habe da jetzt gerade keine Angst davor, weil am Ende wird es uns helfen, die Dinge schneller und besser umzusetzen zu können. Ich glaube, wenn man als Organisation auch begreift, wie kann ich das für mich zunutze machen, wird man da gut ins Handeln kommen. Soll ich mich ein bisschen beeilen, wie kann ich ins Handeln kommen? Kurzfristig Engpässe identifizieren, Use Cases formulieren. Wer keine Idee für Use Cases hat, der guckt entlang für Engpässe. Dort, wo die Engpässe sind, kann ich gucken, kann ich einen Probe für Impact aufbauen, kann ich ein Konzept. Mittelfristig muss ich in die Plattform denken, meine semantische Architektur aufbauen, meine metakognitiven Agenten bauen und am Ende langfristig sorgen, dass meine Organisation zu einer selbstlernenden AI-Organisation mit dem Wissen als Infrastruktur und nicht als Abfallprodukt, das eigentlich im Prozess entsteht. Das ist, glaube ich, ganz wichtig. KI-Systeme als kollektive Partner. Ich habe auch den Beitrag gesehen, der AI-Kollege hat jetzt eine Personalakte an, die ich dem ins Gesicht gebracht habe, das sind keine Menschen, ich brauche keine Feedback-Bespräche mit denen, ich will auch keine Personalakte anlegen. Wie Zeit ich aufhören, um eine Personalakte anzulegen, da bin ich schon wieder drei Schritte weiter mit der AI. Und für die Organisation braucht man mehr Agilität denn je. Ich brauche mehr Automatik, weil ich sonst den Hebel, den AI mir bietet, gar nicht umsetzen kann. Wenn ich in meiner Organisationsstruktur verbleibe und nur schaue, wie kann ich innerhalb des einzelnen Teilseiten, die Hebeleffekte, die solche AI-Systeme gibt, gar nicht nutzen kann. Das heißt, am Ende geht es darum, Systeme und Strukturen zu bauen, die mitdenken und handeln für mehr Wirkung. Hier ist ein Beispiel, das ist leider nicht so gut, den QR-Code könnt ihr euch herunterladen, eine Beispielarchitektur auf der Basis zu Open-Source-Komplimenten, wie man sowas implementieren kann, um am Ende nicht nur die eigenen Unternehmenssysteme zu verbinden, sondern tatsächlich auch dafür zu sorgen, dass sich von produktiven Einsatz erfolgreich benutzt. vergessen einfach viele. Man hat halt mal so ein Problem, Konzept gemacht, so ein kleines Tool implementiert, aber wenn es dann darum liegt, es auf 10.000 Mitarbeiter auszurollen, dann wird es schwierig. POC Graveyard. Ja genau, deswegen nicht Proof of Concept, sondern Proof of Impact. Wir wollen den Impact nutzen. Wir wollen jetzt 20.25 gibt es keine Cuses, wir müssen jetzt Geld verdienen mit AI. Das ist eigentlich das Versprechen, was dahinter steht und wie ich damit arbeiten muss. Und damit bin ich am Ende und Ich hoffe, Sie haben zuerst Fragen und Kommentare. Vielen Dank. Metakognition hat mich Microsoft erfunden. Klar, kommt aus der Psychologie der 70er Jahre, aber man findet ja vieles von diesem mentalistischen Bild. Man hattest schon am Anfang drin, Wissen, welches nicht wirkt, ist wertlos. ein zweischneidiger Satz, weil Wissen hat ja immer so einen potenziellen Charakter. Du hast ein bisschen Klang zum Wissen, das nicht sofort wird, ist wertlos, aber natürlich Wissen hat man ja teilweise auch in seiner Richtung genau dafür, dass es potenziell morgen wird. Aber klar, also die Gefahr, dass man Sachen anwesend wird. Wenn es über lange Frist nicht genutzt wird, sollte man mal fragen, was es ist. Ja, Plattform statt Silos, eh klar. Insofern würde ich sagen, mit Wikis, wenn du Open by Default machst, wie wir bei Simus seit 2008 in einem Wiki. Also das ist das, was die AI liebt. Das Chunking ist perfekt. Es gibt mehreren Versionen. Sharepoint-Seiten ist man so zweit bis drittbester Sieger und PDF ist man dann am Hund. Jetzt hast du beschrieben, da gibt es Möglichkeiten, aber klar, die Hyperlinks, die im PDF sind, die kannst du am Ende dann warten, möglicherweise mit AI. Und weil du ja auch gesagt hast, ja, es startet an Strukturen. Mir fällt immer ein und auf, dass tatsächlich in Bezug auf Wissensmanagement einer der Altfälle des Wissensmanagements, NONAKA, hat die Hypertext-Organisation schon 1995 geschrieben. Können wir jetzt ja sagen, der ist auf den Zug aufgesprungen, Organisationstheoretiker. Aber es ist sehr interessant, wenn man sich das anschaut, das Bild, die Pyramide ist auf den Kopf gestellt und es steht da schon drin, alle haben Zugriff auch möglichst viel. Und da weißt du dann, der hat nicht nur theoretisch ein Konzept geklaut, sondern hat auch nicht verstanden, was die Technik benutzt. Genau, so muss es eigentlich auch sein. Bei uns ist auch das Wiki open by default, write by default. Aber ich habe Organisationen kennengelernt. Da durfte man nur die PR-Abtagung immer einpacken. Und solche Sachen. Das ist halt passend. Da haben wir als 2.8 eigentlich aus der Not eine ziemlich radikale Zeit getroffen. Und haben gesagt, das ist so. Und du kannst zwei Informations-Subräume bauen, aber du kannst nicht abschließen. Und das ist eigentlich, seit dem AI und Rack-Systeme, da sind irgendwie der Traum, weil das robuste Hyperlinks, das Zeug ist auch zu viel von Kommentaren. Ja, haben wir einen Kommentar. Ja, das ist vielleicht noch zuerst kurz. Ja, ist eine direkte Antwort auf den Kommentar von eben. Wir sind auch mit einer topic-basierten Inhaltsstruktur unterwegs und eigentlich gedacht hat sie dann, glaube ich, als erster der Bamba-Busch um den zweiten Weltkrieg herum, as we may think. So, das wäre noch die Ergänzung dazu. Es ist einfach, was im PDF ist, ist tot, ist vergraben. Brauchen wir nicht mehr danach. Einfach, weil es auch mit dem Junking nicht funktioniert. Wenn ich 200 Seiten PDF zerlegen will, keine Chance. Dann kann ich keinen Kontext herstellen. Vielen Dank.