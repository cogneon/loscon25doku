Ja, ja, ich weiß. Du bist heute von zu Hause aus da, ja? Ich bin von zu Hause aus. Mir war es dann zu stressig, jetzt irgendwie noch mit reinzukommen, weil ich hier noch ein paar Sachen erledigen musste. Die Aufzeichnung läuft jetzt. Okay, ja. Das heißt... Was du alles mitgeschnitten haben möchtest. Ich hatte gerade so einen privaten Talk deswegen. Ja gut, wollen wir noch warten. Jetzt sehe ich noch Yvonne, die mit dabei ist, zumindest sich eingemeldet hat. Ich muss noch mal kurz in meinem anderen Raum gucken, ob da auch alles in Ordnung ist. Ja, gib uns mal noch ein bisschen eine Sekunde, oder Julia, weil gerade schaut es ja noch nicht so voll aus. Nee, das ist nicht so. Ja, dann ist es so. Ich sitze hier vorne quasi. Ja. Ja. Das ist auch beim Barcamp möglich, dass man sagt. Es passiert, was passiert. Beim Barcamp kann man auch theoretisch ja sagen, es passiert nichts. Ja, das ist irgendwie alles fein. Ich sage immer, es geht nicht um die Anzahl der Menschen, die da sind, sondern es geht irgendwie darum, dass man ein gutes Gespräch darüber führt und das ist auch vollkommen fein. Also 20 Session zu haben, ist erst einmal noch kein Wert. Und mit den paar Menschen, die Interesse daran haben an dem Thema, das ist eigentlich viel wichtiger. Julia, ich weiß jetzt nicht, ob du sozusagen in dem Fall gehijackt bist, weil du halt irgendwie Raumbody bist. Das heißt, du dürft dich mit dem Thema beschäftigen. Ja, kommt nochmal. Ja, ja, ihr müsst... Ich hab schon gesagt, es liegt wahrscheinlich auch ein bisschen an der Wärme, bis Raum ist. Ja, komm doch mal ein bisschen weiter nach vorne, weil dann sehen wir uns ein bisschen. Das wäre doch klasse. Sorry. Alles gut. Wenn wir so eine kleine Runde sind, dann können wir wahrscheinlich auch mal eine ganz kurze Runde machen, wer ein bisschen welchen Hintergrund zur Softwareentwicklung hat. Julia, ich glaube bei dir. Wie siehst du einen Hintergrund zur Softwareentwicklung? Ich habe ungefähr gar keinen Hintergrund zur Softwareentwicklung. Ich arbeite im Wissensmanagement und wir sind im Onboarding für Microsoft sozusagen, für 365, für die neuen Kollegen da, aber Programmierende Entwicklung. Und wie haben wir dann noch da sitzen? Das tut mich denn so gut? Du kannst einfach da hinreden, das funktioniert, glaube ich, ja. Okay, genau, ich bin mannlos. Ich glaube auch, ich wähle mich eins und ich Mir war nicht klar, dass es schon losgeht. Ich bin Bauernführer und habe tatsächlich früher ganz viel Softwareentwicklung gemacht. Das war mein erster Job nach dem Studium, tatsächlich auch CAD-Software geschrieben zu haben. habe dann 13 Jahre im Konzern eben auch die CAD-Konstrukteure betreut und eben unsere Software weiterentwickelt. Bin jetzt aber seit dreieinhalb Jahren bei der IP. Man hat auch nur Microsoft 365 Projekte und seitdem habe ich, ja doch, ich mache nochmal zwei, drei Zeilen, wo wir kommen, wir können mal ausgeredet werden. Ich habe jetzt diese Anforderungsaufnahme mit Kunden und habe dann halt Entwickler gegeben, die dafür das machen. Ich habe das in meinem Konzern durchaus auch ein Team und habe es selbst immer noch eingebunden. Okay. Das war ein Langschen, das würde ich einfach mal mit ein, für den Widerstand auswärts gewesen, auch nicht vielleicht durch das Thema Weibkommunik, vielleicht nicht als jemand, der ja immer Softwareentwicklung verstanden hat, bei manchen denke ich schneller zu Lösungen wie so ein Boom of Concept, geht denn das oder so, kommen kann, ohne jedes Mal auf die doch begrenzte Ressourceentwickler bei uns einfach zugreifen zu können und zu sagen, vielleicht kann ich manches auch manchmal doch schon selbst herausfinden. Das war so die Idee, die ich hatte. Okay. Dann gebe ich auch ein bisschen Hintergrund. Also ich habe 15 Jahre Software entwickelt. Ich war auch Entwicklungsleiter von zwei Firmen und habe dann in die Richtung Scrum Master, Agile Coach, Trainer und mache jetzt auch viel Trainingsprogramme, sage ich mal. Und vor allem auch Entwicklungspfade für Entwickler. Und das ist mein Thema. Ich kann ja mal gucken, wenn ihr auf ein Board dorthin kommen wollt, weil ich habe auf dem Board, ich zoome mal ein bisschen raus, hier Session 4, 14.15 Uhr, ein bisschen was am Board aufgebaut. Könnt ihr da hin navigieren? Klappt das so weit? Weil ich will ja die anderen hinziehen, weil da kann man sich total unbeliebt machen. Das wisst ihr ja auch so. Mal kurz die Moderation anschmeißen. Und wie ich sozusagen dieses Future Backwards gemacht habe, da habe ich mir gedacht, naja, wie sieht denn das denn aus in zehn Jahren mit der Softwareentwicklung? Und wie würde denn Heaven ausschauen, wie würde denn Hell ausschauen? Und ich habe dann mal eben ChatGPT gefragt und da seht ihr halt, Softwareentwicklung wird zur Dialogarbeit mit intelligenter Unterstützung. Ich würde mal sagen, das ist es schon heute. Es ist viel Dialogarbeit und die intelligente Unterstützung kommt heutzutage eher von Menschen und in Zukunft eben auch von der KI. Dann das andere, der Mensch definiert Vision, Werte, Ethik und Zweck. Das ist das, Magnus, was du so ein bisschen angerissen hast. Nach dem Motto, und dann macht die Maschine den Rest. Das habe ich mal fett gemacht, weil da habe ich so meine Zweifel noch dran. Aber da bin ich vielleicht jetzt der Champion Skeptik. Das andere, Teams werden kleiner, fokussierter, dezentraler, aber durch KI hochskaliert. Kann ich mir auch gut vorstellen. Und wieso tue ich mich mit dem zweiten Punkt ein wenig schwerer? Also ich habe viele Softwareunternehmen, kriege ich mit, wenn die gerade jetzt in größeren Unternehmen, da haben die halt Software, die zum Beispiel 10, 20 oder 30 Jahre im Einsatz ist. Und wenn die dann da so eine Software mal verändern sollen, dann schaut das echt so aus, wie damals der Schliemann die Pyramiden geöffnet hat und dann versuchen sie die Hieroglyphen da an diesen Wänden zu entziffern. Also sprich, das ist nahezu unmöglich oder sauteuer, wenn Menschen die Fähigkeit verloren haben, diese Systeme zu verstehen, die zu verändern. Definitiv. Erfahrung durchaus auch. Als ich da zu meinem letzten Arbeitgeber nicht jetzt interessiert bin, habe ich eben eine Software übernommen, die Jahre zuvor vom Entwicklerteam hergestellt worden sind. Und der war bis drei Jahre bevor ich dazugekommen bin, ist der das Unternehmen verlassen und den Daten auch mal nicht. Und das Lissen war halt komplett tot. Also ich hatte glücklicherweise noch einen Dienstleister, der sich halt mit beschäftigt hatte, auch der damals mit dabei war, dass mir geholfen hat, da reinzukommen. Aber das ist ja zuständig, wenn sie nicht auch vor. Die KD programmiert dir was und du verstehst ja gar nicht mehr die Hintergründe, die da drin sind. Warum hatte ich das denn so gemacht? Und deshalb, also ich bin, ich gehe da vollkommen mit bei dir, dass Vision, Werte, Idee und Zweck vielleicht nicht ausläuft. Okay, und ich gucke jetzt mal Yvonne, du bist ja noch remote zugeschaltet, wenn ich das richtig sehe. Wir haben uns mal kurz gesagt, welche Art von Kontext oder Hintergrund wir haben. Ah, Yvonne ist scheinbar noch anderweitig beschäftigt. Okay. Sobald du dich einschalten wirst, gib Bescheid. Jedenfalls, und wo ich mal drauf schauen will, ich hatte mal davor eben mit ChatGPT mal so eine positive Vision mal zusammengestellt und ich würde mit euch mal da drüber gehen wollen und so sagen, wie halten wir das für realistisch in 10 Jahren? Glauben wir, ist das irgendwo dazwischen? Oder ihr rot, habe ich gesagt, da bin ich ja mal gespannt, das sehe ich ja noch nicht. Ich fände es total lustig, wenn man in 10 Jahren da mal drauf schaut, wie man das dann irgendwie eingeschätzt hat. Das würde ich gerne machen, um mal überhaupt mit dieser Prognose der Zukunft uns auseinanderzusetzen. Und im Anschluss, also ich ziehe mal nach rechts, ich habe hier auch noch wie so ein typischer Arbeitstag eines Entwicklers im Jahr 2035 aussehen könnte. Kann man mal drüber gucken, aber was mir wichtiger ist, dass wir vielleicht da nach hinten kommen, auch noch, was gilt es heute für Softwareentwicklungsteams zu lernen, um uns auf diese prognostizierte Heaven Zukunft vorzubereiten oder um die Hell-Distribie zu vermeiden. Das heißt, die Idee ist, wir machen das davor recht flott, damit wir dahinter zur Diskussion kommen. Ist das erst einmal so vom Weg nachvollziehbar? Das habe ich mir heute früh alles ausgedacht, also deswegen ist das jetzt ein Experiment. Ich hoffe, dass das passt. Mein Kopf ist schon so ein bisschen durch, dass ich es noch nicht ganz verstanden habe, aber lass uns das mal machen, würde ich jetzt sagen. Okay, gehen wir mal so rein. Jetzt habe ich nochmal was gehört gehabt, aber passt so. Das eine ist, dass künstliche Intelligenz als Co-Entwickler wird zum Standard. Wir haben multimodale Co-Piloten, wir haben Agententeams und Code ist nicht mehr zentral, Intent ist zentral. Da könnt ihr euch mal den Text durchlesen und was ich euch einfach mal bitte, man kann sich hier so einen Stift nehmen und mal sagen, ich würde euch irgendwie 5th Point ist wahrscheinlich die richtige Größe für die Dimension, die ich gewählt habe. Halte ich jetzt das denn selber für realistisch? Einfach so wie einen Punkt setzen, zum Beispiel multimodale Co-Piloten halte ich mit dem, was ich gerade so in den Teams sehe, für total realistisch. Und ihr könnt genauso eure Einschätzungen machen und dann würde ich, das sind insgesamt sechs Abschnitte, die wir haben, dass wir danach einfach mal drüber reden über das Bild, was da entsteht. Das sind ja jetzt nur drei Dots, die wir letztendlich setzen. Also Julia, du hast sozusagen die komplette Außensicht. Du weißt gar nicht, was die Softwareentwicklung macht. Wir können auch unterschiedliche Farben wählen übrigens. Vielleicht nimmst du ja eine Farbe, dann wissen wir, das ist für jemanden oder ein anderes Symbol. Coole Sache. Kann man auch machen. Und das gleiche ist wie mit Agententeams. Also da bin ich jetzt mal eher so rechts. Und dann so Code ist nicht mehr zentral, Intents ist zentral. Teams formulieren Ziele, Regeln, Einschränkungen und übernimmt ein sozusagen ein System aus KI-Tools und Runtime-Plattformen. Also das ist so, was ich da so wahrnehme. Magnus, hast du auch eine Einschätzung? Sorry, ich war noch ein bisschen hinterher mit meinen Symbolen, aber ich habe mal angefangen bei den ersten Agententeams. Also das sprechen immer Agenten, die selbstständig dann ein skalierbares Autorisierungssystem für 100 Millionen Nutzern, so in der Art. Also das ist das, was sie da sagen, mit menschlichem Review. Okay. Und jetzt können wir ja mal, also jetzt höre ich mich doppelt gut, es ist schon wieder vorbei. Wenn ich mir anschaue, das erste halten wir alle für realistisch, würde ich jetzt mal sagen, müssen wir mal gar nicht so viel mit diskutieren, aber gehen wir mal zu dem Thema Agententeams. Da ist die Außensicht, Julia, von dir ja mal umgespannend, weil du sagst, jetzt keine Innensicht zum Thema, wie Softwareentwicklung abläuft. Wieso siehst du das auch als irgendwo dazwischen? Ja, also da bin ich auch ein bisschen hoffnungsgeleitet, glaube ich, dass ich hoffe, dass auch immer noch jemand mit Ahnung dessen, was dort herauskommt, nochmal drüber schaut, bevor das automatisch irgendwo eingeht. So habe ich zumindest die Feststellung dort gelesen. Also ich finde, falls ich das jetzt falsch erfasst habe, wie gesagt, das ist warm hier. Und nochmal korrigieren. Mit menschlichem Review, okay, ja. Ja, deshalb irgendwo dazwischen. Also genau, der ist für mich halt entscheidend, glaube ich, bei der Aussage. Und ich fände es nicht ethisch gut, wenn solche Sachen komplett automatisiert, ohne irgendeinen Menschen, der so einen Code auch noch anders übersetzen kann, ablaufen würden. Ich glaube, ein wichtiger Punkt ist tatsächlich in deiner Aussage eben auch vorne bei komplexer Aufgaben. Also unter komplexer Aufgaben kann ich mir das schon auf jeden Fall mehr vorstellen, aber das sind auch so Dinge, wo ich sage, da macht es doch einfach Sinn, auch nochmal solche Dinge eben klarer zu durchdenken. Und klar kann ich mir vorstellen, dass die Agents auch, dass du da halt für verschiedene Dinge halt verschiedene Agents hast, die verschiedene Sachen besser als dein Mensch halt erledigen können und das auch für dich machen. Insbesondere Software-Dokumentation finde ich halt schon mal, also da gibt es natürlich auch ein Riesenpotenzial, wo du sagst, okay, das will keiner wirklich gern machen. Also steht da eine Dokumentation, passt dazu, ja, haken kann, aber dann brauchst du vielleicht nur ein, zwei, drei Sätze halt noch anzupassen. Das passt, glaube ich, schon. Aber gerade komplexe Aufgaben, eben das Skalierbosystem für, genau, 100 Millionen User, das ist halt dann schon so ein Ding, wo du sagst, okay, will ich mich darauf verlassen, dass die KI das schon richtig macht? Naja, und auch, was macht die KI dann damit? Also geht es dann so weit, dass die KI aufgrund von Daten, die sie einfach ausgelesen hat, schon Empfehlungen gibt? Weil, also wenn es dann eben zu solchen Punkten kommt, also macht das noch weitere Schritte auch dann. Also wir können ja sämtliche Daten irgendwie bearbeiten. Also ich bin vielleicht immer nicht ganz sozusagen nur beim Entwicklungsthema. Das macht es für mich, glaube ich, ein bisschen greifbarer. Aber man kann ja Gesundheitsdaten mit Bildungsdaten, mit allem Möglichen zusammenbringen. Okay, und was macht das dann? Also schauen wir denn auf bestimmte Menschen genauer? Was machen wir mit denen? Also da ist es mir schon wichtig, also Datenschutz, Ethik, also von daher, wir können nicht einfach alles hineinfüttern und machen lassen und nicht genau wissen, was da eigentlich passiert, ohne auch nochmal zu gucken, okay, was für Empfehlungen werden denn abgeleitet. Ich frage mich auch in dem Sinn, du sprichst für 3035, in zehn Jahren. Also hat sich auch das Verständnis oder auch die Definition von KI jetzt in den zehn Jahren massiv von dem verändert, wo wir heute stehen? Also heute ist es ja schon noch so, dass wir gesagt haben, das, was wir da als KI bezeichnen, sind ja generative Systeme, die letztendlich basierend auf ihrem Datensatz, den man Ihnen als Beispiel mitgegeben hat, Dinge vorschlagen und nicht wirklich entscheiden, sondern einfach sagen, okay, das passt. Da habe ich, das heißt, haben die in ihrer Datengrundlage ausreichend Daten für eine solche komplexe Aufgabe, 100 Millionen User-System und so weiter, da weiß ich, das macht man so und so, dann kann die das wieder generieren, aber sind das eben Aufgaben, die nicht klar sind und deshalb sage ich komplex, okay, das ist eben nicht im Datenbasis drin, sondern das ist was, was man schon halt nochmal einfach noch entwerfen muss und sagen, mit Trial and Error halt auch Dinge rausfinden muss, dann glaube ich, hängen wir da an, im Punkt, wo das eben auch mit den heutigen Systemen, selbst wenn die sich weiterentwickeln, in neuere Systeme, die Grundlage unserer heutigen GPTs ist ja immer noch dieselbe, auch wenn wir da von Versionen 1 auf 4 auf 4, 5 auf 5 gehen, das müsste sich dann auch in den 10 Jahren verändert haben, wenn das mehr können soll. Alles gut. Ich spring mal über eins drüber, weil das sind insgesamt sechs verschiedene Kategorien. Und ich hätte jetzt immer gesagt, dass wir immer die drei bewerten und uns einfach nur eine anschauen und über die sprechen, weil sonst kommen wir wahrscheinlich zeitlich nicht hin. Und das wäre so das Nächste. Das sind dann selbstoptimierende Architekturen. Dann haben wir Composable Systems. Also wie können Dinge wie Legosteine sozusagen zusammengebaut werden oder Zero Ops. Also Infrastruktur, Developments, Maneturing, Scaling laufen vollständig autonom interagieren. Ihr könnt übrigens das Ganze auch wie eine Skala betreiben. Also ihr könnt euren Punkt auch näher zu grün setzen, selbst wenn er, ich mach das jetzt mal, also bei dem DevOps voll autonom, nur noch mit Domain-Logic. Ich glaube, das würde ich wahrscheinlich irgendwo hier packen. verwendbare KI-Annehmung werden wie Logosteine. Da bin ich vielleicht eher hier. Da bin ich vielleicht eher hier. Und wir können es ja mal so machen, dass immer einer wählen darf, welchen sollen wir denn besprechen? Und lassen wir es mal so in Brown and Robin rumgehen. Julia, du hast schon so gelacht. Willst du es mal machen? Ich bin auch bei der Entscheidung, wo ich mal ein Pünktchen mache. Und Magnus muss auch noch seinen Haken setzen. Und ich finde es übrigens gut, dass wir nicht alle gleich sind. Ja, ich starte jetzt einfach. Ich war jetzt sozusagen gedanklich so bei den selbstoptimierenden Architekten. also das ist was weil da gibt es nicht um inhalte also nach meinem empfinden da geht es sozusagen um um strukturen und um größere zusammenhänge zu sehen um vielleicht auch komplexität zu reduzieren und also das ist was also da habe merke ich selber ich habe weniger störgefühle sozusagen weil es mir da nicht um eine Art von definieren, deuten, irgendwas geht, sondern da geht es irgendwie für mich um Dinge, die meiner Meinung nach total gut zur KI passen, nämlich eine Komplexität zu analysieren, also eine Struktur herzustellen. Da kann ich mitgehen. Das sind von mir nicht der Gefühle. Alles klar. Magnus, du bist irgendwie ähnlich? Hattest du was hinzuzufügen bei Julia oder bist du gleich? Ich glaube schon, dass durch Datenanalyse, was du im Museum mit davon hast, Entscheidungen treffen zu können und das für die vielleicht auch besser treffen zu können als ein Mensch, das sehe ich ganz ehrlich. Das sehe ich bei der Evaluation. Ich glaube schon, dass das nicht komplett kann ich besteuern, deshalb bin ich noch nicht um Geld. Sorry. Da muss irgendwer auch schon mit drin sein. Aber das ist schon starker von der Querida. Das ist die Square auch mal anders. Ich habe mich ein bisschen reingesetzt mit dem Argument von der Julia. Das kann ich nachvollziehen. Ich sage euch aber, wieso ich mich trotzdem damit ein bisschen schwerer tue. Zum einen die Architekturen, die heute aufgesetzt werden, sind in erster Linie mit Domain-Driven Architekturen. Also sozusagen die Architekturen, die dann sozusagen überarbeitet werden, das ist irgendwie eine Geschichte, die werden wahrscheinlich domänengetrieben entwickelt worden sein. Das ist immer das eine. Und das andere, was ich auch spannend finde, also heutzutage, die Menschen, die ich kenne, die jetzt in der Rolle sind, Architekturentscheidungen zu treffen, die haben halt über zig Jahre entwickelt und das gemacht. wie können die sozusagen die Entscheidungen irgendwie treffen, ob Refactoring gut ist oder nett oder eine Architekturänderung gut ist oder nicht, wenn sie das gar nicht mehr tun. Also das ist so, wo ich da meine Bauchschmerzen habe. Ich tue mal hier das noch ein bisschen größer machen, wenn wir reinkommen. Okay, aber wie gesagt, ich habe mich ein bisschen reingesetzt, weil ich kann den Punkt, Julia, von dir schon total verstehen. das ist ja was, weißt du, da in der Technik und hat so nach dem Motto keine ethische Betrachtung und keine Domainbetrachtung. Ja, da fehlt mir dann vielleicht sozusagen das Basiswissen in der Entwicklung sozusagen, was die Architektur in dem Moment bedeutet. Ich war jetzt eher bei sozusagen, das erzeugt eine Zusammenhänge zwischen Datensätzen. Und da ist mein Wissen vielleicht nicht ausreichend dann gewesen. Nö, passt schon und ist ja super. Also wenn wir alle einer Meinung wären, hätten wir nichts zu diskutieren. Irgendwie, da finde ich es so viel angenehmer. Menschliche Teams, kleiner, diverser, strategischer. Also wir haben A, kleinere hochspezialisierte Kerngruppen. Ich tue mal den einen Vorhang hier weg. Dann Domänen und Problemorientierung. Teams sind um Geschäftsprobleme und Nutzerbedürfnisse herum organisiert und nicht mehr um Systeme und Komponenten. Und das KI als Teammitglied. Und ich würde mal sagen, da können wir uns ja auch mal unsere Punkte setzen. Da bin ich dabei. Bin ich auch dabei. Das ist ja, das ist lustig. Wir wissen uns, dass das so ist. Das ist jetzt mal gerade bei der zweiten Dominik-Problem-Modivierung. Mein Wunsch wäre ja, denke ich, dass es so ist. Vielleicht wahrscheinlich eher nicht. Es ist schon die Einschätzung, ob es so sein wird, denke ich mal. Also kommen wir mal umbegucken. Aber da fällt mir gerade auf, ich muss mal nochmal verrutschen. Genau, danke, dass du es nochmal gesagt hast. Aber ich bin da eher hier. Aber das ist cool. Kannst du Kari als Teammitglied nochmal erklären, was du von dir verstehen würdest? Du musst dir vorstellen, das ist dann wie ein Agent, mit dem du halt irgendwie auch sprichst, der eine bestimmte Rolle hat. Ich meine, aktuell promptest du ja auch GPT, dass du sagst, hey, du bist der und der und der und du hast die und die Aufgabe und hier wäre es halt die Rolle eines QA-Leads. Kann ich nachher, wenn wir da noch drei zu haben, also eine relativ für mich einen fremdlichen Einblick in was ich dabei sein konnte. Ja, das ist cool, unbedingt. Lass mir Magnus noch abstimmen. Und dann würde ich mal sagen, lass uns mal über die dritte Reihe da, über das KI als Teammitglied reden, weil ich glaube, das ist das, wo wir am weitesten auseinander liegen, oder? Du schattest. Was denn? Ich finde es total spannend, dass insbesondere du und vielleicht auch eher wir Dinge eher immer so ein bisschen anders um einschätzen. Habe ich eben schon bei den Zweifens gesehen. Du machst dann hinten die schwarzen Punkte und kommst mit dem schwarzen Punkt da vorne, wo ich Ihnen reden sitze. Das ist von daher finde ich die Austausche total gut, dass wir eben verschiedene Meinungen unterbringen. Und deshalb, gut, lass uns da bitte genau da, wo wir große Unterscheidungen haben, nochmal drüber sprechen. Genau, ich mache das nur, ich setze die Bohnen nur, damit wir auf jeden Fall diskutieren. Nee, so ist es nicht. Das war nur Spaß. Dann sprechen wir mal mit KI als Teammitglied. Julia, du bist ganz rechts, oder? Ja, ich bin ganz rechts. Für mich ist es ein Horrorszenario. Also ich mag auch nicht sozusagen immer dieses, KI ist der neue Praktikant im Unternehmen. Ich habe gestern schon hier an so einem Tisch mal gesagt, Ich finde es ganz fürchterlich, wenn wir da wirklich menschliche Personen mit ersetzen wollen. Das ist ja lang angelegt, wahrscheinlich auch teilweise, da wird es der Fall sein, aber ich finde das so dramatisch, was Wissensweitergabe angeht. Gerade so diese Rolle von, ich steige irgendwo neu ein. Ich habe tatsächlich vielleicht nur ein Praktikum, aber ich lerne so viel. Wenn das alles nur noch an KI geht, das passiert einmal und nie wieder, weil dann ist dieser Agent fertig. Sonst habe ich vielleicht immer mal wieder gern Menschen, denen ich sozusagen Einblicke gebe und das ist für mich so eine Komponente. Oh, die clasht total. Außerdem finde ich auch, also jetzt selbst mal weg von der Praktikrolle, ich schaffe mir sozusagen sowas wie einen Coach an und bespricht das nicht mehr mit meiner Führungskraft. Ich habe jetzt den KI-Coach, der mir bei Unsicherheiten hilft, der mich irgendwie berät, der mich da durchbringt. Aber ich mache eine große Lücke auf. Also erst mal weniger Verbindung zu den echten Menschen, die da sind, mit denen ich dazu eigentlich meiner Meinung nach ins Gespräch gehen sollte. Und deshalb bin ich da total auf der roten Seite. Wobei das Rot, was ich so raushöre, ist, lass es nie dazu kommen, oder? Mehr so auf die Art und Weise. Okay, cool. Yvonne, kannst du folgen, was wir gerade machen? Wir hören dich nicht, du musst dich entstummen. Ja, ich habe ja ein bisschen zugehört. Ich konnte noch nicht mitmachen, weil ich konnte nicht sprechen während der Zeit. Ja, ich kann das nachvollziehen. Okay, du kannst es nachvollziehen. Du kannst auch mitmachen. Du brauchst dir bloß einfach ein anderes Symbol oder einen anderen Punkt irgendwie geben. Ach, weißt du was? Ich tue dir mal kurz ein Symbol reingeben. Eins, was lustig ist. Sagen wir mal ein Beach-Symbol oder so. So, da. Also wenn du dich dann... Ups. Das müsste doch eigentlich gehen, oder? Mhm. Vielleicht woanders gelandet. Keine Ahnung, was er jetzt hier macht. Ich kann es nicht machen. Habe anscheinend das recht nicht. Aber du kannst einfach ein anderes Symbol nehmen. Ich mache dir mal ein Quadrat hin. Das kriege ich auf jeden Fall. Wenn du dich selber dann irgendwo deine Einschätzung auch mit reinnehmen willst. Da müsste ich aufs Konzeptwort jetzt gehen. Ja, wenn du das willst. Musst du aber nicht. Also du kannst, ansonsten kannst du einfach auch mitdiskutieren. Ja, ich würde mich auch da irgendwo in dem Roten sehen, weil ich, ja, ich möchte das auch nicht. Also ich würde da auf gar keinen Fall hinwollen. Obwohl ich denke, es ist wahrscheinlich realistischer, das irgendwo im gelben Bereich zu sehen. aber ich hoffe, dass es im Roten ist. Ah, sind sie mir nur noch Agent oder Posten? Magnus, wie sieht es bei dir aus? Also ich glaube schon, dass das mehr in die Richtung kommt, aber es ist schon realistisch, dass das passieren kann. Du sagst ja auch, ihr beide habt beinahe gesagt, ihr wünscht euch das nicht, ist eh das eigentlich eh nicht. ich sehe es aber auch dieses wirklich als Teammitglied also das das es unterstützt, dass es als Agent Dinge übernimmt, aber wirklich dieses Thema als Teammitglied da bin ich mir tatsächlich nicht so ganz sicher das was Microsoft ist ja auch so ein bisschen propagiert, wir sind nur der Agent-Boss, das heißt ich habe gerade keine Mitarbeiter mehr, sondern ich habe da nur noch 17 Agents, die für mich rumlaufen ja, aber ich glaube dass das nicht dasselbe ist. Also das ist was anderes, als mit Ländern schon zu arbeiten und damit ist es für mich kein Teammitglied. Das ist weiterhin eine Unterstützungstechnologie. Ja, da kann ich nicht hin. Ja, und wir hatten ja gestern noch mit dem Fall Thema Coaching-Expertise weiterentwickeln, Julia, wie wir zusammengesessen sind. Und ich habe halt jetzt auch schon in meinem Freundeskreis die sozusagen sich von JGPT sozusagen begleiten lassen in einer Entwicklung. Also wo der, weil sie sich jetzt einen Coach nicht leisten können, mit denen sozusagen eine Begleitung haben. Und es gibt auch Studien darüber, nicht Studien, aber auf jeden Fall nicht nur Einzelfälle, wo Menschen das aus schwierigen Phasen rausfinden, weil es ja halt jemanden, der ihnen positiv zuspielt hat. Und ich denke mal, letztendlich ist es ein Assistent, der einen bestimmten Blickwinkel bekommt. Es ist was anderes, ob ich sage, dass ich das will. Aber ich kann mir durchaus vorstellen, dass das kommen wird. Ich denke mal, der Knackpunkt ist, wenn wir in der Entscheidung sind, ist die Frage, wie können wir immer noch eine gute Entscheidung treffen. Wir kriegen ja letztendlich über die Zeit, wo wir Erfahrungen machen, ein Bauchgefühl dafür, was gut oder was vielleicht schlecht ist. Aber meinst du, du hast es jetzt ja auch so als Coach, die KI als Coach für eine Person, als Sparingspartner, stelle ich mir wieder anders vor, als ich als Teammitglied. Deshalb glaube ich, das ist das große, bei mir einfach das Thrashing. Also mich davon unterstützen zu lassen, Klar, das werden fast alle Entwickler tun oder tun müssen. Ja, und ich glaube, das, was halt, vielleicht ist die Frage, wie man halt Teammitglied irgendwie dann definiert, aber der kennt halt den Teamkontext. Der kennt irgendwie alle Dailies, der weiß sozusagen irgendwie alles, was gelaufen ist. Also es ist halt nicht irgendwie ein Assistent wie von, sagen wir mal, in einem Word-Dokument, der nicht weiß, was wir die letzten vier Wochen gemacht haben. Ja, ja. Und dann kennt ihr den kompletten Kontext. Übrigens, ich habe so das Gefühl, wir kommen nicht über das hinaus, dass wir diese sechs verschiedenen Sparten anschauen. Ich finde es total spannend. Wie geht es euch? Wollen wir das einfach zu Ende machen? Weil wir werden dann nicht mehr zu den Fragen kommen, wenn ich auf die Zeit schaue. Oder wir würden das hier jetzt abbrechen dann. Das wäre die andere Alternative. Was denn? Ich kann nochmal die Fragen mal aufdecken hier nach unten. Also es kommt dann hier, warte mal, weil das ist einfach zu viel, sonst ist es schlecht. Das ist wie gestern. Das war jetzt hier, Entwicklung wird experimentell und simulationsbasiert. Also passiert das. Also Digital Twins für Softwarelösungen, was damit gemeint ist, Hervorrags-Outs werden komplette Softwareumgebungen in Simulationsräumen getestet, samt Nutzerverhalten, Last und Fehler fällen. Also nochmal dahin, du würdest jetzt entweder da weitermachen, oder wir würden nach dem, wo du sagst, was gilt es für uns als Software-Entwicklungsteams zu lernen, um uns darauf vorzubereiten. Genau. Wenn ich vielleicht das, also das Einschätzen ist vielleicht auch schlau, aber vielleicht macht es aus, wenn wir gucken nochmal die anderen Wegen. Die Fragen? Ja. Wollen wir dann rüberwandern? Okay, können wir machen. Dann ziehe ich euch rüber. Also das ist übrigens, wie so ein Tagesablauf ausschauen kann. An der Stelle. Und mit eben, ich weiß gar nicht, ich kann euch da mal ganz schnell drüber führen. Ja, also so sanfter Start mit Mixed Reality Workspace. Also sozusagen, wir haben einen KI-Assistenten, der uns gesagt, was so passiert ist, was über Nacht festgestellt hat und erinnert sich noch an das Gespräch, was wir gestern hatten mit dem Ethik-Thema. Dann asynchrones Team-Alignment. Jeder bringt sozusagen seinen Daily-Status mit rein. Den kriegt man dann in der Früh zur Verfügung gestellt. Dann Produktexploration mit Fachdomänen, also da, wo man wirklich dann zusammenkommt, Hypothesen aufstellt und ein Assistent, die dann konkret sozusagen formuliert, also die Ergebnisse zusammenfasst, irgendwie aus dem Meeting, so wie wir es ja jetzt hier auch haben. Ich bin mir mal gespannt, was dann da rauskommt aus diesem Dialog, den wir haben. Ja, der Fachärztin sagt, ich möchte, dass das System die erste Anzeige subtiler kognitiver Abweichung erkennt, ohne zu stigmatisieren und die KI-Antwort, mhm. Dann haben wir KI-gesteuertes Development. Lina übergibt ein Ziel und die KI macht. Dann die Fokuszeit und Deep Work. Komplett wird man rausgesucht, binaurale Musik wird eingesetzt und dann kann man komplett ein komplexes Stück Domain in spezifischer Logik, das noch nicht automatisiert werden kann, erarbeiten. Dann haben wir so ein Outcome Review mit den Stakeholdern, also mit KI und Stakeholdern. Und am Schluss nochmal am Ende des Tages Reflexion und Lernen. Also einfach mal ein Gefühl zu gehen, wie aus KI-Sicht, also das ist jetzt alles ohne spezielles Prompting entstanden gestern mit ChatGBD. Und dann hat man so ein Fazit des Tages. Also wie wird das denn eigentlich? Die KI ist Umsetzer, Simulant, Berater. Übrigens, Julia, dadurch, dass wir heute Entwickler im Team haben, denke ich mal, dass sie da an der Stelle auch sagen, sie sind Umsetzer. Also sie sind Teammitglied. Und der Fokus liegt mehr auf der Wirkung, nicht auf Code. Ich würde mal sagen, das Letztere, das sollte man eigentlich heute schon haben. Teams sind klein. Wenn ihr überlegt, wie viele Teams waren, jetzt in der Mittlerweile versuchen wir, über zwei Pizza-Teams zu gehen. Die oberen zwei, da bin ich gespannt. Jetzt würde ich mal rübergehen zu den Fragen, die ich da noch habe. Also, wenn man mal sagt, und das ist übrigens abhängig davon, wer immer von uns ist, das Heaven-Szenario. Das ist ja noch nicht beschrieben, dass wenn das alles kommt, dass wir mitunter vielleicht die Software gar nicht mehr warten können, ganz geschweige denn die Software gar nicht mit vielleicht wegen das, was das ja letztendlich bearbeitet ist, ja auch mit der Software, gar nicht damit umgehen kann. Also wenn man mal sagt, was gilt es denn für Softwareentwicklungsteams zu lernen, um uns auf so eine prognostizierte Heftenzukunft vorzubereiten und die Helddystopie sozusagen zu vermeiden. Und jetzt gehe ich mal davon aus, wer gewusst, wie viele Entwickler kommen, also Menschen, die Entwicklungs-Background haben, welche Erkenntnisse habt ihr dazu bereits schon? Oder wo lässt sich etwas dazu finden? Es kann auch sein, dass ihr was dazu gelesen habt, weil dann fände ich das spannend. Oder welche Ideen, HI, AI-Einsätze habt ihr, diese Fragestellung weiter zu explorieren? Und jetzt könnte ich einfach mal sagen, dass jeder mal sich vielleicht zwei Minuten mal Zeit nimmt, was ihm dazu einfällt und dann könnt ihr einfach dieses Deine Gedanken Post-it kopieren und dann teilen wir das noch miteinander und dann wäre das der Abschluss der Session. Klingt das dein Plan? Hell oder heaven, das hast du letztendlich schon bearbeitet, so tief bin ich eigentlich noch nicht reingegangen. Ich glaube, wir haben in unserer Diskussion ein bisschen für uns auch schon mal so ein helles Szenario aufgezeichnet, aber ist uns schon allen klar, was für uns heaven und hell ist? Also mir ist es das noch nicht. Wie sieht das bei dir aus? Das ist jetzt garantiert nur vage, ja. Also auch wenn das, was ich sozusagen beschrieben habe oder was ChatGPT beschrieben hat, war aus meiner Sicht eher das Heaven-Szenario und noch nicht unbedingt das Hell-Szenario. Weil ich habe für mich ein Bauchgefühl, wie ein helles Szenario ausschaut. Dass wir eigentlich komplett von der KI abhängig sind. Es ist nicht mehr selber, um wir verändern können und die KI kann es auch nicht. Und wir müssen es aber updaten. Und das wäre natürlich für mich so ein totales helles Szenario. Das sehe ich halt heute schon mit Code, der von Menschen geschrieben wird. Und die KI wird dann in deutlich größerer Geschwindigkeit deutlich mehr Code erzeugen. Das heißt, du hast eine Masse, die du gar nicht mehr beherrschen kannst. Das wäre für mich so das Dystopische. Okay, dann lass uns mal ein paar Minuten. Ist okay. Wie komme ich denn da hin zu dem Conceptboard? Du kannst einfach auf meine Person, siehst du mich hier oben? Das kann ich nicht größer machen. Ich bin der Martin Heider. Man kann dann sagen, geh zu dieser Person. Geht das? Oder ich kann nochmal schauen, warte mal, wenn ich dich sehe. Yvonne? Sonst nochmal den Objektlink direkt aufs Board teilen. Ja, das kann ich machen. Warte mal, ich kann das machen. Guter Punkt. Ich mach das. Hilft was, wenn Ivan bei Discord ist? Genau, das müsstest du halt den Chat im Discord mal lesen. Okay, ich mach das mal in Discord Räume. So. So. Link auf unseren Siehst du das? Ich soll jetzt praktisch in Discord auf den Raum gehen. Okay. Dann mache ich das. Und da habe ich dir den Link reinkopiert, weil ich kann es nicht hier in dem Chat machen, weil der ist deaktiviert, damit alles in Discord ist. Okay, wir sind Great Portland, ne? Ja. Okay. Gut, ich habe es. Ja, weil es ist so groß, das Konzept wurde. Das ist so Wahnsinn. Das lädt es im Verlauf. Ja, und ich. Dann. Aber der bringt mich nur zum Conceptboard, oder? Nee, er müsste dich genau dorthin bringen, wo wir sind. Ja, aber auch ein bisschen. Der hat auch Hitzestau. Nee, wir können uns keine größere, bessere Rechner leisten von der Stadt Erlangen. Wir sind hier. Ja, so ist das halt, aber das wird schon. So, er blendet ein. Ja, super. Okay. Okay. Okay. Gut. Ah, siehst du, Yvonne. Du hast es geschafft. Wir können ja schon mal starten. Für die anderen dann. Während Yvonne vielleicht noch schreibt. Ich weiß nicht, müssen wir, Julia, Haben wir eine Pause danach? Schauen wir kurz. Also das ist die Profession, der gemeinsame Abschluss drüben quasi wieder gemeinsam ist. Ja, also wir haben jetzt zwei Minuten quasi. Also das heißt, wir müssen jetzt gleich aufbrechen, dann schauen wir einfach mal was. Also vielleicht rückwärts da sein, weil ich wieder eine Videoschnitte machen muss, muss mein Rechner drüben aufbauen. Alles klar. Dann bring doch du mal deine Sachen ein, Magnus, mit, dann kannst du ja als erster gehen, oder? Ja. Also ich finde es auch toll tatsächlich, wenn es für euch okay ist, wenn wir im Nachhinein einfach nicht mehr weiter überlegen, auch bei deinen anderen Fragen, die vorher waren, mit dem rot-grühen-gelb, das einfach noch mal weiter machen und wir da halt einfach, was ich morgen noch mal draufgucken, was die anderen mit anderen sehen, vielleicht auch noch mal Kontakte tauschen. Ich finde die Diskussion sehr, sehr wichtig. Also erstmal vielen lieben Dank. Auch wenn ich gleich bei früher rausgehe, also finde ich schon sehr spannend ich bin noch nicht so tief drin, ich habe jetzt ja geschrieben in Richtung Erkenntnisbereich ist halt teilweise nicht, glaube ich, Code zu sharen mit einer KI, wo Kundenbezug drin ist da gibt es richtig, was auch nicht so eindeutig ist okay, was kannst du wirklich halt mit dem kannst du dir helfen lassen, so eine Art lokale KI wäre tatsächlich auch eine Idee, eben halt zu nutzen, fällt mir da gerade auch ruhiger und sonst wären die Ideen eben Ethikrichtlinien festlegen Regeln für Kainnutzung generell abstehen, das war auch so ein bisschen das, was wir in unserer Session vorhin mit zur vorzunehmen gehabt haben das waren da auch für die allgemeine Kainnutzung natürlich auch Regeln und ich glaube, das müssen wir hier ganz dafür auch definieren Absolut Julia, möchtest du? Danke dir, Martinus. Genau, ich glaube, ich habe gar nicht noch, also ich glaube, du musst mich noch ein bisschen tiefer reindenken, aber ich hatte jetzt sozusagen den Gedanken, wenn Quarist-Systeme nicht mehr zugänglich und das Wissen über die Quotes ist eigentlich nicht mehr da, weil alles KI generiert oder zumindest von KI übernommen und die Menschen, die es getan haben, sind nicht mehr da. Also dieses Wissen tatsächlich unabhängig von KI, auch wenn es quasi oldschool ist, aber auch festzuhalten. KI könnte ja vielleicht unterstützen, aber das Wissen darf nicht in KI allein aufgeben, so wäre mein erster Impuls quasi. Also man muss schon noch irgendwo die Möglichkeit haben, sich nochmal nachzuführen. Okay, danke dir, Julia. Yvonne? Ja, meine Erkenntnis, jetzt habe ich da nichts zu geschrieben, aber mir wurden die Schritte viel klarer. Also das war so ein großer Baustein, was bedeutet das, welchen Einfluss hat das. Aber unklar ist mir immer noch, wie man praktisch erkennt, dass das System irgendwelche ethischen Kriterien nicht erfüllt oder sogar Diskriminierung durchführt. Also ich weiß auch nicht, wo man da ansetzen soll. Das ist immer das, wo man auch sagt, der Mensch muss immer da noch das Ende von der Fahnenstange sein. Ja, vielleicht müsst ihr da auch wissen, warum die KI so entscheidet, um praktisch ganz klar zu sagen, hier ist die Ethik auch noch irgendwie genug mit am Start. Also die spielt hier auch die Rolle, die sie spielen sollen. Ja. Also das ist das, was ich sagen kann. Ich konnte nicht immer aufpassen auf alles. Ja, aber ich finde es trotzdem sehr interessant, wie diese Umsetzung und diese was für eine Rolle spielen kann im Endeffekt. Die KI in der Entwicklung. Ja. Ich hatte auch noch zwei Gedanken. Also überhaupt immer, Das ist in der Entwicklung recht nahe, dadurch, dass Co-Pilot oder andere Assistenten nutzbar sind. Das heißt, die Entwickler sind frühzeitig damit konfrontiert. Viele von denen ich weiß, Unternehmen waren sehr frühzeitig eingebunden und konnten es nutzen. Was ich auch spannend fand, dass wir hier gerade noch rauskommen, weil ich habe jetzt hier eine mögliche Zukunft skizziert, eine Diskussion über einen gewünschten Heaven und Hell zu führen. Also Julias Hell, glaube ich, schaut anders aus wie meine. Und das ist, oder vielleicht schaut es ja gar nicht so anders aus, aber vielleicht hat meine noch ein paar Zusatzaspekte, weil ich sehen kann, was technisch alles schief gehen kann. Ja. Und das Gespräch zu führen, finde ich spannend. Und die Zukunft, die er jetzt da prognostiziert hat, ist ja nur eine von vielen möglichen. Also deswegen bin ich mal gespannt. Vielleicht machen wir das mal in der Community, in der